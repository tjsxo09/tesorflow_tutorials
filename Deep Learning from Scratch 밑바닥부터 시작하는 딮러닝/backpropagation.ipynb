{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 오차역전파(backpropagation)의 필요성\n",
    "\n",
    "- 매개변수의 기울기를 구할 때 수치 미분을 사용하면\n",
    "    1. 구현이 편하다.\n",
    "    2. 계산 시간이 오래 걸린다.\n",
    "    \n",
    "- 매개변수의 기울기를 효율적으로 구하기 위해서 오차역전파를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 계산 그래프\n",
    "\n",
    "- 복수의 노드와 에지로 표현 \n",
    "\n",
    "## 2.1. 계산 그래프로 풀기\n",
    "- 문제 1 : 슈퍼에서 1개에 100원인 사과 2개를 구매. 지불 금액을 구하시요. 소비세는 10%\n",
    "- 위 문제를 그래프로 표현시\n",
    "![문제 1](./images/Q1.png)\n",
    "\n",
    "\n",
    "- 사과의 개수, 소비세를 변수로 취급해 원 밖에 표시\n",
    "![문제_1변형](./images/Q1.2.png)\n",
    "\n",
    "\n",
    "- 문제 2 : 슈퍼에서 사과를 2개, 귤을 3개 샀습니다. 사과는 1개에 100원, 귤은 1개 150원 소비세는 10%\n",
    "![문제_2](./images/Q2.png)\n",
    "\n",
    "\n",
    "- 계산 그래프를 이용한 문제풀이\n",
    "    1. 계산 그래프를 구성\n",
    "    2. 그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다.\n",
    "\n",
    "\n",
    "- 위와 같은 방법을 순전파라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 국소적 계산\n",
    "\n",
    "- 자신과 직접 관계된 작은 범위라는 뜻\n",
    "- 전체 계산이 복잡할지어도 각 노드에서의 계산은 국소적 계산이므로 단순한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 왜 계산 그래프로 푸는가?\n",
    "\n",
    "1. 각 노드에서 문제를 단순화 할 수 있다.\n",
    "2. 중간 계산 결과를 모두 보관할 수 있다.\n",
    "3. 미분을 효율적으로 계산할 수 있다.\n",
    "\n",
    "\n",
    "- 역전파 그림 예시(굵은 화살표 밑의 숫자는 국소적 미분값)\n",
    "![역전파_예시](./images/BP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 연쇄법칙\n",
    "\n",
    "- 국소적 미분을 전달하는 원리\n",
    "\n",
    "\n",
    "## 3.1. 계산 그래프의 역전파\n",
    "\n",
    "- y = f(x)의 역전판 그림 예시\n",
    "![y=f(x)_역전파_예시](./images/BP2.png)\n",
    "\n",
    "\n",
    "- 역전파의 순서\n",
    "    1. 국소적 미분을 구한다.\n",
    "    2. 앞에서 전달된 신호에 국소적 미분을 곱한 뒤 다음 노드로 전달한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. 연쇄법칙이란?\n",
    "\n",
    "- 합성 함수\n",
    "\n",
    "여러 함수로 구성된 함수\n",
    "\n",
    "\n",
    "- z =(x+y)<sup>2</sup>를 합성 함수로 표현\n",
    "\n",
    "$$\n",
    "z = t^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "t = x + y\n",
    "$$\n",
    "\n",
    "\n",
    "여기서 합성 함수의 미분에 대한 성질 - 합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다. - 는 원리를 사용한다.\n",
    "\n",
    "\n",
    "- 위의 식을 예시로 설명\n",
    "$$\n",
    "\\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x}\n",
    "$$\n",
    "\n",
    "위의 δt는 서로 지울 수 있으므로\n",
    "\n",
    "$$\n",
    "\\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\delta x}\n",
    "$$\n",
    "\n",
    "가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 역전파 \n",
    "\n",
    "- +, x 등의 연산을 예로 들어 역전파 구조 설명\n",
    "\n",
    "## 4.1. 덧셈 노드의 역전파\n",
    "\n",
    "- z = x + y을 해석적으로 계산\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\delta z}{\\delta x} = 1 \\\\\n",
    "\\frac{\\delta z}{\\delta y} = 1\n",
    "$$\n",
    "\n",
    "- 계산 그래프로 표현\n",
    "![덧셈_계산그래프](./images/plus.png)\n",
    "\n",
    "\n",
    "- 덧셈 노드의 계산 그래프로 알 수 있는 것\n",
    "    1. 덧셈 노드의 역전파는 입력된 값을 그대로 다음 노드로 보낸다.\n",
    "    \n",
    "## 4.2. 곱셈 노드의 역전파\n",
    "\n",
    "- z = xy를 해석적으로 미분\n",
    "\n",
    "$$\n",
    "\\frac{\\delta z}{\\delta x} = y \\\\\n",
    "\\frac{\\delta z}{\\delta y} = x\n",
    "$$\n",
    "\n",
    "\n",
    "- 계산 그래프로 표현\n",
    "![곱셈_계산그래프](./images/multi.png)\n",
    "\n",
    "\n",
    "- 곱셈 노드의 계산 그래프로 알 수 있는 것\n",
    "    1. 입력 신호를 서로 바꾸어서 곱한 뒤 다음 노드로 보낸다.\n",
    "    \n",
    "## 4.3. 사과 쇼핑 예\n",
    "\n",
    "- 처음 시작했던 사과 쇼핑에 역전파를 적용하였을때의 계산\n",
    "![사과_쇼핑_계산그래프](./images/apple_BP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 단순한 계층 구현하기\n",
    "\n",
    "- 곱셈 노드를 Mullayer, 덧셈 노드를 Addlayer라는 이름으로 구현한다.\\\n",
    "\n",
    "##  5.1. 곱셈 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 곱셈 노드에 대한 구현\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x*y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사과 예제에 대한 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "순전파를 사용한 사과 값 : 220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "# 변수 설정\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# layers\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(\"순전파를 사용한 사과 값 : {}\".format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "역전파를 이용한 각 지점의 미분값 : 2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "# backpropagation\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(\"역전파를 이용한 각 지점의 미분값 : {} {} {}\".format(dapple, dapple_num, dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5.2. 덧셈 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈 노드에 대한 구현\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 활성화 함수 계층 구현하기\n",
    "\n",
    "- Sigmoid, Relu 함수 구현\n",
    "\n",
    "## 6.1. ReLU 계층\n",
    "\n",
    "- ReLU 수식\n",
    "$$\n",
    "y = \n",
    "\\cases{\n",
    "x \\quad (x>0) \\cr\n",
    "0 \\quad (x\\leq0) \n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "- 미분 값\n",
    "$$\n",
    "\\frac{\\delta y}{\\delta x} = \\cases{\n",
    "1 \\quad (x>0) \\cr\n",
    "0 \\quad (x\\leq0)\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "- ReLU의 계산 그래프\n",
    "![ReLU_계산_그래프](./images/ReLU_graph.png)\n",
    "1. x > 0인경우 미분값이 1이므로 상류에서 내려온 값이 그대로 전달된다.\n",
    "2. 반대의 경우엔 미분값이 0이므로 0이 내려간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.mask = (x <= 0) # x가 0보다 작거나 같으면 True, 아니면 False\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0 # True인 부분은 0으로 만들어 전달한다.\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Sigmoid 계층\n",
    "\n",
    "- Sigmoid 수식\n",
    "$$\n",
    "y = \\frac{1}{1 + exp(-x)}\n",
    "$$\n",
    "\n",
    "- Sigmoid 계층의 계산 그래프\n",
    "\n",
    "\n",
    "![Sigmoid_그래프_순전파](./images/sigmoid.png)\n",
    "- exp, / 노드 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- / 노드 미분 수식\n",
    "$$\n",
    "y = \\frac{1}{x} \\\\ \\\\\n",
    "\\frac{\\delta y}{\\delta x} = -\\frac{1}{x^2} \\\\ \\\\\n",
    "= -y^2\n",
    "$$\n",
    "\n",
    "\n",
    "미분값을 보면 상류에서 내려온 값에 -y<sup>2</sup>를 곱하고 내려보내준다.\n",
    "\n",
    "\n",
    "- exp 미분 수식\n",
    "$$\n",
    "\\frac{\\delta y}{\\delta x} = exp(x)\n",
    "$$\n",
    "위와 같이 상류에 exp(x)를 곱하고 내려보내준다.\n",
    "\n",
    "\n",
    "이에 따라서 sigmoid의 모든 노드를 차례차례 보면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 단계 / 노드이므로 -y<sup>2</sup>을 곱하여 보내준다.\n",
    "$$\n",
    "-\\frac{\\delta L}{\\delta y}y^2\n",
    "$$\n",
    "가 된다.\n",
    "\n",
    "\n",
    "2. 단계 + 노드이므로 상류와 같은 값을 보낸다. 따라서 다음 노드로 내려갈 값은\n",
    "$$\n",
    "-\\frac{\\delta L}{\\delta y}y^2\n",
    "$$\n",
    "가 된다.\n",
    "\n",
    "\n",
    "3. 단계 exp 노드이므로 exp(a)를 곱하여 보내준다. a의 값이 -x이므로 내려갈 값은\n",
    "$$\n",
    "-\\frac{\\delta L}{\\delta y}y^2exp(-x)\n",
    "$$\n",
    "가 된다.\n",
    "\n",
    "4. 단계 x 노드이므로 순전파의 값을 바꿔 곱해준다. -1을 곱해줘야 하므로 내려갈 값은\n",
    "$$\n",
    "\\frac{\\delta L}{\\delta y}y^2exp(-x)\n",
    "$$\n",
    "가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 간소화한 Sigmoid 계산 그래프\n",
    "![Sigmoid_그래프_순전파](./images/sigmoid_set.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정리\n",
    "$$\n",
    "y = \\frac{1}{1 + exp(-x)} \\\\\n",
    "\\frac{\\delta L}{\\delta y}y^2exp(-x) = \\frac{\\delta L}{\\delta y} \\frac{1}{(1 + exp(-x))^2}exp(-x) \\\\\n",
    "= \\frac{\\delta L}{\\delta y} \\frac{1}{1 + exp(-x)} \\frac{exp(-x)}{1 + exp(-x)} \\\\\n",
    "= \\frac{\\delta L}{\\delta y}y(1-y)\n",
    "$$\n",
    "\n",
    "\n",
    "따라서 sigmoid 계층은 y만을 가지고서 역전파가 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid 계층 구현\n",
    "class SIgmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.out * (1.0 - self.out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Affine/Softmax 계층 구현하기\n",
    "\n",
    "- 신경망의 순전파 때 수행하는 행렬 곱을 의미\n",
    "- numpy에서는 np.dot으로 사용가능\n",
    "\n",
    "![Affine_계층](./images/affine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Affine 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dw = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Softmax-with-Loss\n",
    "\n",
    "- Softmax는 학습을 할때는 필요하지만, 추론을 할 경우에는 가장 높은것 하나만 고르면 되기때문에 softmax를 사용할 필요가 없다.\n",
    "\n",
    "\n",
    "![소프트맥스_로스](./images/softmax-w-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Softmax-with-Loss 계층 구현 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t # 정답 레이블\n",
    "        self.y = softmax(x) # 결과값\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
