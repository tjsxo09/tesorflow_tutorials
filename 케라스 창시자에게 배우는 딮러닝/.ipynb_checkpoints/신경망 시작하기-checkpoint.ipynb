{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이진 분류, 다중 분류, 회귀 예제를 사용\n",
    "- GPU를 사용한 딮러닝 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 신경망의 구조\n",
    "\n",
    "- 신경망 훈련에 관련 된 요소\n",
    "    1. 네트워크를 구성하는 층\n",
    "    2. 입력 데이터와 상응하는 타깃\n",
    "    3. 피드백 신호를 정의하는 손실 함수\n",
    "    4. 학습 진행 방식을 진행하는 옵티마이저\n",
    "    \n",
    "- 각 요소 사이의 관계\n",
    "![관계_그림_예시](./images/relation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. 층: 딮러닝의 구성 단위\n",
    "\n",
    "- 하나 이상의 텐서를 입력받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈\n",
    "- 대부분의 경우 가중치라는 층의 상태를 가짐\n",
    "- 텐서 종류에 따른 층의 사용\n",
    "    1. 2D 텐서 -> 완전 연결 층\n",
    "    2. 3D 텐서 -> LSTM 같은 순환 층\n",
    "    3. 4D 텐서 -> 2D 합성곱 충(convolution layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스에서는 층을 레고 블럭과 같이 생각 할 수 있다.\n",
    "- 케라스는 호환 가능한 층들을 엮어 데이터 변환 파이프라인을 구성한다.\n",
    "\n",
    "\n",
    "- 케라스에서 층 호환성이란?\n",
    "    - 각 층이 특정 크기의 입력 텐서만 받고 특정 크기의 출력 텐서를 반환하는 것\n",
    "    \n",
    "\n",
    "### 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "# keras.layers.Dense(output_shape, input_shape=(input_shape))\n",
    "layer = layers.Dense(32, input_shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 코드 예시는 첫 번째 차원이 784인 2D 텐서만 입력으로 받는 층이다.\n",
    "- 출력 텐서 크기는 32이다.\n",
    "- 다음 레이어는 입력 크기가 32인 층으로 자동으로 맞추어 준다. (층 호환성으로 인해서)\n",
    "\n",
    "\n",
    "### 모델로 만든 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "model = models.Sequential() # 모델을 층을 연속적으로 쌓아서 하나의 모델로 표시하게 한다.\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(10)) # 층 호환성이 없다면 layers.Dense(10, input_shape(32))라고 입력 크기를 지정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 밀집층에서 입력 크기를 지정하지 않았음에도 모델이 만들어지는것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. 모델: 층의 네트워크\n",
    "\n",
    "- 딮러닝 모델은 층으로 만든 비순환 유향 그래프이다.\n",
    "- 자주 등장하는 네트워크 구조\n",
    "    1. 가지가 2개인 네트워크\n",
    "    2. 출력이 여러 개인 네트워크\n",
    "    3. 인셉션 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. 손실 함수와 옵티마이저: 학습 과정을 조절하는 열쇠\n",
    "\n",
    "- 네트워크 구조를 정의하고나서 해야할 것\n",
    "    1. 손실 함수: 훈련동안 최소화될 값(성공 지표)\n",
    "    2. 옵티마이저: 손실 함수를 기반으로 네트워크가 어떻게 업데이트 될지 결정(ex: SGD, Adam, momentum...)\n",
    "\n",
    "\n",
    "- 여러 개의 출력을 내는 신경망은 여러 개의 손실 함수를 가질 수 있다.\n",
    "\n",
    "\n",
    "- 올바른 손실 함수를 선택하는 지침\n",
    "    1. 2개의 클래스가 있는 분류 문제 : 이진 크로스엔트로피\n",
    "    2. 회귀 문제 : 평균 제곱 오차\n",
    "    3. 시퀸스 학습 문제 : CTC\n",
    "    4. 새로운 연구 : 독자적인 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 케라스 소개\n",
    "\n",
    "- 케라스의 특징\n",
    "    1. 동일한 코드로 CPU와 GPU에서 실행 할 수 있다.\n",
    "    2. 사용하기 쉬운 APi를 가지고 있다.\n",
    "    3. 합성곱 신경망, 순환 신경망을 지원하며 둘을 조합 할 수 있다.\n",
    "    4. 어떤 네트워크 구조도 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 케라스, 텐서플로, 씨아노, CNTK\n",
    "\n",
    "- 케라스 특징\n",
    "    1. 모델 수준의 라이브러리\n",
    "    2. 텐서 조작, 미분 같은 저수준 연산을 다루지 않는다.\n",
    "    3. 백엔드에서 제공하는 최적화된 텐서 라이브러리 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 케라스를 사용한 개발: 빠르게 둘러보기\n",
    "\n",
    "- 케라스 작업 흐름\n",
    "    1. 훈련 데이터 정의\n",
    "    2. 네트워크 정의\n",
    "    3. 지표 선택을 선택하여 학습 과정을 설정\n",
    "    4. fit() 메서드를 반복절으로 호출\n",
    "\n",
    "\n",
    "- 모델을 정의하는 방법\n",
    "    1. Sequential 클래스를 사용\n",
    "    2. 함수형 API 사용\n",
    "    \n",
    "    \n",
    "### Sequential 클래스를 사용하는 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() \n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수형 API를 사용하는 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(784,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 구조가 정의된 후에는 어떤 방법을 사용했는지는 상관없이 이후 단게는 같다.\n",
    "\n",
    "\n",
    "### 컴파일 단계\n",
    "1. 손실함수 정의\n",
    "2. 옵티마이저 정의\n",
    "3. 측정 지표 설정(선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), # 학습률이 0.001으로 설정\n",
    "             loss = 'mse',\n",
    "             metrics=['accuracy']) # 측정 지표로는 정확도를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 단계\n",
    "\n",
    "- fit() 메소드를 사용하여 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(input_tensor, target_tensor, batch_size=128, epoch=10) 여기서는 타겟 텐서가 없으므로 주석 처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 딮러닝 컴퓨터 셋팅\n",
    "\n",
    "- 이 소단원은 하드웨워 및 프로그램 선택에 관한 이야기이므로 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 영화 리뷰 분류: 이진 분류 예제\n",
    "\n",
    "- 영화 리뷰에 대한 긍정(positive), 부정(negative)을 예측하는 문제\n",
    "- 클래스가 2개이므로 이진분류로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. IMDB 데이터셋\n",
    "\n",
    "- 데이터셋\n",
    "    1. 종류 : 인터넷 영화 데이터베이스에서 가져온 양극단 리뷰\n",
    "    2. 개수 : 약 5만개\n",
    "    3. 분류 : 훈련 데이터 2.5만, 테스트 데이터 2.5만\n",
    "    \n",
    "    \n",
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_word 인자 -> 훈련 데이터에서 가장 자주 나타나는 단어 수를 사용\n",
    "- *_data = 리뷰 목록\n",
    "- *_labels = 부정(0), 긍정(1)을 나타내는 리스트\n",
    "\n",
    "\n",
    "### 리뷰 데이터\n",
    "\n",
    "- 리뷰 데이터는 단어가 수자로 매핑되어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 리뷰 : [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(\"0번 리뷰 : {}\".format(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라벨 데이터\n",
    "\n",
    "- 긍정일 경우 1, 부정일 경우 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 리뷰의 라벨: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"0번 리뷰의 라벨: {}\".format(train_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 수 측정\n",
    "\n",
    "- 가장 자주 산용되는 단어 10000개로 정해놓았기 때문에 10000개 이상의 단어 수를 넘지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영단어와 매핑하여 리뷰 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index() # 단어와 정수 인덱스를 매핑한 딕셔너리\n",
    "reverse_word_index = dict([(value, key) for (key,value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 데이터 준비\n",
    "\n",
    "- 신경망에는 숫자 리스트를 주입할 수 없다.\n",
    "- 리스트를 텐서로 변경하는 방법\n",
    "    1. 같은 길이가 되도록 리스트에 패딩 추가하여 (samples, sequence_length) 크기의 정수 텐서로 변환\n",
    "    2. 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환\n",
    "    \n",
    "\n",
    "### 정수 시퀸스를 이진 행렬로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#각 문장에서 나온 단어를 1로 만드는 함수\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. # 특정 인덱스의 위치를 1로 만듬\n",
    "        \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩한 훈련 데이터 0번 : [0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"인코딩한 훈련 데이터 0번 : {}\".format(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이블을 벡터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels).astype('float32')\n",
    "y_test = np.array(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. 신경망 모델 만들기\n",
    "\n",
    "- relu 함수를 사용한 완전 연결 층을 사용\n",
    "- 은닉 유닛이 늘어나면 학습의 표현력이 늘어나지만 계산 비용이 커진다.\n",
    "\n",
    "- Dense 층을 쌓을 때 필요한 구조상으 ㅣ결정\n",
    "    1. 얼마나 많은 층을 쌓을 것인가?\n",
    "    2. 얼마나 많은 은닉 유닛을 둘 것인가?\n",
    "  \n",
    "  \n",
    "### 3층으로 쌓은 신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵티마이저 설정\n",
    "\n",
    "- 이진 분류 문제 -> binary crossentropy 사용\n",
    "- 옵티마이저 -> rmsprop 사용\n",
    "- 훈련 평가 지표 -> accuracy 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케라스의 내장 되어 있는 옵티마이저 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy']) # 학습률이 0.001인 rmsprop을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케라스에 내장 되어 있는 손실 함수, 측정 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.binary_crossentropy,\n",
    "             metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. 훈련 검증\n",
    "\n",
    "- 훈련에서는 훈련 - 검증 - 테스트 데이터를 나누어서 사용한다.\n",
    "- 검증 데이터를 만들기 위해서는 훈련 데이터에서 샘플을 나누어서 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련\n",
    "- 데이터의 배치 개수는 512개로 설정\n",
    "- 모든 데이터를 20번 반복하여 훈련 합니다. (epoch = 20)\n",
    "- 훈련과 동시에 검증 데이터에 적용하여 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 4s 254us/step - loss: 0.5079 - acc: 0.7857 - val_loss: 0.4008 - val_acc: 0.8547\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 3s 190us/step - loss: 0.3053 - acc: 0.9040 - val_loss: 0.3266 - val_acc: 0.8737\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 3s 190us/step - loss: 0.2245 - acc: 0.9281 - val_loss: 0.2800 - val_acc: 0.8902\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.1728 - acc: 0.9437 - val_loss: 0.3301 - val_acc: 0.8675\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 3s 199us/step - loss: 0.1411 - acc: 0.9542 - val_loss: 0.2818 - val_acc: 0.8891\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 3s 189us/step - loss: 0.1156 - acc: 0.9655 - val_loss: 0.2982 - val_acc: 0.8849\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 3s 186us/step - loss: 0.0982 - acc: 0.9695 - val_loss: 0.3138 - val_acc: 0.8824\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 3s 188us/step - loss: 0.0790 - acc: 0.9779 - val_loss: 0.3333 - val_acc: 0.8813\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.0665 - acc: 0.9814 - val_loss: 0.3581 - val_acc: 0.8776\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 3s 199us/step - loss: 0.0545 - acc: 0.9867 - val_loss: 0.3963 - val_acc: 0.8742: 0s - loss: 0.0531 - acc: \n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0460 - acc: 0.9892 - val_loss: 0.4210 - val_acc: 0.8729\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 3s 200us/step - loss: 0.0357 - acc: 0.9922 - val_loss: 0.4369 - val_acc: 0.8748\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 4s 257us/step - loss: 0.0294 - acc: 0.9940 - val_loss: 0.4674 - val_acc: 0.8728\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 3s 194us/step - loss: 0.0226 - acc: 0.9965 - val_loss: 0.5018 - val_acc: 0.8702\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 3s 186us/step - loss: 0.0201 - acc: 0.9964 - val_loss: 0.5370 - val_acc: 0.8676\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 3s 186us/step - loss: 0.0171 - acc: 0.9968 - val_loss: 0.5703 - val_acc: 0.8676\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 3s 186us/step - loss: 0.0100 - acc: 0.9994 - val_loss: 0.5924 - val_acc: 0.8674\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 3s 193us/step - loss: 0.0091 - acc: 0.9993 - val_loss: 0.6354 - val_acc: 0.8678 acc: 0.999\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 3s 213us/step - loss: 0.0103 - acc: 0.9979 - val_loss: 0.6707 - val_acc: 0.8662\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.7040 - val_acc: 0.8650\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.binary_crossentropy,\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### history 객체\n",
    "\n",
    "- 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histroy의 key: dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(\"histroy의 key: {}\".format(history_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 출력에서 확인 할 수 있듯이 모니터링 할 측정 지표들을 가지고 있는것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련과 검증 손실 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1) # loss 개수 만큼 설정 epoch 개수를 설정\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') # x축에 epochs 값으로, y축을 loss 값으로 설정\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs') # 축 라벨을 Epochs로 설정\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 그래프에서 훈련 loss는 계속해서 낮아지지만, 검증 loss는 상승하는 것을 볼 수 있다.\n",
    "- 이는 Overfitting에 의해서 훈련 데이터에 너무 맞춰져있기 때문에 발생한 결과이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련, 검증 정확도 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc) + 1) # loss 개수 만큼 설정 epoch 개수를 설정\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc') # x축에 epochs 값으로, y축을 loss 값으로 설정\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation acc')\n",
    "plt.xlabel('Epochs') # 축 라벨을 Epochs로 설정\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 처음부터 다시 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 122us/step - loss: 0.4446 - accuracy: 0.8166\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 0.2560 - accuracy: 0.9093\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 167us/step - loss: 0.1988 - accuracy: 0.9292\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 125us/step - loss: 0.1697 - accuracy: 0.9398\n",
      "25000/25000 [==============================] - 5s 195us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.binary_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                   y_train,\n",
    "                   epochs=4,\n",
    "                   batch_size=512)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 결과: [0.2941011528635025, 0.8839200139045715]\n"
     ]
    }
   ],
   "source": [
    "print(\"최종 결과: {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최종 결과로 약 87%의 정확도를 달성하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. 훈련 모델로 새로운 데이터 에측하기\n",
    "\n",
    "- predict 메서드를 사용해서 리뷰의 확률을 예측 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11451009],\n",
       "       [0.9994111 ],\n",
       "       [0.7660862 ],\n",
       "       ...,\n",
       "       [0.09870643],\n",
       "       [0.05049237],\n",
       "       [0.503477  ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. 추가 실험\n",
    "\n",
    "- 3개의 은닉층 사용\n",
    "- 은닉 유닛 추가, 혹은 줄이기\n",
    "- mse 손실 함수 사용\n",
    "- tanh 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 123us/step - loss: 0.1231 - accuracy: 0.8301\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 0.0651 - accuracy: 0.9133\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 0.0522 - accuracy: 0.93300s - loss: 0.050\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 117us/step - loss: 0.0438 - accuracy: 0.94440s - loss: 0.0440 - accuracy\n",
      "25000/25000 [==============================] - 4s 175us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='tanh'))\n",
    "model.add(layers.Dense(32, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.MSE,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                   y_train,\n",
    "                   epochs=4,\n",
    "                   batch_size=512)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 결과: [0.09641224736481906, 0.8741199970245361]\n"
     ]
    }
   ],
   "source": [
    "print(\"최종 결과: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0307039 ],\n",
       "       [0.9979006 ],\n",
       "       [0.98188525],\n",
       "       ...,\n",
       "       [0.05815109],\n",
       "       [0.05104753],\n",
       "       [0.08186865]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. 정리\n",
    "\n",
    "- 원본 데이터를 신경망에 텐서로 주입하려면 전처리가 많이 필요하다.\n",
    "- 출력 클래스가 2개인 이진 분류 문제에서는 하나의 유닛과 sigmoid 함수를 가진 Dense 층으로 끝나야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 뉴스 기사 분류: 다중 분류 문제\n",
    "\n",
    "- 2개 이상의 클래스가 있을 때의 분류 문제\n",
    "- 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. 로이터 데이터셋\n",
    "\n",
    "- 1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽 집합\n",
    "- 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있다.\n",
    "- 어떤 토픽은 다른 것에 비해서 많은 데이터를 가지고 있다.\n",
    "\n",
    "\n",
    "### 로이터 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 8,982개의 훈련 샘플, 2,246개의 테스트 샘플\n",
    "- IMDB 리뷰처럼 각 샘플을 정수 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수: 8982\n",
      "테스트 데이터의 개수: 2246\n",
      "샘플의 예 : [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터의 개수: {}\".format(len(train_data)))\n",
    "print(\"테스트 데이터의 개수: {}\".format(len(test_data)))\n",
    "print(\"샘플의 예 : {}\".format(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 디코딩\n",
    "\n",
    "1. 단어와 인덱스가 저장 되어있는 딕셔너리 불러오기\n",
    "2. 딕셔너리의 키와 밸류를 get 메서드로 가져 오기 쉽게 위치 변경\n",
    "3. 데이터에 있는 문장을 띄어쓰기를 기준으로 나누어 get 메서드로 탐색 없는 경우 ?를 출력하게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번 train_data 내용: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "디코딩한 0 번 train_data 내용: ? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index() # 단어와 인덱스를 가지고 있는 딕셔너리 데이터 가져오기\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # 단어와 인덱스의 위치를 변경\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]]) # 0, 1, 2 는 패딩, 문서 시작, 사전에 없음을 위한 인덱스 임으로 뺴준다.\n",
    "\n",
    "print(\"0 번 train_data 내용: {}\".format(train_data[0]))\n",
    "print(\"디코딩한 0 번 train_data 내용: {}\".format(decoded_newswire))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2. 데이터 준비\n",
    "\n",
    "- 이전 예제와 동일한 코드를 사용하여 데이터를 벡터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. \n",
    "        \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이블 변경\n",
    "\n",
    "- 레이블 을 벡터로 변경하는 방법\n",
    "    1. 레이블 리스트를 정수 텐서로 변환\n",
    "    2. 원-핫 인코딩 사용\n",
    "    \n",
    "\n",
    "### 레이블을 원-핫 인코딩으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수로 원-핫 인코딩 구현\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i,label] = 1.\n",
    "        \n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 내장 함수를 사용하여 변경\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. 모델 구성\n",
    "\n",
    "- 출력 클래스가 총 46개\n",
    "- 16개의 차원은 46개의 클래스를 표현하기에는 제약이 많다.\n",
    "- 64개의 은닉 노드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax')) # 다중 분류이므로 softmax를 사용하여 각 클래스에 대해서 확률을 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델에서 사용할 손실 함수는 categoical_crossentropy이다. -> 다중 분류에서 사용되는 crossentropy\n",
    "- 위 손실 함수는 두 확률 분포 사이의 거리를 측정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. 훈련 검증\n",
    "\n",
    "- 1,000 개의 샘플을 따로 떼어서 검증 세트로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 완성한 모델을 epoch=20번 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 173us/step - loss: 2.5706 - accuracy: 0.4957 - val_loss: 1.7075 - val_accuracy: 0.6510\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 1.4014 - accuracy: 0.7116 - val_loss: 1.3063 - val_accuracy: 0.7290\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 1.0402 - accuracy: 0.7830 - val_loss: 1.1303 - val_accuracy: 0.7540\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.8244 - accuracy: 0.8250 - val_loss: 1.0299 - val_accuracy: 0.7770\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.6573 - accuracy: 0.8601 - val_loss: 0.9825 - val_accuracy: 0.7910\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.5313 - accuracy: 0.8894 - val_loss: 0.9494 - val_accuracy: 0.7920\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 197us/step - loss: 0.4301 - accuracy: 0.9089 - val_loss: 0.9161 - val_accuracy: 0.8070\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 185us/step - loss: 0.3493 - accuracy: 0.9285 - val_loss: 0.9397 - val_accuracy: 0.8020\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.2928 - accuracy: 0.9369 - val_loss: 0.9047 - val_accuracy: 0.8150\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.2446 - accuracy: 0.9458 - val_loss: 0.9361 - val_accuracy: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 0.2147 - accuracy: 0.9476 - val_loss: 1.0029 - val_accuracy: 0.8030\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.1875 - accuracy: 0.9531 - val_loss: 0.9241 - val_accuracy: 0.8220\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 0.1694 - accuracy: 0.9530 - val_loss: 0.9694 - val_accuracy: 0.8120\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 175us/step - loss: 0.1547 - accuracy: 0.9546 - val_loss: 0.9718 - val_accuracy: 0.8170\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.1404 - accuracy: 0.9567 - val_loss: 1.0047 - val_accuracy: 0.8030\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.1336 - accuracy: 0.9545 - val_loss: 1.0903 - val_accuracy: 0.7950\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.1251 - accuracy: 0.9578 - val_loss: 1.0863 - val_accuracy: 0.7940\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 156us/step - loss: 0.1225 - accuracy: 0.9558 - val_loss: 1.0967 - val_accuracy: 0.7990\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.1180 - accuracy: 0.9587 - val_loss: 1.1417 - val_accuracy: 0.7990\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.1139 - accuracy: 0.9564 - val_loss: 1.0599 - val_accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                    batch_size=512,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련과 검증 손실 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련과 검증 정확도 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # 그래프 초기화\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델은 대충 5번째 이후 과대적합이 발생\n",
    "\n",
    "\n",
    "### 7번의 epoch를 가진 새로운 모델 훈련 및 테스트 세트에서 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/7\n",
      "7982/7982 [==============================] - 1s 178us/step - loss: 2.7354 - accuracy: 0.5185 - val_loss: 1.8220 - val_accuracy: 0.6220\n",
      "Epoch 2/7\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 1.4858 - accuracy: 0.7031 - val_loss: 1.3274 - val_accuracy: 0.7150\n",
      "Epoch 3/7\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 1.0816 - accuracy: 0.7755 - val_loss: 1.1351 - val_accuracy: 0.7720\n",
      "Epoch 4/7\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.8462 - accuracy: 0.8245 - val_loss: 1.0356 - val_accuracy: 0.7850\n",
      "Epoch 5/7\n",
      "7982/7982 [==============================] - 1s 158us/step - loss: 0.6700 - accuracy: 0.8622 - val_loss: 0.9590 - val_accuracy: 0.7990\n",
      "Epoch 6/7\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.5350 - accuracy: 0.8874 - val_loss: 0.9278 - val_accuracy: 0.8090\n",
      "Epoch 7/7\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.4297 - accuracy: 0.9104 - val_loss: 0.8980 - val_accuracy: 0.8150\n",
      "2246/2246 [==============================] - 1s 244us/step\n",
      "최종 결과 : [0.971429357545671, 0.7898486256599426]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=7,\n",
    "                    batch_size=512,\n",
    "                   validation_data=(x_val, y_val))\n",
    "\n",
    "result = model.evaluate(x_test, one_hot_test_labels)\n",
    "\n",
    "print(\"최종 결과 : {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 테스트 셋의 정확도는 약 79% 정도로 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. 새로운 데이터에 대해 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction의 길이: (2246, 46)\n",
      "prediction의 원소들의 합: 0.9999999403953552\n",
      "prediction의 예측 클래스: 3\n"
     ]
    }
   ],
   "source": [
    "print('prediction의 길이: {}'.format(predictions.shape))\n",
    "print('prediction의 원소들의 합: {}'.format(np.sum(predictions[0])))\n",
    "print('prediction의 예측 클래스: {}'.format(np.argmax(predictions[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. 레이블과 손실을 다루는 다른 방법\n",
    "\n",
    "- 레이블을 인코딩하는 다른 방법을 소개\n",
    "- 바뀐 방법에 의한 사용해야 되는 손실 함수 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 텐서로 변환\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sparse_categorical_entropy 함수는 인터페이스만 다를 뿐 수학적으로는 같은 기능을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7. 충분히 큰 중간층을 두어야 하는 이유\n",
    "\n",
    "- 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어지만 안된다.\n",
    "- 만약 많이 작아진다면 정보의 병목이 일어날 수 있기 떄문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 171us/step - loss: 3.4515 - accuracy: 0.2028 - val_loss: 3.0879 - val_accuracy: 0.3600\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 2.8114 - accuracy: 0.3740 - val_loss: 2.5658 - val_accuracy: 0.3810\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 2.3215 - accuracy: 0.3926 - val_loss: 2.1787 - val_accuracy: 0.3920\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 1.9729 - accuracy: 0.4107 - val_loss: 1.9222 - val_accuracy: 0.4100\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 1.7243 - accuracy: 0.4817 - val_loss: 1.7370 - val_accuracy: 0.5610\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 1.5320 - accuracy: 0.6220 - val_loss: 1.6103 - val_accuracy: 0.5980\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 1.3848 - accuracy: 0.6498 - val_loss: 1.5279 - val_accuracy: 0.6160\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 1.2577 - accuracy: 0.6720 - val_loss: 1.4493 - val_accuracy: 0.6420\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 1.1621 - accuracy: 0.6932 - val_loss: 1.4264 - val_accuracy: 0.6390\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 1.0823 - accuracy: 0.7189 - val_loss: 1.3844 - val_accuracy: 0.6710\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 1.0122 - accuracy: 0.7488 - val_loss: 1.3629 - val_accuracy: 0.6800\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.9474 - accuracy: 0.7695 - val_loss: 1.3496 - val_accuracy: 0.6830\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.8926 - accuracy: 0.7821 - val_loss: 1.3387 - val_accuracy: 0.6970\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.8408 - accuracy: 0.7928 - val_loss: 1.3503 - val_accuracy: 0.6940\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.7952 - accuracy: 0.8052 - val_loss: 1.3499 - val_accuracy: 0.7050\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 159us/step - loss: 0.7542 - accuracy: 0.8177 - val_loss: 1.3522 - val_accuracy: 0.7030\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.7155 - accuracy: 0.8274 - val_loss: 1.3529 - val_accuracy: 0.7060\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.6814 - accuracy: 0.8336 - val_loss: 1.3536 - val_accuracy: 0.7000\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.6520 - accuracy: 0.8379 - val_loss: 1.3821 - val_accuracy: 0.7110\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.6209 - accuracy: 0.8421 - val_loss: 1.3813 - val_accuracy: 0.7140\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu')) # 중간의 히든 유닛이 4개로 변경됨\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                    batch_size=512,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 정확도가 78%에서 71%로 감소하였다.\n",
    "- 위와 같은 현상이 나타나는 이유는 많은 정보를 저차원 표현 공간으로 압축하려 했기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 주택 가격 예측: 회귀 문제\n",
    "\n",
    "- 회귀문제\n",
    "    - 개별적인 레이블 대신 연속적인 값을 예측하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. 보스턴 주택 가격 데이터셋\n",
    "\n",
    "- 506개의 데이터 셋\n",
    "- 404개의 훈련 샘플, 102개의 테스트 샘플\n",
    "- 입력 데이터에 있는 각 특성은 스케일이 서로 다르다.\n",
    "\n",
    "\n",
    "### 데이터 셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: (404, 13)\n",
      "테스트 데이터 크기: (102, 13)\n",
      "타겟 데이터: [15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1 17.9 23.1 19.9\n",
      " 15.7  8.8 50.  22.5 24.1 27.5 10.9 30.8 32.9 24.  18.5 13.3 22.9 34.7\n",
      " 16.6 17.5 22.3 16.1 14.9 23.1 34.9 25.  13.9 13.1 20.4 20.  15.2 24.7\n",
      " 22.2 16.7 12.7 15.6 18.4 21.  30.1 15.1 18.7  9.6 31.5 24.8 19.1 22.\n",
      " 14.5 11.  32.  29.4 20.3 24.4 14.6 19.5 14.1 14.3 15.6 10.5  6.3 19.3\n",
      " 19.3 13.4 36.4 17.8 13.5 16.5  8.3 14.3 16.  13.4 28.6 43.5 20.2 22.\n",
      " 23.  20.7 12.5 48.5 14.6 13.4 23.7 50.  21.7 39.8 38.7 22.2 34.9 22.5\n",
      " 31.1 28.7 46.  41.7 21.  26.6 15.  24.4 13.3 21.2 11.7 21.7 19.4 50.\n",
      " 22.8 19.7 24.7 36.2 14.2 18.9 18.3 20.6 24.6 18.2  8.7 44.  10.4 13.2\n",
      " 21.2 37.  30.7 22.9 20.  19.3 31.7 32.  23.1 18.8 10.9 50.  19.6  5.\n",
      " 14.4 19.8 13.8 19.6 23.9 24.5 25.  19.9 17.2 24.6 13.5 26.6 21.4 11.9\n",
      " 22.6 19.6  8.5 23.7 23.1 22.4 20.5 23.6 18.4 35.2 23.1 27.9 20.6 23.7\n",
      " 28.  13.6 27.1 23.6 20.6 18.2 21.7 17.1  8.4 25.3 13.8 22.2 18.4 20.7\n",
      " 31.6 30.5 20.3  8.8 19.2 19.4 23.1 23.  14.8 48.8 22.6 33.4 21.1 13.6\n",
      " 32.2 13.1 23.4 18.9 23.9 11.8 23.3 22.8 19.6 16.7 13.4 22.2 20.4 21.8\n",
      " 26.4 14.9 24.1 23.8 12.3 29.1 21.  19.5 23.3 23.8 17.8 11.5 21.7 19.9\n",
      " 25.  33.4 28.5 21.4 24.3 27.5 33.1 16.2 23.3 48.3 22.9 22.8 13.1 12.7\n",
      " 22.6 15.  15.3 10.5 24.  18.5 21.7 19.5 33.2 23.2  5.  19.1 12.7 22.3\n",
      " 10.2 13.9 16.3 17.  20.1 29.9 17.2 37.3 45.4 17.8 23.2 29.  22.  18.\n",
      " 17.4 34.6 20.1 25.  15.6 24.8 28.2 21.2 21.4 23.8 31.  26.2 17.4 37.9\n",
      " 17.5 20.   8.3 23.9  8.4 13.8  7.2 11.7 17.1 21.6 50.  16.1 20.4 20.6\n",
      " 21.4 20.6 36.5  8.5 24.8 10.8 21.9 17.3 18.9 36.2 14.9 18.2 33.3 21.8\n",
      " 19.7 31.6 24.8 19.4 22.8  7.5 44.8 16.8 18.7 50.  50.  19.5 20.1 50.\n",
      " 17.2 20.8 19.3 41.3 20.4 20.5 13.8 16.5 23.9 20.6 31.5 23.3 16.8 14.\n",
      " 33.8 36.1 12.8 18.3 18.7 19.1 29.  30.1 50.  50.  22.  11.9 37.6 50.\n",
      " 22.7 20.8 23.5 27.9 50.  19.3 23.9 22.6 15.2 21.7 19.2 43.8 20.3 33.2\n",
      " 19.9 22.5 32.7 22.  17.1 19.  15.  16.1 25.1 23.7 28.7 37.2 22.6 16.4\n",
      " 25.  29.8 22.1 17.4 18.1 30.3 17.5 24.7 12.6 26.5 28.7 13.3 10.4 24.4\n",
      " 23.  20.  17.8  7.  11.8 24.4 13.8 19.4 25.2 19.4 19.4 29.1]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "print(\"훈련 데이터 크기: {}\".format(train_data.shape))\n",
    "print(\"테스트 데이터 크기: {}\".format(test_data.shape))\n",
    "print(\"타겟 데이터: {}\".format(train_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. 데이터 준비\n",
    "\n",
    "- 서로 다른 데이터 스캐일을 입력 데이터로하면 문제가 생김\n",
    "- 이런 문제점을 해결하기 위해서 특성별로 정규화를 진행\n",
    "\n",
    "\n",
    "- 정규화 방법\n",
    "    - 각 특성에 대해서 특성의 평균을 빼고 표준 편차로 나눈다.\n",
    "    - 이러한 방법을 쓰면 특성의 중앙이 0근처에 맞추어지고 표준 편차가 1이 된다.\n",
    "    - 이 방법은 밑바닥부터 시작하는 딥러닝에 자세히 서술 되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0) # 입력 데이터의 첫 번째 축을 기준으로 평균을 구한다. -> 첫 번째 축은 각 특성들이다.\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0) # 표준 편차를 구함\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터를 정규화할 때 사용한 값은 훈련 데이터에서 계산한 값이다.\n",
    "- 작업 과정에서 테스트 데이터에서 계산한 어떤 값도 사용하면 안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. 모델 구성\n",
    "\n",
    "- 샘플 개수가 적기 때문에 64개의 유닛을 가진 2개의 은닉 층으로 작은 네트워크 구성\n",
    "- 샘플 개수가 작을 때 작은 네트워크를 사용하는것은 오버 피팅을 피하는 한가지 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                          input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='mse',\n",
    "                 metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막 층에는 활성화 함수가 사용되지 않았다.\n",
    "    - 이 모델은 순수한 선형값을 출력하므로 값을 제한하는 활성화 함수를 사용하지 않는다.\n",
    "    \n",
    "    \n",
    "- 손실 함수로는 mse(평균 제곱 오차)를 사용했다.\n",
    "    - 회귀 문제에서 널리 사용되며 예측값과 타깃 값 사이의 거리의 절대값을 줄이는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. K-겹 검증을 사용한 훈련 검증\n",
    "\n",
    "- 훈련에 사용하는 데이터가 너무 적으면 과대 적합이 될 가능성이 매우 높다.\n",
    "- 따라서 이를 k개로 나누어서 그 중 한개를 검증 데이터로 사용하고, 이를 k 번 반복하여 평균을 내는 방법이다.\n",
    "\n",
    "\n",
    "- k-겹 검증의 예시\n",
    "![k_fold](./images/kfold.jpg)\n",
    "\n",
    "\n",
    "### K-겹 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 212.6824 - mae: 10.7864 - val_loss: 35.7141 - val_mae: 3.9395\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 29.0113 - mae: 3.8039 - val_loss: 21.6640 - val_mae: 3.2911\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 20.6542 - mae: 3.1868 - val_loss: 16.2293 - val_mae: 2.5520\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 17.3474 - mae: 2.8712 - val_loss: 17.4805 - val_mae: 3.1770\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 15.3951 - mae: 2.7805 - val_loss: 15.5781 - val_mae: 2.4625\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 15.0220 - mae: 2.6183 - val_loss: 13.5774 - val_mae: 2.4183\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 14.2783 - mae: 2.5011 - val_loss: 11.7695 - val_mae: 2.2969\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 13.3065 - mae: 2.4259 - val_loss: 11.3395 - val_mae: 2.2862\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 12.8322 - mae: 2.4307 - val_loss: 12.9432 - val_mae: 2.6473\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.2721 - mae: 2.3535 - val_loss: 13.2173 - val_mae: 2.6127\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.8530 - mae: 2.2625 - val_loss: 11.7115 - val_mae: 2.5459\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.3828 - mae: 2.2732 - val_loss: 10.3105 - val_mae: 2.1148\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.2143 - mae: 2.2688 - val_loss: 10.1140 - val_mae: 2.1108\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.3277 - mae: 2.2936 - val_loss: 9.7474 - val_mae: 2.1469\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.5677 - mae: 2.2010 - val_loss: 10.9253 - val_mae: 2.1635\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.6871 - mae: 2.0960 - val_loss: 10.6576 - val_mae: 2.3876\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.5497 - mae: 2.1759 - val_loss: 10.7759 - val_mae: 2.3769\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.2295 - mae: 2.1314 - val_loss: 10.9518 - val_mae: 2.2517\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.0405 - mae: 2.0822 - val_loss: 9.2044 - val_mae: 2.0447\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.1187 - mae: 2.0843 - val_loss: 9.9048 - val_mae: 2.3848\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.8842 - mae: 2.0514 - val_loss: 9.0557 - val_mae: 1.9297\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.0069 - mae: 2.0432 - val_loss: 10.0137 - val_mae: 2.1753\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.8718 - mae: 2.0211 - val_loss: 9.4280 - val_mae: 1.9334\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.6559 - mae: 1.9571 - val_loss: 9.5104 - val_mae: 1.9030\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.5238 - mae: 1.9613 - val_loss: 9.3839 - val_mae: 2.0072\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.3015 - mae: 1.9636 - val_loss: 8.2053 - val_mae: 1.8775\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.1867 - mae: 1.9280 - val_loss: 10.5571 - val_mae: 2.1701\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.1113 - mae: 1.9625 - val_loss: 8.8768 - val_mae: 2.0876\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9714 - mae: 1.9793 - val_loss: 9.3952 - val_mae: 1.9100\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.2914 - mae: 1.9494 - val_loss: 8.6355 - val_mae: 2.0416\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.2429 - mae: 1.8260 - val_loss: 8.9386 - val_mae: 1.9381\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.7798 - mae: 1.8794 - val_loss: 9.0051 - val_mae: 2.0651\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.2345 - mae: 1.9267 - val_loss: 8.2929 - val_mae: 1.8650\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.3592 - mae: 1.8544 - val_loss: 9.2008 - val_mae: 1.9018\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.7776 - mae: 1.8933 - val_loss: 10.4387 - val_mae: 2.3098\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.2778 - mae: 1.8092 - val_loss: 8.2065 - val_mae: 1.9521\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.2105 - mae: 1.8576 - val_loss: 7.8108 - val_mae: 1.7604\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8961 - mae: 1.8054 - val_loss: 9.7058 - val_mae: 2.2389\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.9744 - mae: 1.7950 - val_loss: 8.6007 - val_mae: 2.0505\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8367 - mae: 1.8117 - val_loss: 9.0981 - val_mae: 2.0863\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.9183 - mae: 1.8295 - val_loss: 8.0617 - val_mae: 1.7211\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.8094 - mae: 1.7868 - val_loss: 8.0449 - val_mae: 1.8400\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8403 - mae: 1.8513 - val_loss: 7.8419 - val_mae: 1.9070\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.3356 - mae: 1.7424 - val_loss: 10.0233 - val_mae: 2.2388\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.4449 - mae: 1.7522 - val_loss: 8.9250 - val_mae: 2.0829\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.2462 - mae: 1.7156 - val_loss: 8.6713 - val_mae: 1.9985\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.1521 - mae: 1.7184 - val_loss: 8.6592 - val_mae: 2.0335\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.0995 - mae: 1.7276 - val_loss: 9.5056 - val_mae: 2.1431\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.0881 - mae: 1.7541 - val_loss: 8.0400 - val_mae: 1.7266\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.3346 - mae: 1.7477 - val_loss: 7.8702 - val_mae: 1.9301\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.8192 - mae: 1.7253 - val_loss: 11.4289 - val_mae: 2.2443\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.7501 - mae: 1.6708 - val_loss: 11.2503 - val_mae: 2.0925\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.2557 - mae: 1.6508 - val_loss: 9.2647 - val_mae: 2.1865\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.7714 - mae: 1.6539 - val_loss: 9.6513 - val_mae: 2.1537\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.4408 - mae: 1.6580 - val_loss: 8.8148 - val_mae: 1.8341\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.7361 - mae: 1.6641 - val_loss: 8.9281 - val_mae: 1.9834\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.0537 - mae: 1.6939 - val_loss: 8.5255 - val_mae: 2.0579\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.4268 - mae: 1.6286 - val_loss: 8.9126 - val_mae: 2.1574\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.6440 - mae: 1.6093 - val_loss: 9.1640 - val_mae: 1.9114\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.3156 - mae: 1.6138 - val_loss: 9.1973 - val_mae: 2.1500\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1532 - mae: 1.5909 - val_loss: 8.7565 - val_mae: 1.9500\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.0981 - mae: 1.5953 - val_loss: 9.5242 - val_mae: 2.3306\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.4944 - mae: 1.6123 - val_loss: 9.2905 - val_mae: 2.1409\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.3555 - mae: 1.5821 - val_loss: 8.1460 - val_mae: 1.8597\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2413 - mae: 1.6373 - val_loss: 9.7485 - val_mae: 2.3040\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8785 - mae: 1.6485 - val_loss: 7.4815 - val_mae: 1.9688\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1411 - mae: 1.5342 - val_loss: 9.1457 - val_mae: 2.2325\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2115 - mae: 1.6006 - val_loss: 8.1281 - val_mae: 2.0539\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.5740 - mae: 1.5868 - val_loss: 7.8032 - val_mae: 1.9737\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.9402 - mae: 1.5765 - val_loss: 8.3959 - val_mae: 2.0734\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.5250 - mae: 1.5811 - val_loss: 10.3282 - val_mae: 2.4543\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.9784 - mae: 1.5459 - val_loss: 8.3291 - val_mae: 1.9120\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.8876 - mae: 1.5646 - val_loss: 9.0054 - val_mae: 1.9741\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7451 - mae: 1.5566 - val_loss: 9.0572 - val_mae: 2.2649\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.3775 - mae: 1.5854 - val_loss: 8.7725 - val_mae: 2.0293\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.5631 - mae: 1.5491 - val_loss: 10.1395 - val_mae: 2.1822\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8307 - mae: 1.5358 - val_loss: 8.2218 - val_mae: 1.9526\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8240 - mae: 1.5606 - val_loss: 8.3422 - val_mae: 1.9471\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4173 - mae: 1.5294 - val_loss: 8.8085 - val_mae: 2.1370\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.2381 - mae: 1.4958 - val_loss: 8.5932 - val_mae: 1.9351\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4349 - mae: 1.5303 - val_loss: 9.4287 - val_mae: 2.3812\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.4552 - mae: 1.5003 - val_loss: 9.0122 - val_mae: 2.1947\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.2501 - mae: 1.4681 - val_loss: 8.0265 - val_mae: 2.0274\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.9657 - mae: 1.4751 - val_loss: 8.0548 - val_mae: 2.0035\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0570 - mae: 1.5074 - val_loss: 7.7250 - val_mae: 1.8694\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.1958 - mae: 1.4812 - val_loss: 10.1576 - val_mae: 2.3279\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7597 - mae: 1.4708 - val_loss: 9.4193 - val_mae: 2.3667\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1386 - mae: 1.4712 - val_loss: 11.1386 - val_mae: 2.6044\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.5318 - mae: 1.5141 - val_loss: 8.9751 - val_mae: 2.0454\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0533 - mae: 1.4389 - val_loss: 8.5963 - val_mae: 2.0597\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3334 - mae: 1.4895 - val_loss: 8.0830 - val_mae: 2.0122\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8603 - mae: 1.4914 - val_loss: 8.9688 - val_mae: 2.1188\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.0728 - mae: 1.4552 - val_loss: 7.8375 - val_mae: 2.0460\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1179 - mae: 1.4732 - val_loss: 9.4112 - val_mae: 2.4418\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.7375 - mae: 1.4554 - val_loss: 8.9867 - val_mae: 1.9872\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8733 - mae: 1.5140 - val_loss: 8.2414 - val_mae: 1.9696\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.4268 - mae: 1.3765 - val_loss: 12.6061 - val_mae: 2.6580\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.9553 - mae: 1.4750 - val_loss: 8.1179 - val_mae: 1.9823\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.5485 - mae: 1.3884 - val_loss: 9.9606 - val_mae: 2.5034\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.4307 - mae: 1.4507 - val_loss: 8.2442 - val_mae: 2.0165\n",
      "처리중인 폴드 # 1\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 238.8348 - mae: 11.4868 - val_loss: 27.7727 - val_mae: 3.9879\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 27.9038 - mae: 3.3544 - val_loss: 16.8855 - val_mae: 3.0928\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 19.1962 - mae: 2.8758 - val_loss: 17.6257 - val_mae: 3.1824\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 15.7200 - mae: 2.5699 - val_loss: 14.4380 - val_mae: 2.9395\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 13.8175 - mae: 2.4226 - val_loss: 13.8088 - val_mae: 2.9465\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 12.5651 - mae: 2.3446 - val_loss: 13.9673 - val_mae: 2.9276\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 12.4126 - mae: 2.2801 - val_loss: 13.4355 - val_mae: 2.9137\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.8420 - mae: 2.2924 - val_loss: 13.0722 - val_mae: 2.8277\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.5406 - mae: 2.2699 - val_loss: 12.8736 - val_mae: 2.8007\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.0055 - mae: 2.1479 - val_loss: 11.3180 - val_mae: 2.6085\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.5320 - mae: 2.1553 - val_loss: 10.7246 - val_mae: 2.5683\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.5618 - mae: 2.1047 - val_loss: 15.5607 - val_mae: 3.1064\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.0834 - mae: 2.0632 - val_loss: 11.4626 - val_mae: 2.5242\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.0957 - mae: 2.0892 - val_loss: 11.4235 - val_mae: 2.6435\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.7670 - mae: 2.0545 - val_loss: 11.3985 - val_mae: 2.6783\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.6133 - mae: 2.0454 - val_loss: 12.9124 - val_mae: 2.7812\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.3466 - mae: 1.9945 - val_loss: 12.2070 - val_mae: 2.7326\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.8871 - mae: 1.9418 - val_loss: 13.1418 - val_mae: 2.8029\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.2002 - mae: 2.0276 - val_loss: 11.6496 - val_mae: 2.6621\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.9216 - mae: 2.0110 - val_loss: 12.8930 - val_mae: 2.7750\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 9.0820 - mae: 2.0080 - val_loss: 11.1238 - val_mae: 2.5629\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.8304 - mae: 1.9688 - val_loss: 13.7528 - val_mae: 2.8780\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.6346 - mae: 1.9371 - val_loss: 11.2744 - val_mae: 2.5787\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.5104 - mae: 1.9102 - val_loss: 12.2124 - val_mae: 2.7111\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0943 - mae: 1.9081 - val_loss: 10.8469 - val_mae: 2.4710\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.3323 - mae: 1.8730 - val_loss: 12.7059 - val_mae: 2.7576\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.3219 - mae: 1.8802 - val_loss: 14.1493 - val_mae: 2.9101\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.9599 - mae: 1.8682 - val_loss: 10.4991 - val_mae: 2.4970\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.8831 - mae: 1.8748 - val_loss: 12.8382 - val_mae: 2.7468\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.1670 - mae: 1.8403 - val_loss: 11.2911 - val_mae: 2.5843\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.9732 - mae: 1.7922 - val_loss: 13.0164 - val_mae: 2.7691\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.6809 - mae: 1.8534 - val_loss: 13.0652 - val_mae: 2.7822\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.7792 - mae: 1.7871 - val_loss: 11.8934 - val_mae: 2.6461\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.7747 - mae: 1.8131 - val_loss: 11.8214 - val_mae: 2.6251\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.4340 - mae: 1.7632 - val_loss: 10.8258 - val_mae: 2.5091\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.6865 - mae: 1.8294 - val_loss: 11.9899 - val_mae: 2.6809\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.2288 - mae: 1.7216 - val_loss: 12.0504 - val_mae: 2.6883\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.4050 - mae: 1.7067 - val_loss: 11.0543 - val_mae: 2.5177\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.9051 - mae: 1.7308 - val_loss: 10.4036 - val_mae: 2.4417\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.3551 - mae: 1.7410 - val_loss: 12.6355 - val_mae: 2.6594\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.8566 - mae: 1.6808 - val_loss: 12.9042 - val_mae: 2.7920\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.3095 - mae: 1.6926 - val_loss: 11.9370 - val_mae: 2.6522\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.0374 - mae: 1.7814 - val_loss: 10.9801 - val_mae: 2.4837\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.6378 - mae: 1.6871 - val_loss: 11.1932 - val_mae: 2.5609\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.7080 - mae: 1.6994 - val_loss: 13.0731 - val_mae: 2.6797\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.2798 - mae: 1.6577 - val_loss: 13.5394 - val_mae: 2.7328\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.6550 - mae: 1.7047 - val_loss: 11.2898 - val_mae: 2.4720\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.2843 - mae: 1.5990 - val_loss: 10.2405 - val_mae: 2.4213\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.3782 - mae: 1.7217 - val_loss: 11.7210 - val_mae: 2.5422\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.8752 - mae: 1.6031 - val_loss: 11.9243 - val_mae: 2.6052\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.1523 - mae: 1.6269 - val_loss: 15.4109 - val_mae: 2.9208\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.1846 - mae: 1.6498 - val_loss: 11.6783 - val_mae: 2.4880\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.9475 - mae: 1.6643 - val_loss: 13.6696 - val_mae: 2.7189\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.9963 - mae: 1.6159 - val_loss: 14.0455 - val_mae: 2.6219\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.8975 - mae: 1.6007 - val_loss: 16.3128 - val_mae: 2.9241\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.7182 - mae: 1.5610 - val_loss: 11.7777 - val_mae: 2.5015\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.7731 - mae: 1.5316 - val_loss: 11.8527 - val_mae: 2.5205\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.6475 - mae: 1.5369 - val_loss: 13.3733 - val_mae: 2.5983\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3290 - mae: 1.5577 - val_loss: 13.0215 - val_mae: 2.6694\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.5013 - mae: 1.5512 - val_loss: 12.6424 - val_mae: 2.5019\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.6448 - mae: 1.5574 - val_loss: 11.3076 - val_mae: 2.4077\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.4501 - mae: 1.5408 - val_loss: 10.6087 - val_mae: 2.3475\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.2120 - mae: 1.5187 - val_loss: 11.6757 - val_mae: 2.4481\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.5006 - mae: 1.4403 - val_loss: 14.6794 - val_mae: 2.8890\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1300 - mae: 1.5407 - val_loss: 13.5505 - val_mae: 2.7142\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.7024 - mae: 1.4573 - val_loss: 14.0926 - val_mae: 2.6403\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1584 - mae: 1.4907 - val_loss: 14.2722 - val_mae: 2.7650\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.9860 - mae: 1.4488 - val_loss: 14.5915 - val_mae: 2.6607\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.3042 - mae: 1.5135 - val_loss: 15.6662 - val_mae: 2.7007\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.7726 - mae: 1.4113 - val_loss: 12.9834 - val_mae: 2.5627\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.1700 - mae: 1.4981 - val_loss: 11.7689 - val_mae: 2.4318\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.8799 - mae: 1.4628 - val_loss: 11.9970 - val_mae: 2.5731\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.9023 - mae: 1.4807 - val_loss: 13.2820 - val_mae: 2.4562\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.8697 - mae: 1.4936 - val_loss: 15.3946 - val_mae: 2.6806\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.1159 - mae: 1.4771 - val_loss: 14.1252 - val_mae: 2.4793\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6433 - mae: 1.4783 - val_loss: 13.9407 - val_mae: 2.6612\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.4891 - mae: 1.4057 - val_loss: 14.0777 - val_mae: 2.5279\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.7053 - mae: 1.4772 - val_loss: 14.4899 - val_mae: 2.7076\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.6282 - mae: 1.5120 - val_loss: 13.8058 - val_mae: 2.5570\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.6763 - mae: 1.4396 - val_loss: 17.4956 - val_mae: 3.0172\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.7074 - mae: 1.4559 - val_loss: 11.7898 - val_mae: 2.4253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5724 - mae: 1.4172 - val_loss: 15.4558 - val_mae: 2.7504\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.1686 - mae: 1.4149 - val_loss: 14.2928 - val_mae: 2.5201\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7395 - mae: 1.4415 - val_loss: 13.1784 - val_mae: 2.3851\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.5112 - mae: 1.3805 - val_loss: 16.4868 - val_mae: 2.7102\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.0615 - mae: 1.3265 - val_loss: 14.1165 - val_mae: 2.5150\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.2858 - mae: 1.4036 - val_loss: 14.7356 - val_mae: 2.5102\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.2126 - mae: 1.4238 - val_loss: 13.6752 - val_mae: 2.4810\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1402 - mae: 1.3797 - val_loss: 14.0713 - val_mae: 2.5570\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.2153 - mae: 1.3674 - val_loss: 14.0626 - val_mae: 2.5403\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.8557 - mae: 1.3400 - val_loss: 19.4574 - val_mae: 2.9624\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.6022 - mae: 1.3218 - val_loss: 17.2860 - val_mae: 2.6225\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1121 - mae: 1.3395 - val_loss: 22.3115 - val_mae: 2.9366\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.1092 - mae: 1.3344 - val_loss: 21.4730 - val_mae: 2.8884\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0871 - mae: 1.3488 - val_loss: 14.8042 - val_mae: 2.5274\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.7871 - mae: 1.2811 - val_loss: 19.9903 - val_mae: 2.9298\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7851 - mae: 1.2427 - val_loss: 19.6259 - val_mae: 2.8613\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.1956 - mae: 1.3792 - val_loss: 18.7893 - val_mae: 2.9625\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9618 - mae: 1.3303 - val_loss: 16.6353 - val_mae: 2.7302\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.6338 - mae: 1.2864 - val_loss: 17.7761 - val_mae: 2.7033\n",
      "처리중인 폴드 # 2\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 203.2229 - mae: 10.3910 - val_loss: 41.1655 - val_mae: 4.4373\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 31.4219 - mae: 3.8552 - val_loss: 26.2867 - val_mae: 3.6502\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 20.7299 - mae: 3.2055 - val_loss: 20.0384 - val_mae: 2.8357\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 16.8693 - mae: 2.8730 - val_loss: 19.2394 - val_mae: 2.9446\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 14.4115 - mae: 2.6689 - val_loss: 17.4086 - val_mae: 2.6542\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 12.7138 - mae: 2.4567 - val_loss: 16.2234 - val_mae: 2.6733\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.4232 - mae: 2.3392 - val_loss: 15.6302 - val_mae: 2.5660\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.1047 - mae: 2.2650 - val_loss: 15.2075 - val_mae: 2.5613\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.3543 - mae: 2.2449 - val_loss: 15.6706 - val_mae: 2.6564\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.5446 - mae: 2.1807 - val_loss: 15.4722 - val_mae: 2.5478\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.2657 - mae: 2.1139 - val_loss: 16.1066 - val_mae: 2.6546\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.0257 - mae: 2.1081 - val_loss: 14.7836 - val_mae: 2.5278\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.7035 - mae: 2.1264 - val_loss: 14.1641 - val_mae: 2.5498\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.4309 - mae: 2.0158 - val_loss: 16.1353 - val_mae: 2.5522\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.6981 - mae: 2.0424 - val_loss: 14.5882 - val_mae: 2.5925\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.9755 - mae: 1.9749 - val_loss: 14.8376 - val_mae: 2.4561\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.0216 - mae: 1.9768 - val_loss: 15.7301 - val_mae: 2.6988\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.4803 - mae: 1.9203 - val_loss: 16.2342 - val_mae: 2.6123\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.6398 - mae: 1.8659 - val_loss: 14.9403 - val_mae: 2.5588\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.9604 - mae: 1.9192 - val_loss: 14.3439 - val_mae: 2.4188\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.0318 - mae: 1.8962 - val_loss: 13.3070 - val_mae: 2.3848\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.3129 - mae: 1.8953 - val_loss: 14.7730 - val_mae: 2.6394\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5970 - mae: 1.8588 - val_loss: 14.8711 - val_mae: 2.5938\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.0741 - mae: 1.8243 - val_loss: 14.7884 - val_mae: 2.4219\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.0465 - mae: 1.8391 - val_loss: 14.2409 - val_mae: 2.5114\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.8013 - mae: 1.7968 - val_loss: 14.3609 - val_mae: 2.4600\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.9504 - mae: 1.8289 - val_loss: 14.8047 - val_mae: 2.6126\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.6004 - mae: 1.8215 - val_loss: 14.7763 - val_mae: 2.5405\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1522 - mae: 1.8140 - val_loss: 18.1700 - val_mae: 2.8866\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.6255 - mae: 1.7233 - val_loss: 14.6677 - val_mae: 2.4884\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.3945 - mae: 1.7442 - val_loss: 14.9947 - val_mae: 2.5222\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.5113 - mae: 1.7279 - val_loss: 13.9394 - val_mae: 2.5202\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.9574 - mae: 1.7268 - val_loss: 14.9726 - val_mae: 2.6641\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.9720 - mae: 1.6496 - val_loss: 18.1362 - val_mae: 3.1342\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.8331 - mae: 1.6810 - val_loss: 14.8010 - val_mae: 2.4806\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.8632 - mae: 1.6868 - val_loss: 17.2961 - val_mae: 2.9311\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.8354 - mae: 1.6997 - val_loss: 13.9369 - val_mae: 2.5773\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.0436 - mae: 1.7149 - val_loss: 14.9557 - val_mae: 2.5881\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.7367 - mae: 1.7065 - val_loss: 14.2841 - val_mae: 2.4960\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.8923 - mae: 1.6763 - val_loss: 14.3745 - val_mae: 2.4473\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7095 - mae: 1.6318 - val_loss: 15.6770 - val_mae: 2.8160\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 2s 8ms/step - loss: 5.6710 - mae: 1.6567 - val_loss: 14.7099 - val_mae: 2.6983\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.3858 - mae: 1.6353 - val_loss: 15.6428 - val_mae: 2.6580\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6065 - mae: 1.6379 - val_loss: 16.3400 - val_mae: 2.8743\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.4872 - mae: 1.6673 - val_loss: 14.3847 - val_mae: 2.5381\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4785 - mae: 1.5809 - val_loss: 15.5045 - val_mae: 2.7961\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.2727 - mae: 1.5909 - val_loss: 15.1378 - val_mae: 2.6355\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.4307 - mae: 1.6473 - val_loss: 15.2929 - val_mae: 2.6520\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.1303 - mae: 1.6152 - val_loss: 15.1957 - val_mae: 2.5505\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3105 - mae: 1.6159 - val_loss: 14.9695 - val_mae: 2.6414\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.1994 - mae: 1.5685 - val_loss: 14.5619 - val_mae: 2.5938\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1360 - mae: 1.6222 - val_loss: 14.8725 - val_mae: 2.6529\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.5984 - mae: 1.5087 - val_loss: 15.4670 - val_mae: 2.5971\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1558 - mae: 1.5888 - val_loss: 14.4412 - val_mae: 2.5649\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.9827 - mae: 1.5208 - val_loss: 16.1639 - val_mae: 2.8798\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.9637 - mae: 1.5466 - val_loss: 14.4986 - val_mae: 2.6241\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 4.9990 - mae: 1.5682 - val_loss: 13.4767 - val_mae: 2.4781\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.4851 - mae: 1.5547 - val_loss: 13.3767 - val_mae: 2.4927\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.6723 - mae: 1.4802 - val_loss: 14.5369 - val_mae: 2.4893\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.3441 - mae: 1.5001 - val_loss: 15.2070 - val_mae: 2.7760\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.6972 - mae: 1.5560 - val_loss: 13.5261 - val_mae: 2.5422\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.9213 - mae: 1.5230 - val_loss: 15.1680 - val_mae: 2.6023\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.5617 - mae: 1.4927 - val_loss: 15.5168 - val_mae: 2.6513\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5530 - mae: 1.5079 - val_loss: 13.7358 - val_mae: 2.5520\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.2845 - mae: 1.4990 - val_loss: 13.4431 - val_mae: 2.4577\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3965 - mae: 1.4624 - val_loss: 14.0288 - val_mae: 2.5360\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6665 - mae: 1.5158 - val_loss: 14.6202 - val_mae: 2.5901\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1247 - mae: 1.4216 - val_loss: 14.7440 - val_mae: 2.6591\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1346 - mae: 1.4613 - val_loss: 14.8861 - val_mae: 2.6178\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2768 - mae: 1.4562 - val_loss: 14.9672 - val_mae: 2.5842\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2128 - mae: 1.4269 - val_loss: 14.3775 - val_mae: 2.5267\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8971 - mae: 1.3956 - val_loss: 18.1128 - val_mae: 2.8624\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2169 - mae: 1.4323 - val_loss: 15.2478 - val_mae: 2.6056\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8306 - mae: 1.3776 - val_loss: 15.7868 - val_mae: 2.7320\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8295 - mae: 1.3574 - val_loss: 14.9854 - val_mae: 2.6437\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8510 - mae: 1.3817 - val_loss: 14.2008 - val_mae: 2.5257\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7410 - mae: 1.3939 - val_loss: 14.4336 - val_mae: 2.6302\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8212 - mae: 1.4467 - val_loss: 14.3233 - val_mae: 2.5562\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7471 - mae: 1.3932 - val_loss: 14.1812 - val_mae: 2.5498\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5545 - mae: 1.3049 - val_loss: 13.9477 - val_mae: 2.5475\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6173 - mae: 1.3716 - val_loss: 14.3552 - val_mae: 2.6447\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7041 - mae: 1.3656 - val_loss: 15.2553 - val_mae: 2.7397\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5236 - mae: 1.3190 - val_loss: 13.9972 - val_mae: 2.5449\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4302 - mae: 1.3092 - val_loss: 14.4035 - val_mae: 2.6323\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3762 - mae: 1.2923 - val_loss: 13.7274 - val_mae: 2.5627\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5386 - mae: 1.3041 - val_loss: 15.2314 - val_mae: 2.6817\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5401 - mae: 1.3379 - val_loss: 13.7976 - val_mae: 2.5147\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4248 - mae: 1.3288 - val_loss: 15.2831 - val_mae: 2.6927\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2232 - mae: 1.2962 - val_loss: 13.4351 - val_mae: 2.4828\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5077 - mae: 1.3277 - val_loss: 13.3018 - val_mae: 2.5201\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0858 - mae: 1.2629 - val_loss: 16.2360 - val_mae: 2.8720\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9581 - mae: 1.2425 - val_loss: 16.5404 - val_mae: 2.7529\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3119 - mae: 1.3365 - val_loss: 13.8492 - val_mae: 2.5420\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2176 - mae: 1.2925 - val_loss: 14.1415 - val_mae: 2.5665\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1177 - mae: 1.3109 - val_loss: 13.9588 - val_mae: 2.5562\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1079 - mae: 1.2723 - val_loss: 13.9715 - val_mae: 2.5622\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9036 - mae: 1.2199 - val_loss: 13.5905 - val_mae: 2.5219\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1105 - mae: 1.2366 - val_loss: 13.9520 - val_mae: 2.6600\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1941 - mae: 1.2485 - val_loss: 15.1709 - val_mae: 2.6936\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8598 - mae: 1.2426 - val_loss: 14.9014 - val_mae: 2.6543\n",
      "처리중인 폴드 # 3\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 177.0722 - mae: 10.0144 - val_loss: 73.4284 - val_mae: 6.2544\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 29.3086 - mae: 3.6063 - val_loss: 38.6361 - val_mae: 4.0614\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 20.3175 - mae: 2.9676 - val_loss: 32.2692 - val_mae: 3.5647\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 16.3524 - mae: 2.6906 - val_loss: 28.4570 - val_mae: 3.2813\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 14.9305 - mae: 2.4688 - val_loss: 24.8676 - val_mae: 3.3314\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 14.1419 - mae: 2.4670 - val_loss: 22.9446 - val_mae: 3.0128\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.7610 - mae: 2.3921 - val_loss: 22.8776 - val_mae: 2.8375\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.1891 - mae: 2.1912 - val_loss: 23.4108 - val_mae: 2.9287\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.9071 - mae: 2.2511 - val_loss: 23.1733 - val_mae: 2.8463\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.6017 - mae: 2.1184 - val_loss: 18.6466 - val_mae: 2.7390\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.0654 - mae: 2.1340 - val_loss: 19.0241 - val_mae: 2.9567\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.9617 - mae: 2.0821 - val_loss: 18.4827 - val_mae: 2.8607\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.5507 - mae: 2.0719 - val_loss: 18.4599 - val_mae: 2.6973\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.6635 - mae: 2.0930 - val_loss: 17.2765 - val_mae: 2.5750\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.8619 - mae: 1.9859 - val_loss: 17.0247 - val_mae: 2.6851\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.3734 - mae: 1.9638 - val_loss: 17.3097 - val_mae: 2.5273\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.4604 - mae: 2.0160 - val_loss: 17.1993 - val_mae: 2.5010\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.6095 - mae: 1.9252 - val_loss: 21.8240 - val_mae: 3.3701\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.6105 - mae: 1.9007 - val_loss: 17.1767 - val_mae: 2.6540\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.7347 - mae: 1.9164 - val_loss: 15.4741 - val_mae: 2.5797\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.3657 - mae: 1.8521 - val_loss: 15.8554 - val_mae: 2.5954\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0522 - mae: 1.9297 - val_loss: 15.2311 - val_mae: 2.5218\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.4227 - mae: 1.8530 - val_loss: 15.0117 - val_mae: 2.6173\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.9571 - mae: 1.8557 - val_loss: 15.5266 - val_mae: 2.5285\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0389 - mae: 1.8820 - val_loss: 15.1015 - val_mae: 2.5008\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0965 - mae: 1.7926 - val_loss: 16.1593 - val_mae: 2.7656\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8277 - mae: 1.8019 - val_loss: 14.9389 - val_mae: 2.5904\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5057 - mae: 1.7400 - val_loss: 13.9997 - val_mae: 2.5296\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.3089 - mae: 1.8430 - val_loss: 13.8914 - val_mae: 2.5127\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.3086 - mae: 1.8014 - val_loss: 13.2680 - val_mae: 2.4249\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.3421 - mae: 1.7591 - val_loss: 12.5480 - val_mae: 2.4196\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.2206 - mae: 1.7230 - val_loss: 13.0289 - val_mae: 2.3779\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.9837 - mae: 1.7066 - val_loss: 12.9708 - val_mae: 2.4443\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.2961 - mae: 1.7175 - val_loss: 12.5864 - val_mae: 2.4613\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.7760 - mae: 1.7330 - val_loss: 13.0766 - val_mae: 2.4937\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.8542 - mae: 1.6954 - val_loss: 12.1460 - val_mae: 2.4190\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.6847 - mae: 1.6925 - val_loss: 14.5736 - val_mae: 2.6912\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.7181 - mae: 1.6730 - val_loss: 12.9427 - val_mae: 2.4129\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.4447 - mae: 1.6689 - val_loss: 11.9617 - val_mae: 2.5050\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.0687 - mae: 1.6235 - val_loss: 12.0918 - val_mae: 2.4035\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.3586 - mae: 1.6413 - val_loss: 12.1705 - val_mae: 2.4484\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.0662 - mae: 1.6534 - val_loss: 12.5530 - val_mae: 2.3788\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.0653 - mae: 1.5980 - val_loss: 11.9529 - val_mae: 2.4005\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8080 - mae: 1.6116 - val_loss: 12.1031 - val_mae: 2.4088\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8958 - mae: 1.6228 - val_loss: 11.9701 - val_mae: 2.4186\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.9607 - mae: 1.5677 - val_loss: 12.6036 - val_mae: 2.5628\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7612 - mae: 1.5463 - val_loss: 12.0744 - val_mae: 2.4044\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.5454 - mae: 1.5777 - val_loss: 10.7294 - val_mae: 2.3224\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7908 - mae: 1.5856 - val_loss: 12.2699 - val_mae: 2.5372\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7706 - mae: 1.5119 - val_loss: 11.0321 - val_mae: 2.3472\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7350 - mae: 1.5964 - val_loss: 12.0359 - val_mae: 2.3973\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.2961 - mae: 1.4884 - val_loss: 11.7399 - val_mae: 2.3107\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.3235 - mae: 1.5333 - val_loss: 11.9827 - val_mae: 2.4473\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3260 - mae: 1.5215 - val_loss: 13.8731 - val_mae: 2.5493\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4462 - mae: 1.5072 - val_loss: 10.6161 - val_mae: 2.2524\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0596 - mae: 1.4841 - val_loss: 11.8863 - val_mae: 2.4485\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4327 - mae: 1.5479 - val_loss: 10.5244 - val_mae: 2.2621\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0264 - mae: 1.4482 - val_loss: 13.4186 - val_mae: 2.7416\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0380 - mae: 1.4849 - val_loss: 11.3122 - val_mae: 2.4169\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.2374 - mae: 1.4609 - val_loss: 12.9305 - val_mae: 2.6609\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1720 - mae: 1.4472 - val_loss: 10.3712 - val_mae: 2.2166\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7685 - mae: 1.4471 - val_loss: 11.4581 - val_mae: 2.3766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8526 - mae: 1.4918 - val_loss: 10.3944 - val_mae: 2.2960\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8945 - mae: 1.4444 - val_loss: 11.0081 - val_mae: 2.3437\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3497 - mae: 1.4678 - val_loss: 10.0847 - val_mae: 2.2447\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4954 - mae: 1.4161 - val_loss: 11.8586 - val_mae: 2.4088\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6254 - mae: 1.4353 - val_loss: 11.3997 - val_mae: 2.3803\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8282 - mae: 1.4876 - val_loss: 9.9553 - val_mae: 2.1954\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4354 - mae: 1.4274 - val_loss: 11.1787 - val_mae: 2.3225\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6081 - mae: 1.4158 - val_loss: 10.7256 - val_mae: 2.3148\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8357 - mae: 1.4275 - val_loss: 11.4217 - val_mae: 2.3926\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6925 - mae: 1.4334 - val_loss: 10.3078 - val_mae: 2.3292\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3947 - mae: 1.3495 - val_loss: 10.4754 - val_mae: 2.2100\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3776 - mae: 1.4040 - val_loss: 11.3671 - val_mae: 2.4593\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2518 - mae: 1.3479 - val_loss: 14.4097 - val_mae: 2.7353\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4568 - mae: 1.4025 - val_loss: 10.1037 - val_mae: 2.2227\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6094 - mae: 1.4073 - val_loss: 10.0023 - val_mae: 2.1130\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3298 - mae: 1.3648 - val_loss: 10.9239 - val_mae: 2.3642\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0312 - mae: 1.3623 - val_loss: 10.4089 - val_mae: 2.2445\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3785 - mae: 1.3640 - val_loss: 12.0061 - val_mae: 2.3803\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3138 - mae: 1.3508 - val_loss: 10.5499 - val_mae: 2.3183\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2569 - mae: 1.3716 - val_loss: 10.4674 - val_mae: 2.3552\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0252 - mae: 1.3712 - val_loss: 11.2999 - val_mae: 2.3711\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1366 - mae: 1.3262 - val_loss: 11.5856 - val_mae: 2.3809\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1941 - mae: 1.3127 - val_loss: 9.9119 - val_mae: 2.2032\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0088 - mae: 1.3271 - val_loss: 10.9867 - val_mae: 2.2890\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9656 - mae: 1.3575 - val_loss: 10.5875 - val_mae: 2.2914\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0505 - mae: 1.2960 - val_loss: 10.8604 - val_mae: 2.2859\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1016 - mae: 1.2951 - val_loss: 11.7459 - val_mae: 2.4068\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0318 - mae: 1.2992 - val_loss: 10.4716 - val_mae: 2.2211\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9333 - mae: 1.3411 - val_loss: 10.6443 - val_mae: 2.2406\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8882 - mae: 1.2871 - val_loss: 10.0831 - val_mae: 2.2421\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9639 - mae: 1.3322 - val_loss: 10.8129 - val_mae: 2.2506\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8148 - mae: 1.2934 - val_loss: 9.6510 - val_mae: 2.1652\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7452 - mae: 1.3100 - val_loss: 12.4314 - val_mae: 2.5888\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6874 - mae: 1.2710 - val_loss: 13.6193 - val_mae: 2.5738\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7462 - mae: 1.2885 - val_loss: 11.6252 - val_mae: 2.4164\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5021 - mae: 1.2513 - val_loss: 9.8194 - val_mae: 2.2852\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7044 - mae: 1.2689 - val_loss: 11.1819 - val_mae: 2.2963\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.7839 - mae: 1.2690 - val_loss: 13.1383 - val_mae: 2.4628\n"
     ]
    }
   ],
   "source": [
    "k = 4 \n",
    "\n",
    "num_val_samples = len(train_data) // k # 전체 데이터 개수를 k로 나눈 몫\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드 #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    # np.concatenate는 배열을 축을 기준으로 합치는 기능을 한다.\n",
    "    # 밑의 예는 검증 데이터 부분을 제외하고 훈련 데이터를 합치는 경우이다.\n",
    "    partial_train_data = np.concatenate(\n",
    "    [train_data[:i * num_val_samples],\n",
    "    train_data[(i + 1) * num_val_samples :]],\n",
    "    axis=0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate(\n",
    "    [train_targets[:i * num_val_samples],\n",
    "    train_targets[(i + 1) * num_val_samples :]],\n",
    "    axis=0)\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data,\n",
    "            partial_train_targets,\n",
    "            validation_data=(val_data, val_targets),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=1,\n",
    "            verbose=1)\n",
    "    \n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0) # 검증 셋으로 평가\n",
    "    all_scores.append(val_mae) # 평가 기준의 값을 넣어놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스코어들 : [2.016528606414795, 2.7032535076141357, 2.65431809425354, 2.4627556800842285]\n",
      "스코어 평균 : 2.459213972091675\n"
     ]
    }
   ],
   "source": [
    "print(\"스코어들 : {}\".format(all_scores))\n",
    "print(\"스코어 평균 : {}\".format(np.mean(all_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 셋이 1.8 ~ 2.68로 차이가 크다.\n",
    "- 신경망을 더 오래 500 epochs 학습\n",
    "- 각 에포크마다 모델이 얼마나 개선되는지 기록하기 위해 에포크의 검증 점수를 로그에 저장\n",
    "\n",
    "\n",
    "### 각 폴드에서 검증 점수를 로그에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 205.1945 - mae: 10.7458 - val_loss: 44.3260 - val_mae: 4.4879\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 34.7797 - mae: 4.1088 - val_loss: 25.2033 - val_mae: 3.1992\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 23.3008 - mae: 3.3417 - val_loss: 20.1533 - val_mae: 2.8166\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 18.5448 - mae: 2.8837 - val_loss: 16.2128 - val_mae: 2.7140\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 16.3222 - mae: 2.7108 - val_loss: 14.5544 - val_mae: 2.4542\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 14.9638 - mae: 2.5335 - val_loss: 13.9800 - val_mae: 2.3966\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 14.4455 - mae: 2.4631 - val_loss: 14.5537 - val_mae: 2.5138\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 14.0517 - mae: 2.4642 - val_loss: 11.3495 - val_mae: 2.3419\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 13.5674 - mae: 2.3860 - val_loss: 11.7612 - val_mae: 2.4929\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.4684 - mae: 2.3501 - val_loss: 10.3622 - val_mae: 2.2512\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.5826 - mae: 2.3082 - val_loss: 11.4298 - val_mae: 2.0914\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.3995 - mae: 2.3083 - val_loss: 9.7027 - val_mae: 1.9534\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.6242 - mae: 2.2090 - val_loss: 9.0727 - val_mae: 2.0418\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.1090 - mae: 2.1299 - val_loss: 9.1930 - val_mae: 2.1099\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.4448 - mae: 2.2262 - val_loss: 10.2616 - val_mae: 2.2729\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.3177 - mae: 2.1639 - val_loss: 10.7056 - val_mae: 2.3388\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.3568 - mae: 2.1785 - val_loss: 8.3704 - val_mae: 1.9656\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.9182 - mae: 2.0815 - val_loss: 10.2766 - val_mae: 2.4086\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.0437 - mae: 2.1058 - val_loss: 9.7495 - val_mae: 2.0473\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.8489 - mae: 2.0805 - val_loss: 8.7963 - val_mae: 2.0772\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.1430 - mae: 2.0807 - val_loss: 7.9211 - val_mae: 1.9973\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.2461 - mae: 2.0177 - val_loss: 9.0454 - val_mae: 2.0376\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.9339 - mae: 2.0632 - val_loss: 8.7911 - val_mae: 1.8787\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.4877 - mae: 1.9580 - val_loss: 8.8055 - val_mae: 2.1515\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9848 - mae: 2.0148 - val_loss: 11.1463 - val_mae: 2.2760\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.5106 - mae: 1.9585 - val_loss: 8.5608 - val_mae: 1.8450\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.5920 - mae: 1.9992 - val_loss: 7.6534 - val_mae: 1.9351\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.1370 - mae: 1.9320 - val_loss: 6.8713 - val_mae: 1.8526\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.5591 - mae: 1.9502 - val_loss: 7.6492 - val_mae: 1.8637\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.7170 - mae: 1.9825 - val_loss: 7.0784 - val_mae: 1.8794\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.6253 - mae: 1.9128 - val_loss: 7.6076 - val_mae: 2.0033\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9174 - mae: 1.9320 - val_loss: 8.0404 - val_mae: 1.8096\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9437 - mae: 1.9146 - val_loss: 6.7268 - val_mae: 1.7771\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.4593 - mae: 1.8409 - val_loss: 8.1531 - val_mae: 2.1905\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0728 - mae: 1.8281 - val_loss: 7.8308 - val_mae: 2.0776\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0086 - mae: 1.8454 - val_loss: 8.0197 - val_mae: 1.9927\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0369 - mae: 1.8563 - val_loss: 7.4692 - val_mae: 1.9351\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8679 - mae: 1.8494 - val_loss: 8.1103 - val_mae: 2.1267\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.6018 - mae: 1.8274 - val_loss: 9.5645 - val_mae: 2.1520\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.3297 - mae: 1.8570 - val_loss: 7.1832 - val_mae: 1.8366\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.0310 - mae: 1.8254 - val_loss: 7.1509 - val_mae: 1.8730\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5878 - mae: 1.7798 - val_loss: 8.3217 - val_mae: 1.9445\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5020 - mae: 1.7695 - val_loss: 7.3969 - val_mae: 1.9776\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.1403 - mae: 1.8105 - val_loss: 7.8272 - val_mae: 2.0306\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.4754 - mae: 1.7521 - val_loss: 7.8496 - val_mae: 2.0756\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8545 - mae: 1.7497 - val_loss: 7.7478 - val_mae: 2.0545\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.2651 - mae: 1.7751 - val_loss: 7.0962 - val_mae: 1.9139\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.9197 - mae: 1.7465 - val_loss: 9.0521 - val_mae: 2.3141\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.2470 - mae: 1.7195 - val_loss: 7.6207 - val_mae: 2.1180\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.0969 - mae: 1.7522 - val_loss: 7.4167 - val_mae: 1.8912\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.8931 - mae: 1.7206 - val_loss: 8.6197 - val_mae: 1.9967\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.6871 - mae: 1.6353 - val_loss: 9.1614 - val_mae: 2.3644\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.7539 - mae: 1.7259 - val_loss: 7.7962 - val_mae: 2.0723\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.4122 - mae: 1.6629 - val_loss: 9.1095 - val_mae: 2.1894\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.7986 - mae: 1.6952 - val_loss: 7.7445 - val_mae: 1.9639\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.8478 - mae: 1.6875 - val_loss: 9.0289 - val_mae: 2.0481\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.4455 - mae: 1.6698 - val_loss: 7.7018 - val_mae: 2.0179\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.7711 - mae: 1.6192 - val_loss: 7.3916 - val_mae: 2.1074\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.6965 - mae: 1.5972 - val_loss: 6.8061 - val_mae: 1.7510\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.2910 - mae: 1.6301 - val_loss: 7.8246 - val_mae: 2.1245\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5778 - mae: 1.6758 - val_loss: 6.4843 - val_mae: 1.8350\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.4258 - mae: 1.6409 - val_loss: 7.7162 - val_mae: 1.9107\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1991 - mae: 1.6359 - val_loss: 7.8858 - val_mae: 1.9862\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1996 - mae: 1.6163 - val_loss: 8.7629 - val_mae: 2.0454\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8694 - mae: 1.6044 - val_loss: 6.8579 - val_mae: 1.8309\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1307 - mae: 1.5524 - val_loss: 7.3477 - val_mae: 2.0070\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.7801 - mae: 1.5590 - val_loss: 6.8265 - val_mae: 1.7342\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2057 - mae: 1.6161 - val_loss: 7.1801 - val_mae: 1.9641\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1395 - mae: 1.5920 - val_loss: 7.7137 - val_mae: 2.1297\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.6447 - mae: 1.5729 - val_loss: 10.7035 - val_mae: 2.5722\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.9578 - mae: 1.5701 - val_loss: 6.6977 - val_mae: 1.8688\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.7842 - mae: 1.5455 - val_loss: 7.5732 - val_mae: 2.1513\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8345 - mae: 1.5313 - val_loss: 6.8365 - val_mae: 1.9874\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.5436 - mae: 1.5326 - val_loss: 7.8145 - val_mae: 2.1012\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8093 - mae: 1.5614 - val_loss: 6.5957 - val_mae: 1.9186\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.6288 - mae: 1.5274 - val_loss: 6.6894 - val_mae: 1.9633\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.5451 - mae: 1.5132 - val_loss: 10.7734 - val_mae: 2.5275\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.8266 - mae: 1.5388 - val_loss: 7.3761 - val_mae: 2.0765\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3702 - mae: 1.5296 - val_loss: 6.9596 - val_mae: 1.8864\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4480 - mae: 1.5142 - val_loss: 6.6609 - val_mae: 1.8289\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.5391 - mae: 1.5218 - val_loss: 6.6914 - val_mae: 1.8942\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1860 - mae: 1.4468 - val_loss: 6.5041 - val_mae: 1.8808\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.0802 - mae: 1.5062 - val_loss: 6.6267 - val_mae: 1.8277\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.0492 - mae: 1.4564 - val_loss: 7.1832 - val_mae: 2.1095\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.1943 - mae: 1.4699 - val_loss: 8.8166 - val_mae: 2.3353\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4979 - mae: 1.5071 - val_loss: 7.5547 - val_mae: 1.9686\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8397 - mae: 1.4541 - val_loss: 7.0360 - val_mae: 1.9844\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.9944 - mae: 1.5037 - val_loss: 6.3502 - val_mae: 1.7937\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8656 - mae: 1.4285 - val_loss: 6.9204 - val_mae: 1.8488\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.9701 - mae: 1.4773 - val_loss: 7.8874 - val_mae: 1.9865\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0991 - mae: 1.5098 - val_loss: 7.1716 - val_mae: 1.9547\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0091 - mae: 1.4424 - val_loss: 6.9576 - val_mae: 1.8837\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1350 - mae: 1.5006 - val_loss: 7.4509 - val_mae: 2.0027\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.9238 - mae: 1.3986 - val_loss: 7.1204 - val_mae: 1.8800\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8492 - mae: 1.3813 - val_loss: 10.2113 - val_mae: 2.3455\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3178 - mae: 1.3763 - val_loss: 7.0396 - val_mae: 1.9672\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6506 - mae: 1.4050 - val_loss: 6.5071 - val_mae: 1.8260\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7259 - mae: 1.3911 - val_loss: 7.7975 - val_mae: 2.0126\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7250 - mae: 1.4165 - val_loss: 8.5807 - val_mae: 2.1409\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7331 - mae: 1.3955 - val_loss: 8.0119 - val_mae: 2.1343\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0389 - mae: 1.3957 - val_loss: 6.6579 - val_mae: 1.8115\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7278 - mae: 1.3438 - val_loss: 6.3139 - val_mae: 1.9570\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.9011 - mae: 1.4293 - val_loss: 6.7972 - val_mae: 1.9355\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5721 - mae: 1.3946 - val_loss: 6.7430 - val_mae: 1.8610\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4174 - mae: 1.3941 - val_loss: 8.2225 - val_mae: 2.1612\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6159 - mae: 1.4213 - val_loss: 5.8300 - val_mae: 1.7974\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4091 - mae: 1.3566 - val_loss: 6.7280 - val_mae: 1.9261\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2096 - mae: 1.3754 - val_loss: 9.6470 - val_mae: 2.2252\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9480 - mae: 1.3092 - val_loss: 7.0240 - val_mae: 1.9879\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3541 - mae: 1.3947 - val_loss: 6.7810 - val_mae: 1.8906\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5111 - mae: 1.4114 - val_loss: 6.4847 - val_mae: 1.8867\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3175 - mae: 1.3126 - val_loss: 6.5601 - val_mae: 1.8804\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2030 - mae: 1.3854 - val_loss: 7.5482 - val_mae: 2.0322\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9232 - mae: 1.3315 - val_loss: 7.8830 - val_mae: 1.9988\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0705 - mae: 1.3586 - val_loss: 7.4020 - val_mae: 1.9736\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2783 - mae: 1.3233 - val_loss: 6.8633 - val_mae: 1.9658\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1066 - mae: 1.2620 - val_loss: 8.4297 - val_mae: 2.1872\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2365 - mae: 1.3343 - val_loss: 7.2814 - val_mae: 1.9658\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2301 - mae: 1.3503 - val_loss: 6.8139 - val_mae: 1.9404\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0320 - mae: 1.3294 - val_loss: 6.9158 - val_mae: 1.9678\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1966 - mae: 1.3172 - val_loss: 7.3954 - val_mae: 1.9997\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8260 - mae: 1.2705 - val_loss: 8.2782 - val_mae: 2.3016\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9785 - mae: 1.3129 - val_loss: 7.2744 - val_mae: 1.9378\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8857 - mae: 1.3005 - val_loss: 7.2044 - val_mae: 1.9145\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0123 - mae: 1.2300 - val_loss: 6.8607 - val_mae: 1.9500\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9258 - mae: 1.2870 - val_loss: 7.6347 - val_mae: 2.0094\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7461 - mae: 1.2727 - val_loss: 6.4663 - val_mae: 1.9403\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7107 - mae: 1.2626 - val_loss: 6.7967 - val_mae: 1.9626\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7633 - mae: 1.2576 - val_loss: 7.6057 - val_mae: 2.2134\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6991 - mae: 1.2224 - val_loss: 5.8482 - val_mae: 1.8267\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6751 - mae: 1.2742 - val_loss: 6.2356 - val_mae: 1.9538\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7674 - mae: 1.3023 - val_loss: 7.6859 - val_mae: 2.0883\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7067 - mae: 1.2841 - val_loss: 7.2020 - val_mae: 2.0041\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5898 - mae: 1.2904 - val_loss: 8.3648 - val_mae: 2.1623\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4514 - mae: 1.2973 - val_loss: 7.8905 - val_mae: 2.0733\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4322 - mae: 1.2356 - val_loss: 6.6957 - val_mae: 1.9944\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8051 - mae: 1.2490 - val_loss: 7.2064 - val_mae: 2.0227\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5287 - mae: 1.2643 - val_loss: 6.3755 - val_mae: 1.9372\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6206 - mae: 1.2368 - val_loss: 6.2951 - val_mae: 1.9374\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5737 - mae: 1.2559 - val_loss: 6.9560 - val_mae: 1.9638\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5104 - mae: 1.3009 - val_loss: 6.9830 - val_mae: 1.9872\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3929 - mae: 1.2528 - val_loss: 6.6836 - val_mae: 2.0625\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5507 - mae: 1.2680 - val_loss: 8.0091 - val_mae: 2.1880\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5162 - mae: 1.2830 - val_loss: 9.0942 - val_mae: 2.2124\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5021 - mae: 1.3333 - val_loss: 7.8267 - val_mae: 2.1146\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3808 - mae: 1.1955 - val_loss: 7.2920 - val_mae: 2.0478\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5591 - mae: 1.2506 - val_loss: 9.9901 - val_mae: 2.3995\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3434 - mae: 1.2426 - val_loss: 7.5827 - val_mae: 2.1376\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1911 - mae: 1.2479 - val_loss: 8.4805 - val_mae: 2.2441\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2846 - mae: 1.2204 - val_loss: 8.0188 - val_mae: 2.1866\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3222 - mae: 1.2454 - val_loss: 8.5138 - val_mae: 2.3724\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.8645 - mae: 1.1796 - val_loss: 9.0834 - val_mae: 2.2768\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1274 - mae: 1.2025 - val_loss: 9.1368 - val_mae: 2.3483\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1615 - mae: 1.2186 - val_loss: 6.6151 - val_mae: 2.0367\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1917 - mae: 1.2421 - val_loss: 6.8598 - val_mae: 2.1242\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1773 - mae: 1.2028 - val_loss: 7.5731 - val_mae: 2.0931\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2697 - mae: 1.2878 - val_loss: 9.0607 - val_mae: 2.3018\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.0744 - mae: 1.1753 - val_loss: 11.7601 - val_mae: 2.5288\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3794 - mae: 1.3078 - val_loss: 7.9554 - val_mae: 2.1672\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.2197 - mae: 1.2204 - val_loss: 7.1567 - val_mae: 2.0640\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1371 - mae: 1.1651 - val_loss: 7.4323 - val_mae: 2.1965\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9015 - mae: 1.1603 - val_loss: 9.9160 - val_mae: 2.3382\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0527 - mae: 1.1948 - val_loss: 7.7439 - val_mae: 2.0490\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8246 - mae: 1.2060 - val_loss: 9.9787 - val_mae: 2.3487\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9182 - mae: 1.2180 - val_loss: 8.0565 - val_mae: 2.2793\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7408 - mae: 1.1891 - val_loss: 8.6432 - val_mae: 2.1982\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.0004 - mae: 1.1877 - val_loss: 9.2844 - val_mae: 2.3501\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7845 - mae: 1.1568 - val_loss: 7.6431 - val_mae: 2.1262\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.8643 - mae: 1.1400 - val_loss: 7.4450 - val_mae: 2.1444\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9547 - mae: 1.2095 - val_loss: 10.8709 - val_mae: 2.5266\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7908 - mae: 1.1700 - val_loss: 12.8985 - val_mae: 2.6730\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0461 - mae: 1.2134 - val_loss: 9.0866 - val_mae: 2.2357\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9429 - mae: 1.1521 - val_loss: 9.0804 - val_mae: 2.3080\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.6033 - mae: 1.1368 - val_loss: 11.7493 - val_mae: 2.5974\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6799 - mae: 1.1285 - val_loss: 9.0789 - val_mae: 2.3110\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9533 - mae: 1.1590 - val_loss: 8.8426 - val_mae: 2.3072\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6223 - mae: 1.1808 - val_loss: 9.2127 - val_mae: 2.2975\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5664 - mae: 1.1144 - val_loss: 10.8427 - val_mae: 2.4821\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5804 - mae: 1.1632 - val_loss: 8.5746 - val_mae: 2.1811\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5269 - mae: 1.1424 - val_loss: 10.0926 - val_mae: 2.3851\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7365 - mae: 1.2086 - val_loss: 8.3260 - val_mae: 2.2018\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4382 - mae: 1.0907 - val_loss: 11.5464 - val_mae: 2.6161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5649 - mae: 1.1879 - val_loss: 7.8726 - val_mae: 2.1595\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5416 - mae: 1.1314 - val_loss: 9.8340 - val_mae: 2.3907\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2462 - mae: 1.0590 - val_loss: 8.1366 - val_mae: 2.1552\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4330 - mae: 1.1380 - val_loss: 7.6164 - val_mae: 2.0835\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4754 - mae: 1.0718 - val_loss: 9.6400 - val_mae: 2.3652\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5475 - mae: 1.1348 - val_loss: 7.6423 - val_mae: 2.1014\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4050 - mae: 1.1143 - val_loss: 8.9179 - val_mae: 2.3473\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6326 - mae: 1.1520 - val_loss: 8.0940 - val_mae: 2.1581\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4521 - mae: 1.1021 - val_loss: 7.8399 - val_mae: 2.1662\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5203 - mae: 1.1374 - val_loss: 8.1110 - val_mae: 2.2301\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4806 - mae: 1.1488 - val_loss: 9.4892 - val_mae: 2.4511\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3573 - mae: 1.1346 - val_loss: 8.1390 - val_mae: 2.1573\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3002 - mae: 1.0647 - val_loss: 9.0218 - val_mae: 2.2782\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5135 - mae: 1.1060 - val_loss: 9.0697 - val_mae: 2.2778\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4726 - mae: 1.1230 - val_loss: 9.2226 - val_mae: 2.2770\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5146 - mae: 1.0870 - val_loss: 8.2074 - val_mae: 2.1786\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4324 - mae: 1.0852 - val_loss: 7.6181 - val_mae: 2.0903\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1442 - mae: 1.0311 - val_loss: 10.4854 - val_mae: 2.4235\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2533 - mae: 1.0925 - val_loss: 8.3954 - val_mae: 2.2834\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2323 - mae: 1.0574 - val_loss: 9.4771 - val_mae: 2.3507\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2894 - mae: 1.1033 - val_loss: 9.9080 - val_mae: 2.4371\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3266 - mae: 1.0710 - val_loss: 11.0937 - val_mae: 2.4842\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5821 - mae: 1.1349 - val_loss: 9.0218 - val_mae: 2.2036\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2447 - mae: 1.0355 - val_loss: 10.8537 - val_mae: 2.4608\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1999 - mae: 1.0798 - val_loss: 9.3609 - val_mae: 2.3085\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4331 - mae: 1.0715 - val_loss: 9.9008 - val_mae: 2.4504\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0198 - mae: 1.0316 - val_loss: 8.5305 - val_mae: 2.2655\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1235 - mae: 1.0702 - val_loss: 8.1076 - val_mae: 2.1887\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1008 - mae: 1.1030 - val_loss: 10.0041 - val_mae: 2.4523\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4383 - mae: 1.1061 - val_loss: 8.5136 - val_mae: 2.1865\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1421 - mae: 1.0325 - val_loss: 8.8338 - val_mae: 2.3914\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2457 - mae: 1.0826 - val_loss: 7.9781 - val_mae: 2.1114\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3057 - mae: 1.1034 - val_loss: 8.9443 - val_mae: 2.2398\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1068 - mae: 1.0693 - val_loss: 11.2490 - val_mae: 2.6753\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1236 - mae: 1.0385 - val_loss: 10.1972 - val_mae: 2.3781\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1401 - mae: 1.0784 - val_loss: 9.6560 - val_mae: 2.4004\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0208 - mae: 1.0295 - val_loss: 8.3596 - val_mae: 2.1913\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1504 - mae: 1.0659 - val_loss: 8.8927 - val_mae: 2.1947\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9342 - mae: 0.9850 - val_loss: 9.6040 - val_mae: 2.2995\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0497 - mae: 1.0278 - val_loss: 8.0931 - val_mae: 2.1862\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9776 - mae: 1.0191 - val_loss: 9.1357 - val_mae: 2.3589\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7977 - mae: 0.9904 - val_loss: 10.3797 - val_mae: 2.4852\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.2177 - mae: 1.0758 - val_loss: 9.4530 - val_mae: 2.3641\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0208 - mae: 1.0727 - val_loss: 9.3273 - val_mae: 2.1921\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.2398 - mae: 1.0655 - val_loss: 7.7522 - val_mae: 2.0677\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9605 - mae: 1.0447 - val_loss: 10.4915 - val_mae: 2.5396\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1837 - mae: 1.0660 - val_loss: 7.7500 - val_mae: 2.2067\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9543 - mae: 1.0163 - val_loss: 9.3398 - val_mae: 2.2869\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.2657 - mae: 1.0367 - val_loss: 8.4069 - val_mae: 2.1659\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3937 - mae: 1.0777 - val_loss: 10.1859 - val_mae: 2.3197\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8992 - mae: 0.9548 - val_loss: 8.6359 - val_mae: 2.2097\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1752 - mae: 1.0209 - val_loss: 8.9403 - val_mae: 2.1937\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9047 - mae: 1.0151 - val_loss: 8.8810 - val_mae: 2.2412\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0180 - mae: 1.0229 - val_loss: 10.2590 - val_mae: 2.4327\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8161 - mae: 1.0082 - val_loss: 12.0225 - val_mae: 2.5768\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9273 - mae: 1.0056 - val_loss: 9.4953 - val_mae: 2.3767\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.0726 - mae: 1.0272 - val_loss: 9.5504 - val_mae: 2.3363\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8293 - mae: 1.0133 - val_loss: 7.7463 - val_mae: 2.1093\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7296 - mae: 0.9688 - val_loss: 10.5371 - val_mae: 2.5207\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0027 - mae: 1.0110 - val_loss: 9.4468 - val_mae: 2.2840\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0389 - mae: 1.0164 - val_loss: 9.0461 - val_mae: 2.2644\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6938 - mae: 0.9833 - val_loss: 8.9059 - val_mae: 2.2222\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9607 - mae: 0.9972 - val_loss: 10.5774 - val_mae: 2.5108\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0008 - mae: 1.0503 - val_loss: 9.2382 - val_mae: 2.3086\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8605 - mae: 0.9965 - val_loss: 8.6242 - val_mae: 2.2689\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8116 - mae: 0.9811 - val_loss: 8.8791 - val_mae: 2.3139\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9655 - mae: 1.0043 - val_loss: 7.9114 - val_mae: 2.1862\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.7211 - mae: 0.9604 - val_loss: 12.2377 - val_mae: 2.6684\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8488 - mae: 0.9954 - val_loss: 10.9556 - val_mae: 2.4608\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9497 - mae: 1.0171 - val_loss: 7.6170 - val_mae: 2.1004\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9411 - mae: 1.0315 - val_loss: 9.5887 - val_mae: 2.2572\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7194 - mae: 0.9585 - val_loss: 8.9788 - val_mae: 2.2380\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7186 - mae: 0.9393 - val_loss: 8.5298 - val_mae: 2.2626\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0590 - mae: 1.0008 - val_loss: 9.1433 - val_mae: 2.2698\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8734 - mae: 1.0057 - val_loss: 9.4175 - val_mae: 2.3587\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7640 - mae: 0.9637 - val_loss: 9.2590 - val_mae: 2.3406\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6611 - mae: 0.9464 - val_loss: 10.0756 - val_mae: 2.4145\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9625 - mae: 0.9955 - val_loss: 8.9324 - val_mae: 2.2835\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8504 - mae: 0.9499 - val_loss: 9.4859 - val_mae: 2.3014\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6384 - mae: 0.9402 - val_loss: 8.7408 - val_mae: 2.2513\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8667 - mae: 1.0012 - val_loss: 8.2805 - val_mae: 2.2162\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7433 - mae: 0.9901 - val_loss: 10.0440 - val_mae: 2.4253\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8608 - mae: 0.9657 - val_loss: 8.2144 - val_mae: 2.2244\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7364 - mae: 0.9143 - val_loss: 9.8500 - val_mae: 2.3434\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6993 - mae: 0.9475 - val_loss: 10.0676 - val_mae: 2.5213\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8517 - mae: 0.9717 - val_loss: 10.0031 - val_mae: 2.3552\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7509 - mae: 0.9424 - val_loss: 9.6441 - val_mae: 2.4854\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0226 - mae: 0.9564 - val_loss: 8.9776 - val_mae: 2.3400\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7610 - mae: 0.9561 - val_loss: 9.2136 - val_mae: 2.2636\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.7633 - mae: 0.9475 - val_loss: 9.6258 - val_mae: 2.2868\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7248 - mae: 0.9518 - val_loss: 10.0096 - val_mae: 2.3665\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5345 - mae: 0.8920 - val_loss: 8.8045 - val_mae: 2.2304\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6633 - mae: 0.9492 - val_loss: 10.2191 - val_mae: 2.3235\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6322 - mae: 0.9491 - val_loss: 10.5994 - val_mae: 2.4630\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5680 - mae: 0.9513 - val_loss: 9.1435 - val_mae: 2.2896\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.7322 - mae: 0.9277 - val_loss: 10.0249 - val_mae: 2.4317\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6797 - mae: 0.9435 - val_loss: 10.1632 - val_mae: 2.3815\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5157 - mae: 0.9293 - val_loss: 9.8247 - val_mae: 2.4253\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8013 - mae: 0.9394 - val_loss: 8.5168 - val_mae: 2.1569\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4459 - mae: 0.8776 - val_loss: 9.3812 - val_mae: 2.2255\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6252 - mae: 0.9371 - val_loss: 11.1851 - val_mae: 2.5765\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4036 - mae: 0.8813 - val_loss: 10.5887 - val_mae: 2.3888\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8152 - mae: 0.9401 - val_loss: 9.9162 - val_mae: 2.3829\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4921 - mae: 0.8881 - val_loss: 10.9130 - val_mae: 2.5479\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6656 - mae: 0.9207 - val_loss: 10.7323 - val_mae: 2.4429\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5536 - mae: 0.9481 - val_loss: 9.3619 - val_mae: 2.3283\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5486 - mae: 0.9075 - val_loss: 8.8009 - val_mae: 2.2209\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7211 - mae: 0.9495 - val_loss: 9.9646 - val_mae: 2.2781\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3930 - mae: 0.8697 - val_loss: 9.1965 - val_mae: 2.3186\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6918 - mae: 0.8878 - val_loss: 12.9548 - val_mae: 2.7695\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5890 - mae: 0.9200 - val_loss: 10.8104 - val_mae: 2.4783\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4748 - mae: 0.9017 - val_loss: 9.5549 - val_mae: 2.3663\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5537 - mae: 0.9112 - val_loss: 11.2856 - val_mae: 2.4727\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6469 - mae: 0.9505 - val_loss: 10.7178 - val_mae: 2.3563\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7399 - mae: 0.9441 - val_loss: 12.2449 - val_mae: 2.7111\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5231 - mae: 0.9017 - val_loss: 9.2352 - val_mae: 2.3296\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6371 - mae: 0.9301 - val_loss: 10.6975 - val_mae: 2.4526\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4897 - mae: 0.8870 - val_loss: 8.9670 - val_mae: 2.2345\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6256 - mae: 0.9329 - val_loss: 9.9943 - val_mae: 2.2731\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6222 - mae: 0.9180 - val_loss: 9.7825 - val_mae: 2.3540\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3363 - mae: 0.8749 - val_loss: 11.7657 - val_mae: 2.5031\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5076 - mae: 0.8929 - val_loss: 9.7574 - val_mae: 2.3476\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3087 - mae: 0.8554 - val_loss: 12.1200 - val_mae: 2.4581\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.6178 - mae: 0.9421 - val_loss: 11.1169 - val_mae: 2.5037\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4087 - mae: 0.8734 - val_loss: 10.0718 - val_mae: 2.3839\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4135 - mae: 0.8562 - val_loss: 9.7511 - val_mae: 2.3883\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.6124 - mae: 0.9355 - val_loss: 9.1679 - val_mae: 2.3203\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3869 - mae: 0.8602 - val_loss: 9.8806 - val_mae: 2.2338\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.2906 - mae: 0.8392 - val_loss: 9.7956 - val_mae: 2.4097\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4200 - mae: 0.9129 - val_loss: 12.6715 - val_mae: 2.6970\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5338 - mae: 0.8961 - val_loss: 9.7811 - val_mae: 2.2847\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6789 - mae: 0.9039 - val_loss: 10.2121 - val_mae: 2.4393\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4116 - mae: 0.8441 - val_loss: 9.9689 - val_mae: 2.2243\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4001 - mae: 0.8608 - val_loss: 12.1655 - val_mae: 2.7079\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4475 - mae: 0.8685 - val_loss: 11.6571 - val_mae: 2.5469\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3747 - mae: 0.8792 - val_loss: 10.3830 - val_mae: 2.3443\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4585 - mae: 0.8503 - val_loss: 9.4382 - val_mae: 2.2796\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5392 - mae: 0.8694 - val_loss: 11.3463 - val_mae: 2.4673\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4297 - mae: 0.8982 - val_loss: 12.5583 - val_mae: 2.6661\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4143 - mae: 0.8824 - val_loss: 9.6881 - val_mae: 2.3814\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2965 - mae: 0.8202 - val_loss: 11.6927 - val_mae: 2.5207\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5908 - mae: 0.9108 - val_loss: 10.9873 - val_mae: 2.4815\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1857 - mae: 0.7951 - val_loss: 11.1286 - val_mae: 2.4631\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4230 - mae: 0.8658 - val_loss: 11.7571 - val_mae: 2.5619\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2881 - mae: 0.8084 - val_loss: 11.1625 - val_mae: 2.5065\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4434 - mae: 0.9019 - val_loss: 9.3326 - val_mae: 2.3098\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3588 - mae: 0.8518 - val_loss: 9.4034 - val_mae: 2.3649\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3035 - mae: 0.8542 - val_loss: 9.2001 - val_mae: 2.3019\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2955 - mae: 0.8416 - val_loss: 10.4827 - val_mae: 2.3808\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3435 - mae: 0.8545 - val_loss: 9.4862 - val_mae: 2.3606\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3067 - mae: 0.8227 - val_loss: 10.3311 - val_mae: 2.4125\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4259 - mae: 0.8666 - val_loss: 10.1686 - val_mae: 2.2834\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3007 - mae: 0.8305 - val_loss: 10.3757 - val_mae: 2.3897\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3943 - mae: 0.8716 - val_loss: 8.8157 - val_mae: 2.1462\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4840 - mae: 0.8738 - val_loss: 9.2441 - val_mae: 2.2757\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2044 - mae: 0.8375 - val_loss: 10.4988 - val_mae: 2.4414\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3700 - mae: 0.8500 - val_loss: 9.7012 - val_mae: 2.3188\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0560 - mae: 0.7644 - val_loss: 9.8706 - val_mae: 2.3809\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4056 - mae: 0.8482 - val_loss: 9.2957 - val_mae: 2.2713\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2660 - mae: 0.8462 - val_loss: 10.0513 - val_mae: 2.3891\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2712 - mae: 0.8152 - val_loss: 8.8722 - val_mae: 2.1708\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3452 - mae: 0.8204 - val_loss: 8.9512 - val_mae: 2.2625\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3226 - mae: 0.8362 - val_loss: 10.1466 - val_mae: 2.2962\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1980 - mae: 0.8090 - val_loss: 10.5745 - val_mae: 2.2936\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3580 - mae: 0.8466 - val_loss: 10.4837 - val_mae: 2.3130\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2353 - mae: 0.8098 - val_loss: 9.9259 - val_mae: 2.3270\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2305 - mae: 0.7995 - val_loss: 10.8320 - val_mae: 2.4046\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2988 - mae: 0.8226 - val_loss: 9.6005 - val_mae: 2.2724\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3789 - mae: 0.8711 - val_loss: 9.7064 - val_mae: 2.3448\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2122 - mae: 0.8110 - val_loss: 9.7001 - val_mae: 2.1887\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4255 - mae: 0.8798 - val_loss: 11.2699 - val_mae: 2.5361\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2732 - mae: 0.8382 - val_loss: 10.3180 - val_mae: 2.3694\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2646 - mae: 0.8096 - val_loss: 10.5349 - val_mae: 2.4299\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3095 - mae: 0.8439 - val_loss: 10.3301 - val_mae: 2.4349\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2713 - mae: 0.8145 - val_loss: 11.0569 - val_mae: 2.4638\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2124 - mae: 0.7959 - val_loss: 9.7285 - val_mae: 2.3224\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2833 - mae: 0.8409 - val_loss: 10.7120 - val_mae: 2.4929\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2187 - mae: 0.8224 - val_loss: 9.7301 - val_mae: 2.1860\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2284 - mae: 0.8047 - val_loss: 9.6326 - val_mae: 2.2948\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2858 - mae: 0.8413 - val_loss: 10.7089 - val_mae: 2.5656\n",
      "Epoch 363/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2505 - mae: 0.8374 - val_loss: 11.5455 - val_mae: 2.5396\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2890 - mae: 0.8385 - val_loss: 10.4298 - val_mae: 2.3991\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3767 - mae: 0.8103 - val_loss: 9.7382 - val_mae: 2.3301\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0519 - mae: 0.7599 - val_loss: 10.1609 - val_mae: 2.3882\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2977 - mae: 0.8427 - val_loss: 10.7798 - val_mae: 2.5917\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2915 - mae: 0.8186 - val_loss: 10.0579 - val_mae: 2.4106\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0592 - mae: 0.7499 - val_loss: 9.1739 - val_mae: 2.2505\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2975 - mae: 0.8231 - val_loss: 9.9934 - val_mae: 2.3850\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0769 - mae: 0.7798 - val_loss: 9.0880 - val_mae: 2.2638\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2202 - mae: 0.8290 - val_loss: 9.2994 - val_mae: 2.2934\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1878 - mae: 0.7958 - val_loss: 9.9538 - val_mae: 2.2144\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1135 - mae: 0.7918 - val_loss: 11.2907 - val_mae: 2.5675\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3934 - mae: 0.8446 - val_loss: 12.3077 - val_mae: 2.6090\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2277 - mae: 0.7971 - val_loss: 9.8751 - val_mae: 2.3106\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3559 - mae: 0.8427 - val_loss: 9.6599 - val_mae: 2.2563\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1549 - mae: 0.7781 - val_loss: 10.4175 - val_mae: 2.3446\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1568 - mae: 0.8138 - val_loss: 9.8693 - val_mae: 2.3376\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0504 - mae: 0.7764 - val_loss: 10.9273 - val_mae: 2.3818\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1647 - mae: 0.7662 - val_loss: 9.3362 - val_mae: 2.2401\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1196 - mae: 0.7656 - val_loss: 9.4633 - val_mae: 2.2173\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1668 - mae: 0.7882 - val_loss: 10.9689 - val_mae: 2.3790\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1791 - mae: 0.7673 - val_loss: 9.3113 - val_mae: 2.3179\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1874 - mae: 0.8096 - val_loss: 10.1004 - val_mae: 2.3232\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1191 - mae: 0.7740 - val_loss: 10.5793 - val_mae: 2.4603\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1025 - mae: 0.7849 - val_loss: 10.3103 - val_mae: 2.4120\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3705 - mae: 0.8185 - val_loss: 9.9141 - val_mae: 2.3685\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2022 - mae: 0.7986 - val_loss: 9.4054 - val_mae: 2.3458\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0498 - mae: 0.7500 - val_loss: 10.2419 - val_mae: 2.3469\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1672 - mae: 0.8134 - val_loss: 9.7670 - val_mae: 2.2384\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1330 - mae: 0.7633 - val_loss: 10.5997 - val_mae: 2.3705\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1767 - mae: 0.8388 - val_loss: 9.4168 - val_mae: 2.2471\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1779 - mae: 0.7829 - val_loss: 9.7295 - val_mae: 2.2764\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1800 - mae: 0.7739 - val_loss: 9.7934 - val_mae: 2.3615\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1184 - mae: 0.7835 - val_loss: 8.9152 - val_mae: 2.1991\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2916 - mae: 0.8170 - val_loss: 9.3440 - val_mae: 2.2224\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0377 - mae: 0.7686 - val_loss: 9.7199 - val_mae: 2.3304\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0944 - mae: 0.7486 - val_loss: 11.0854 - val_mae: 2.4345\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1173 - mae: 0.7337 - val_loss: 9.1227 - val_mae: 2.2804\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0882 - mae: 0.7785 - val_loss: 10.2136 - val_mae: 2.3767\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2916 - mae: 0.8056 - val_loss: 9.5604 - val_mae: 2.2060\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9763 - mae: 0.7404 - val_loss: 9.5862 - val_mae: 2.3112\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9159 - mae: 0.7106 - val_loss: 9.5033 - val_mae: 2.2277\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1700 - mae: 0.7897 - val_loss: 9.2949 - val_mae: 2.2678\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9764 - mae: 0.7516 - val_loss: 8.9431 - val_mae: 2.1199\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9486 - mae: 0.6859 - val_loss: 9.1998 - val_mae: 2.2779\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0350 - mae: 0.7509 - val_loss: 9.1328 - val_mae: 2.2561\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0606 - mae: 0.7353 - val_loss: 9.4610 - val_mae: 2.2677\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0254 - mae: 0.7305 - val_loss: 9.0738 - val_mae: 2.1847\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1760 - mae: 0.7810 - val_loss: 9.1706 - val_mae: 2.3117\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1418 - mae: 0.7585 - val_loss: 9.9409 - val_mae: 2.3571\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9351 - mae: 0.7167 - val_loss: 9.1112 - val_mae: 2.3107\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1954 - mae: 0.7766 - val_loss: 10.6236 - val_mae: 2.4417\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1446 - mae: 0.7905 - val_loss: 9.1038 - val_mae: 2.1606\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0888 - mae: 0.7457 - val_loss: 8.7036 - val_mae: 2.2308\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0700 - mae: 0.7333 - val_loss: 10.9585 - val_mae: 2.3865\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2030 - mae: 0.7806 - val_loss: 10.5969 - val_mae: 2.4321\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0567 - mae: 0.7336 - val_loss: 9.6479 - val_mae: 2.3403\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2122 - mae: 0.8004 - val_loss: 9.4536 - val_mae: 2.2023\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1111 - mae: 0.7367 - val_loss: 10.4872 - val_mae: 2.4283\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8865 - mae: 0.6892 - val_loss: 8.9387 - val_mae: 2.1455\n",
      "Epoch 423/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1251 - mae: 0.7552 - val_loss: 10.9310 - val_mae: 2.4071\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0939 - mae: 0.7411 - val_loss: 9.6156 - val_mae: 2.2445\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0612 - mae: 0.7504 - val_loss: 11.1129 - val_mae: 2.4912\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9867 - mae: 0.7313 - val_loss: 11.1407 - val_mae: 2.5121\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1302 - mae: 0.7679 - val_loss: 8.9139 - val_mae: 2.2218\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9503 - mae: 0.7296 - val_loss: 9.0943 - val_mae: 2.1984\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0620 - mae: 0.7473 - val_loss: 9.8676 - val_mae: 2.2461\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0550 - mae: 0.7337 - val_loss: 10.1796 - val_mae: 2.3236\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9849 - mae: 0.7397 - val_loss: 10.3050 - val_mae: 2.3412\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9704 - mae: 0.7156 - val_loss: 8.8468 - val_mae: 2.0438\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0875 - mae: 0.7533 - val_loss: 9.9996 - val_mae: 2.2683\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9849 - mae: 0.7223 - val_loss: 10.5927 - val_mae: 2.3498\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0991 - mae: 0.7992 - val_loss: 9.8525 - val_mae: 2.2423\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9908 - mae: 0.6568 - val_loss: 11.2109 - val_mae: 2.5165\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9465 - mae: 0.7278 - val_loss: 10.0987 - val_mae: 2.3416\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0505 - mae: 0.7257 - val_loss: 11.0087 - val_mae: 2.4634\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9886 - mae: 0.7423 - val_loss: 10.1801 - val_mae: 2.2473\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9825 - mae: 0.7196 - val_loss: 9.5789 - val_mae: 2.1750\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1137 - mae: 0.7503 - val_loss: 9.2884 - val_mae: 2.1110\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0600 - mae: 0.7764 - val_loss: 9.1958 - val_mae: 2.1591\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9447 - mae: 0.7212 - val_loss: 9.5635 - val_mae: 2.2520\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1156 - mae: 0.7807 - val_loss: 10.2088 - val_mae: 2.3348\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0224 - mae: 0.7452 - val_loss: 10.2849 - val_mae: 2.4044\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0983 - mae: 0.7642 - val_loss: 9.5397 - val_mae: 2.1795\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9925 - mae: 0.7243 - val_loss: 9.1919 - val_mae: 2.2244\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9068 - mae: 0.7250 - val_loss: 10.3772 - val_mae: 2.3573\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0768 - mae: 0.7234 - val_loss: 10.3157 - val_mae: 2.3495\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9599 - mae: 0.7133 - val_loss: 9.1298 - val_mae: 2.2080\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0886 - mae: 0.7367 - val_loss: 10.0255 - val_mae: 2.3837\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9748 - mae: 0.7388 - val_loss: 10.1213 - val_mae: 2.3125\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9942 - mae: 0.7030 - val_loss: 10.5980 - val_mae: 2.3991\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9504 - mae: 0.7127 - val_loss: 11.3550 - val_mae: 2.5663\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0262 - mae: 0.7222 - val_loss: 10.4099 - val_mae: 2.3350\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0704 - mae: 0.7465 - val_loss: 9.1929 - val_mae: 2.2280\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9653 - mae: 0.7186 - val_loss: 9.0880 - val_mae: 2.1886\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0175 - mae: 0.7378 - val_loss: 9.7929 - val_mae: 2.2197\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9285 - mae: 0.7055 - val_loss: 9.9038 - val_mae: 2.2615\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0289 - mae: 0.7490 - val_loss: 9.3638 - val_mae: 2.2057\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9821 - mae: 0.7432 - val_loss: 9.3560 - val_mae: 2.2900\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9182 - mae: 0.7046 - val_loss: 9.5764 - val_mae: 2.3615\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 0.8739 - mae: 0.6846 - val_loss: 9.0641 - val_mae: 2.1801\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9481 - mae: 0.7090 - val_loss: 9.5019 - val_mae: 2.2101\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0380 - mae: 0.7395 - val_loss: 9.6040 - val_mae: 2.2718\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0525 - mae: 0.7263 - val_loss: 9.1607 - val_mae: 2.2132\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9568 - mae: 0.7154 - val_loss: 11.1589 - val_mae: 2.4781\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8490 - mae: 0.6872 - val_loss: 9.5450 - val_mae: 2.3082\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9176 - mae: 0.7353 - val_loss: 10.4481 - val_mae: 2.2708\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9786 - mae: 0.7430 - val_loss: 9.3431 - val_mae: 2.2408\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9837 - mae: 0.7319 - val_loss: 11.0426 - val_mae: 2.4508\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9209 - mae: 0.6798 - val_loss: 9.9891 - val_mae: 2.2358\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0208 - mae: 0.7239 - val_loss: 9.8234 - val_mae: 2.2665\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8331 - mae: 0.6802 - val_loss: 12.9614 - val_mae: 2.6447\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0610 - mae: 0.7356 - val_loss: 11.1564 - val_mae: 2.3921\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9488 - mae: 0.6999 - val_loss: 10.4985 - val_mae: 2.2849\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8753 - mae: 0.6834 - val_loss: 11.9310 - val_mae: 2.5613\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9878 - mae: 0.6933 - val_loss: 10.8425 - val_mae: 2.3863\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9237 - mae: 0.7123 - val_loss: 10.6111 - val_mae: 2.3462\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8926 - mae: 0.6636 - val_loss: 10.1920 - val_mae: 2.3215\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9376 - mae: 0.7024 - val_loss: 12.4885 - val_mae: 2.5777\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9476 - mae: 0.7422 - val_loss: 9.8821 - val_mae: 2.2167\n",
      "Epoch 483/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9186 - mae: 0.7048 - val_loss: 10.4772 - val_mae: 2.3288\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9115 - mae: 0.6966 - val_loss: 10.2844 - val_mae: 2.3159\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8999 - mae: 0.6669 - val_loss: 12.5189 - val_mae: 2.6214\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9585 - mae: 0.7204 - val_loss: 9.5305 - val_mae: 2.1539\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7531 - mae: 0.6314 - val_loss: 11.1984 - val_mae: 2.3431\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9911 - mae: 0.7268 - val_loss: 10.2159 - val_mae: 2.3132\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8541 - mae: 0.6973 - val_loss: 9.7044 - val_mae: 2.1854\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9568 - mae: 0.7178 - val_loss: 9.9780 - val_mae: 2.2315\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8059 - mae: 0.6791 - val_loss: 10.8614 - val_mae: 2.2917\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8484 - mae: 0.6683 - val_loss: 10.0066 - val_mae: 2.2135\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9580 - mae: 0.7028 - val_loss: 10.3325 - val_mae: 2.2754\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9269 - mae: 0.6891 - val_loss: 9.7882 - val_mae: 2.1999\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9023 - mae: 0.6876 - val_loss: 9.3979 - val_mae: 2.2576\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9157 - mae: 0.6882 - val_loss: 8.3561 - val_mae: 2.0871\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9190 - mae: 0.6769 - val_loss: 9.0756 - val_mae: 2.1185\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9078 - mae: 0.6748 - val_loss: 9.8507 - val_mae: 2.2681\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9421 - mae: 0.7141 - val_loss: 9.5313 - val_mae: 2.1956\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9455 - mae: 0.6937 - val_loss: 9.6010 - val_mae: 2.1764\n",
      "처리중인 폴드 # 1\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 192.8679 - mae: 10.1310 - val_loss: 34.6672 - val_mae: 4.5629\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 30.5524 - mae: 3.6631 - val_loss: 17.8070 - val_mae: 3.0642\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 21.3541 - mae: 3.0062 - val_loss: 16.8036 - val_mae: 3.0403\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 18.0873 - mae: 2.7366 - val_loss: 15.0700 - val_mae: 2.9203\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 15.2725 - mae: 2.6142 - val_loss: 12.6438 - val_mae: 2.7077\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 14.1671 - mae: 2.5029 - val_loss: 12.9138 - val_mae: 2.6319\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 13.3466 - mae: 2.4241 - val_loss: 12.9615 - val_mae: 2.7599\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 13.1041 - mae: 2.3309 - val_loss: 12.1744 - val_mae: 2.7155\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 12.2540 - mae: 2.3618 - val_loss: 11.9030 - val_mae: 2.5945\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.3558 - mae: 2.2507 - val_loss: 11.4825 - val_mae: 2.5666\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.8791 - mae: 2.1496 - val_loss: 10.4898 - val_mae: 2.4667\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 10.5431 - mae: 2.1583 - val_loss: 12.8521 - val_mae: 2.7675\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.6007 - mae: 2.1221 - val_loss: 9.6679 - val_mae: 2.3928\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.1193 - mae: 2.1486 - val_loss: 9.9101 - val_mae: 2.3867\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.4192 - mae: 2.1470 - val_loss: 10.2953 - val_mae: 2.4539\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.4839 - mae: 2.0699 - val_loss: 10.3661 - val_mae: 2.4918\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.8540 - mae: 2.0629 - val_loss: 10.6561 - val_mae: 2.5190\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.2057 - mae: 1.9863 - val_loss: 10.9842 - val_mae: 2.4948\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.1064 - mae: 1.9842 - val_loss: 10.5791 - val_mae: 2.5133\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.6178 - mae: 2.0193 - val_loss: 11.2088 - val_mae: 2.5589\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.3813 - mae: 1.9276 - val_loss: 10.3315 - val_mae: 2.4458\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.3771 - mae: 1.9815 - val_loss: 9.8386 - val_mae: 2.4359\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.8261 - mae: 1.9662 - val_loss: 9.7462 - val_mae: 2.3629\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.2047 - mae: 1.9418 - val_loss: 9.4970 - val_mae: 2.3524\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.8244 - mae: 1.9301 - val_loss: 8.4996 - val_mae: 2.2465\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.8583 - mae: 1.9226 - val_loss: 9.1702 - val_mae: 2.3153\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.2381 - mae: 1.9127 - val_loss: 9.7644 - val_mae: 2.3942\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.1164 - mae: 1.9078 - val_loss: 8.7281 - val_mae: 2.2562\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9233 - mae: 1.9292 - val_loss: 8.8859 - val_mae: 2.2659\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.3288 - mae: 1.8886 - val_loss: 9.0263 - val_mae: 2.2661\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.1487 - mae: 1.8672 - val_loss: 8.9719 - val_mae: 2.2852\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.4212 - mae: 1.8472 - val_loss: 9.1272 - val_mae: 2.3162\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.1238 - mae: 1.8317 - val_loss: 10.4510 - val_mae: 2.4519\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.1131 - mae: 1.7926 - val_loss: 11.2406 - val_mae: 2.5819\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.4997 - mae: 1.7598 - val_loss: 8.9923 - val_mae: 2.3369\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.5359 - mae: 1.7538 - val_loss: 8.6444 - val_mae: 2.2735\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5513 - mae: 1.8224 - val_loss: 9.0388 - val_mae: 2.3039\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.8378 - mae: 1.8444 - val_loss: 9.2510 - val_mae: 2.2934\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.4590 - mae: 1.7752 - val_loss: 8.4195 - val_mae: 2.2095\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.5869 - mae: 1.7984 - val_loss: 8.9912 - val_mae: 2.2853\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.0322 - mae: 1.7286 - val_loss: 10.5231 - val_mae: 2.5261\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.3414 - mae: 1.7533 - val_loss: 9.1390 - val_mae: 2.3861\n",
      "Epoch 43/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 5ms/step - loss: 7.3037 - mae: 1.7298 - val_loss: 8.5664 - val_mae: 2.2672\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.3492 - mae: 1.7224 - val_loss: 7.6940 - val_mae: 2.1035\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.0605 - mae: 1.7551 - val_loss: 8.1833 - val_mae: 2.1875\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.5393 - mae: 1.7732 - val_loss: 7.8799 - val_mae: 2.1736\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.7548 - mae: 1.6870 - val_loss: 10.9486 - val_mae: 2.5065\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.3394 - mae: 1.7426 - val_loss: 8.2367 - val_mae: 2.1573\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.8591 - mae: 1.7305 - val_loss: 8.4864 - val_mae: 2.2244\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.9147 - mae: 1.6848 - val_loss: 8.1433 - val_mae: 2.1560\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.9635 - mae: 1.7323 - val_loss: 8.6657 - val_mae: 2.2788\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.7625 - mae: 1.7344 - val_loss: 7.3499 - val_mae: 2.0500\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.6435 - mae: 1.6948 - val_loss: 7.4702 - val_mae: 2.0640\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.7206 - mae: 1.6488 - val_loss: 8.4054 - val_mae: 2.1877\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2215 - mae: 1.6593 - val_loss: 9.8510 - val_mae: 2.4733\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1751 - mae: 1.6915 - val_loss: 8.1553 - val_mae: 2.1591\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.5932 - mae: 1.5887 - val_loss: 8.9027 - val_mae: 2.2617\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.4508 - mae: 1.6549 - val_loss: 9.2332 - val_mae: 2.4109\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.0058 - mae: 1.6379 - val_loss: 9.7592 - val_mae: 2.4429\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2881 - mae: 1.6522 - val_loss: 8.5591 - val_mae: 2.2606\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2058 - mae: 1.6241 - val_loss: 9.3674 - val_mae: 2.2614\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.2132 - mae: 1.6557 - val_loss: 9.3498 - val_mae: 2.4203\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.1656 - mae: 1.5930 - val_loss: 7.9944 - val_mae: 2.2011\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.2139 - mae: 1.5519 - val_loss: 9.5907 - val_mae: 2.3416\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.1131 - mae: 1.6203 - val_loss: 8.5120 - val_mae: 2.1540\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7559 - mae: 1.5782 - val_loss: 8.7074 - val_mae: 2.2454\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8201 - mae: 1.6326 - val_loss: 8.0443 - val_mae: 2.1721\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6370 - mae: 1.5628 - val_loss: 9.7534 - val_mae: 2.3476\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8983 - mae: 1.6193 - val_loss: 8.9611 - val_mae: 2.2874\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7381 - mae: 1.5997 - val_loss: 8.7494 - val_mae: 2.2217\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8283 - mae: 1.5583 - val_loss: 8.4164 - val_mae: 2.1743\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4721 - mae: 1.5622 - val_loss: 9.2736 - val_mae: 2.3547\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7115 - mae: 1.5626 - val_loss: 7.7478 - val_mae: 2.0809\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.3474 - mae: 1.5264 - val_loss: 9.2637 - val_mae: 2.3658\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3537 - mae: 1.4605 - val_loss: 8.9902 - val_mae: 2.2746\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.8208 - mae: 1.4952 - val_loss: 8.1383 - val_mae: 2.1791\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4512 - mae: 1.5559 - val_loss: 8.7940 - val_mae: 2.2177\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3182 - mae: 1.4865 - val_loss: 13.1528 - val_mae: 2.7242\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.9876 - mae: 1.5030 - val_loss: 9.8491 - val_mae: 2.4495\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.2490 - mae: 1.4827 - val_loss: 9.1293 - val_mae: 2.3089\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.9038 - mae: 1.4629 - val_loss: 8.3608 - val_mae: 2.1507\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4091 - mae: 1.5192 - val_loss: 8.5830 - val_mae: 2.2632\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.1170 - mae: 1.4792 - val_loss: 9.5142 - val_mae: 2.3065\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.1647 - mae: 1.4647 - val_loss: 8.9755 - val_mae: 2.2522\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.1479 - mae: 1.4752 - val_loss: 8.4454 - val_mae: 2.2012\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0326 - mae: 1.4539 - val_loss: 7.9668 - val_mae: 2.1063\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.8954 - mae: 1.4832 - val_loss: 8.8252 - val_mae: 2.2391\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8187 - mae: 1.4874 - val_loss: 10.4774 - val_mae: 2.5203\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8270 - mae: 1.4940 - val_loss: 10.6239 - val_mae: 2.3825\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0407 - mae: 1.4607 - val_loss: 10.0795 - val_mae: 2.4046\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8958 - mae: 1.4373 - val_loss: 9.9244 - val_mae: 2.3817\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.7927 - mae: 1.4531 - val_loss: 8.9041 - val_mae: 2.2576\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.9370 - mae: 1.4499 - val_loss: 9.1641 - val_mae: 2.2942\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.6651 - mae: 1.4331 - val_loss: 10.3603 - val_mae: 2.4218\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4650 - mae: 1.4170 - val_loss: 8.7011 - val_mae: 2.2064\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.6550 - mae: 1.4284 - val_loss: 11.0284 - val_mae: 2.4721\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6893 - mae: 1.4488 - val_loss: 8.6716 - val_mae: 2.2036\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.8576 - mae: 1.4391 - val_loss: 12.0929 - val_mae: 2.6324\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2414 - mae: 1.3021 - val_loss: 8.8844 - val_mae: 2.1872\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5977 - mae: 1.4059 - val_loss: 9.0710 - val_mae: 2.2433\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1212 - mae: 1.3931 - val_loss: 14.8566 - val_mae: 2.9266\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1279 - mae: 1.3914 - val_loss: 9.5624 - val_mae: 2.3459\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.4620 - mae: 1.4105 - val_loss: 8.9948 - val_mae: 2.2173\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 4.3346 - mae: 1.3945 - val_loss: 13.4565 - val_mae: 2.7538\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.9183 - mae: 1.3440 - val_loss: 10.2604 - val_mae: 2.3483\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.2103 - mae: 1.3332 - val_loss: 11.4249 - val_mae: 2.4272\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.3268 - mae: 1.3721 - val_loss: 9.1698 - val_mae: 2.1851\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1768 - mae: 1.3696 - val_loss: 10.8163 - val_mae: 2.3925\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2202 - mae: 1.3548 - val_loss: 10.3801 - val_mae: 2.4139\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6815 - mae: 1.3363 - val_loss: 10.6642 - val_mae: 2.3863\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2949 - mae: 1.4398 - val_loss: 9.0974 - val_mae: 2.2430\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9521 - mae: 1.3359 - val_loss: 11.5062 - val_mae: 2.4982\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1095 - mae: 1.3266 - val_loss: 10.7618 - val_mae: 2.3970\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4559 - mae: 1.4076 - val_loss: 10.8887 - val_mae: 2.3553\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0036 - mae: 1.2575 - val_loss: 10.8123 - val_mae: 2.4200\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.0989 - mae: 1.3127 - val_loss: 10.6591 - val_mae: 2.4200\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0837 - mae: 1.3409 - val_loss: 12.3845 - val_mae: 2.5299\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6455 - mae: 1.3076 - val_loss: 11.2453 - val_mae: 2.3544\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0745 - mae: 1.3275 - val_loss: 16.0546 - val_mae: 2.8806\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.6357 - mae: 1.2913 - val_loss: 11.8660 - val_mae: 2.5489\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9051 - mae: 1.3268 - val_loss: 10.7965 - val_mae: 2.4761\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8478 - mae: 1.3091 - val_loss: 12.2803 - val_mae: 2.3625\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7276 - mae: 1.2977 - val_loss: 12.4592 - val_mae: 2.5118\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6969 - mae: 1.2770 - val_loss: 11.8377 - val_mae: 2.4184\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.6674 - mae: 1.3855 - val_loss: 12.5710 - val_mae: 2.5404\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5368 - mae: 1.2872 - val_loss: 19.9377 - val_mae: 3.6173\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8135 - mae: 1.2656 - val_loss: 9.8514 - val_mae: 2.3057\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.6150 - mae: 1.249 - 1s 4ms/step - loss: 3.6502 - mae: 1.2614 - val_loss: 9.9022 - val_mae: 2.3312\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4458 - mae: 1.2504 - val_loss: 11.3253 - val_mae: 2.4233\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6776 - mae: 1.3199 - val_loss: 11.3847 - val_mae: 2.5080\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5070 - mae: 1.2705 - val_loss: 11.6404 - val_mae: 2.4618\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.2697 - mae: 1.2131 - val_loss: 21.6069 - val_mae: 3.3144\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2540 - mae: 1.2566 - val_loss: 13.4659 - val_mae: 2.5702\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.5598 - mae: 1.2403 - val_loss: 11.4139 - val_mae: 2.4442\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4234 - mae: 1.2702 - val_loss: 12.7212 - val_mae: 2.6429\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.3822 - mae: 1.2098 - val_loss: 12.3925 - val_mae: 2.6103\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3655 - mae: 1.2707 - val_loss: 11.7205 - val_mae: 2.4232\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.4520 - mae: 1.2743 - val_loss: 11.7159 - val_mae: 2.4106\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3486 - mae: 1.1941 - val_loss: 14.4627 - val_mae: 2.5962\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5356 - mae: 1.2580 - val_loss: 12.5843 - val_mae: 2.4597\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.1106 - mae: 1.1847 - val_loss: 13.1778 - val_mae: 2.5824\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5449 - mae: 1.2682 - val_loss: 13.3037 - val_mae: 2.5311\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9863 - mae: 1.1898 - val_loss: 12.7800 - val_mae: 2.5904\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9696 - mae: 1.1411 - val_loss: 13.5562 - val_mae: 2.5751\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1793 - mae: 1.1453 - val_loss: 16.1112 - val_mae: 2.8448\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9883 - mae: 1.1578 - val_loss: 10.3160 - val_mae: 2.2641\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.1554 - mae: 1.2341 - val_loss: 16.2933 - val_mae: 2.7098\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0305 - mae: 1.1633 - val_loss: 9.9965 - val_mae: 2.2831\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9623 - mae: 1.2286 - val_loss: 13.1983 - val_mae: 2.5642\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2271 - mae: 1.2356 - val_loss: 12.7359 - val_mae: 2.5201\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8831 - mae: 1.1874 - val_loss: 14.3423 - val_mae: 2.7894\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0120 - mae: 1.2207 - val_loss: 12.7145 - val_mae: 2.4038\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1700 - mae: 1.1396 - val_loss: 15.3643 - val_mae: 2.7530\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8682 - mae: 1.1982 - val_loss: 17.7963 - val_mae: 3.0452\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1792 - mae: 1.2610 - val_loss: 13.9621 - val_mae: 2.6202\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.8228 - mae: 1.1507 - val_loss: 12.6429 - val_mae: 2.6047\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1406 - mae: 1.1951 - val_loss: 13.0984 - val_mae: 2.5185\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9942 - mae: 1.1962 - val_loss: 15.5204 - val_mae: 2.6892\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1493 - mae: 1.1864 - val_loss: 16.2445 - val_mae: 2.7965\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8770 - mae: 1.1885 - val_loss: 15.2965 - val_mae: 2.7147\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8244 - mae: 1.1457 - val_loss: 16.1196 - val_mae: 2.6987\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8687 - mae: 1.1785 - val_loss: 13.0182 - val_mae: 2.4437\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.0149 - mae: 1.2314 - val_loss: 16.3821 - val_mae: 2.8728\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0207 - mae: 1.1814 - val_loss: 14.6860 - val_mae: 2.5425\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7491 - mae: 1.1640 - val_loss: 14.8440 - val_mae: 2.6335\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0001 - mae: 1.2007 - val_loss: 12.4506 - val_mae: 2.4458\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7695 - mae: 1.1288 - val_loss: 14.8849 - val_mae: 2.6175\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8298 - mae: 1.1320 - val_loss: 13.4764 - val_mae: 2.5748\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7539 - mae: 1.1378 - val_loss: 16.0225 - val_mae: 2.5906\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.6764 - mae: 1.1160 - val_loss: 13.1084 - val_mae: 2.5441\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7888 - mae: 1.1167 - val_loss: 18.0040 - val_mae: 3.0030\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8033 - mae: 1.1513 - val_loss: 16.4946 - val_mae: 2.9023\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5906 - mae: 1.0599 - val_loss: 16.3728 - val_mae: 2.6858\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4407 - mae: 1.1103 - val_loss: 14.4722 - val_mae: 2.5366\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7787 - mae: 1.1588 - val_loss: 18.5502 - val_mae: 2.8496\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.7969 - mae: 1.0950 - val_loss: 13.0503 - val_mae: 2.5022\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6911 - mae: 1.1699 - val_loss: 16.7883 - val_mae: 2.6035\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8181 - mae: 1.1243 - val_loss: 14.7972 - val_mae: 2.5863\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5984 - mae: 1.0929 - val_loss: 17.2063 - val_mae: 2.9375\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5342 - mae: 1.0666 - val_loss: 18.9436 - val_mae: 2.7349\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5585 - mae: 1.1252 - val_loss: 17.0467 - val_mae: 2.7505\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6243 - mae: 1.0947 - val_loss: 14.7966 - val_mae: 2.6710\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5642 - mae: 1.1000 - val_loss: 18.5669 - val_mae: 2.8251\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2825 - mae: 1.0429 - val_loss: 23.2411 - val_mae: 3.0061\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5250 - mae: 1.0977 - val_loss: 23.3406 - val_mae: 3.0561\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6114 - mae: 1.0806 - val_loss: 17.5956 - val_mae: 2.6665\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3974 - mae: 1.1084 - val_loss: 14.6240 - val_mae: 2.5782\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2241 - mae: 1.0313 - val_loss: 19.5400 - val_mae: 2.8353\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4492 - mae: 1.0941 - val_loss: 14.4694 - val_mae: 2.5049\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4274 - mae: 1.0989 - val_loss: 16.9829 - val_mae: 2.7704\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 2.4018 - mae: 1.1048 - val_loss: 15.8312 - val_mae: 2.8428\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4139 - mae: 1.0646 - val_loss: 22.6762 - val_mae: 3.0739\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.2801 - mae: 1.0225 - val_loss: 20.9368 - val_mae: 2.8467\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.3481 - mae: 1.0558 - val_loss: 17.1008 - val_mae: 2.7437\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2522 - mae: 1.0516 - val_loss: 21.0676 - val_mae: 3.0339\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4308 - mae: 1.0521 - val_loss: 21.4022 - val_mae: 3.0943\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5030 - mae: 1.0913 - val_loss: 22.9981 - val_mae: 2.9094\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3230 - mae: 1.1049 - val_loss: 20.5643 - val_mae: 2.9489\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5683 - mae: 1.0719 - val_loss: 20.4855 - val_mae: 2.9298\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.3931 - mae: 1.0670 - val_loss: 17.6987 - val_mae: 2.6595\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2207 - mae: 1.0363 - val_loss: 16.1700 - val_mae: 2.7175\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.3659 - mae: 1.1025 - val_loss: 18.0392 - val_mae: 2.7791\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4003 - mae: 1.0698 - val_loss: 17.5781 - val_mae: 2.8265\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3068 - mae: 1.0593 - val_loss: 34.4278 - val_mae: 3.6038\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4712 - mae: 1.0959 - val_loss: 23.9729 - val_mae: 3.1732\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5215 - mae: 1.1227 - val_loss: 16.7720 - val_mae: 2.6880\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2453 - mae: 1.0190 - val_loss: 23.0933 - val_mae: 3.0677\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3142 - mae: 1.0803 - val_loss: 17.8297 - val_mae: 2.9232\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0725 - mae: 1.0146 - val_loss: 22.3217 - val_mae: 3.2526\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8303 - mae: 1.0105 - val_loss: 24.7663 - val_mae: 3.1757\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2403 - mae: 1.0384 - val_loss: 24.8194 - val_mae: 3.0214\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0914 - mae: 0.9990 - val_loss: 17.3776 - val_mae: 2.7252\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0917 - mae: 1.0541 - val_loss: 20.4348 - val_mae: 2.8212\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1812 - mae: 1.0287 - val_loss: 15.9430 - val_mae: 2.6456\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1859 - mae: 1.0023 - val_loss: 18.5774 - val_mae: 2.7828\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.2111 - mae: 1.0235 - val_loss: 19.3313 - val_mae: 2.7666\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1288 - mae: 1.0382 - val_loss: 27.0846 - val_mae: 3.5748\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0439 - mae: 1.0175 - val_loss: 19.7735 - val_mae: 2.8563\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2554 - mae: 1.0510 - val_loss: 21.5980 - val_mae: 2.8211\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9834 - mae: 0.9862 - val_loss: 22.4374 - val_mae: 3.0884\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0397 - mae: 1.0476 - val_loss: 17.2370 - val_mae: 2.8052\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0437 - mae: 1.0443 - val_loss: 18.6602 - val_mae: 2.8655\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8676 - mae: 0.9717 - val_loss: 21.8812 - val_mae: 2.7955\n",
      "Epoch 224/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8512 - mae: 0.9933 - val_loss: 17.0553 - val_mae: 2.6363\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0143 - mae: 1.0252 - val_loss: 20.4165 - val_mae: 3.0103\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2806 - mae: 1.0495 - val_loss: 16.7474 - val_mae: 2.7922\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6448 - mae: 0.9406 - val_loss: 27.0933 - val_mae: 3.1611\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0007 - mae: 1.0171 - val_loss: 14.9852 - val_mae: 2.5999\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8005 - mae: 0.9675 - val_loss: 21.3767 - val_mae: 2.8319\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8926 - mae: 0.9828 - val_loss: 24.4153 - val_mae: 3.2793\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.9519 - mae: 1.0172 - val_loss: 20.1166 - val_mae: 2.8181\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7428 - mae: 0.9647 - val_loss: 17.3129 - val_mae: 2.7520\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9487 - mae: 0.9987 - val_loss: 21.4815 - val_mae: 3.0287\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9500 - mae: 0.9748 - val_loss: 19.9148 - val_mae: 3.0066\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9180 - mae: 0.9519 - val_loss: 21.7509 - val_mae: 3.0395\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9277 - mae: 0.9754 - val_loss: 18.4652 - val_mae: 2.7457\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0626 - mae: 0.9978 - val_loss: 18.2723 - val_mae: 2.8256\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.7912 - mae: 0.9610 - val_loss: 15.3429 - val_mae: 2.6243\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9234 - mae: 1.0016 - val_loss: 22.3504 - val_mae: 3.0471\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6467 - mae: 0.9213 - val_loss: 17.5482 - val_mae: 2.6830\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9008 - mae: 0.9860 - val_loss: 14.7653 - val_mae: 2.6417\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8447 - mae: 0.9916 - val_loss: 19.5765 - val_mae: 2.8849\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7411 - mae: 0.9636 - val_loss: 17.4137 - val_mae: 2.6761\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8025 - mae: 0.9774 - val_loss: 18.6936 - val_mae: 2.7990\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7922 - mae: 1.0035 - val_loss: 14.5422 - val_mae: 2.5943\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6734 - mae: 0.9281 - val_loss: 19.8479 - val_mae: 2.9005\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8128 - mae: 1.0117 - val_loss: 18.1421 - val_mae: 2.7959\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6086 - mae: 0.9185 - val_loss: 18.2167 - val_mae: 2.8618\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7790 - mae: 0.9659 - val_loss: 18.6357 - val_mae: 2.6982\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7752 - mae: 0.9329 - val_loss: 19.7018 - val_mae: 2.9379\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6326 - mae: 0.9279 - val_loss: 18.0778 - val_mae: 2.7956\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6480 - mae: 0.9450 - val_loss: 21.5115 - val_mae: 2.9620\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7164 - mae: 0.9276 - val_loss: 16.3591 - val_mae: 2.6064\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7931 - mae: 1.0117 - val_loss: 20.7580 - val_mae: 2.8462\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.7137 - mae: 0.9151 - val_loss: 18.8815 - val_mae: 2.7697\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6106 - mae: 0.9187 - val_loss: 21.5736 - val_mae: 2.9672\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7171 - mae: 0.9302 - val_loss: 17.7076 - val_mae: 2.8275\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4500 - mae: 0.9281 - val_loss: 17.1590 - val_mae: 2.7543\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6085 - mae: 0.9375 - val_loss: 15.6947 - val_mae: 2.5633\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4956 - mae: 0.8879 - val_loss: 21.3038 - val_mae: 3.0037\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7986 - mae: 0.9305 - val_loss: 23.6824 - val_mae: 2.9519\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7600 - mae: 0.9738 - val_loss: 17.5927 - val_mae: 2.7615\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4965 - mae: 0.9061 - val_loss: 20.4333 - val_mae: 2.9180\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5970 - mae: 0.9320 - val_loss: 17.1762 - val_mae: 2.7104\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6181 - mae: 0.9667 - val_loss: 18.1671 - val_mae: 2.6621\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6656 - mae: 0.9374 - val_loss: 23.5960 - val_mae: 3.1504\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.7488 - mae: 0.9618 - val_loss: 16.4300 - val_mae: 2.8008\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4757 - mae: 0.9388 - val_loss: 24.4438 - val_mae: 2.9763\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.7217 - mae: 0.9189 - val_loss: 21.0559 - val_mae: 3.0200\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5847 - mae: 0.9278 - val_loss: 17.7400 - val_mae: 2.7746\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5255 - mae: 0.8834 - val_loss: 24.7043 - val_mae: 2.8790\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4702 - mae: 0.8921 - val_loss: 23.8225 - val_mae: 2.9911\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5916 - mae: 0.8984 - val_loss: 20.7501 - val_mae: 2.8445\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6406 - mae: 0.9190 - val_loss: 19.7693 - val_mae: 2.8012\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5227 - mae: 0.9327 - val_loss: 18.8481 - val_mae: 2.7652\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5373 - mae: 0.9001 - val_loss: 21.0296 - val_mae: 2.8227\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5808 - mae: 0.9092 - val_loss: 19.2678 - val_mae: 2.7359\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5439 - mae: 0.8854 - val_loss: 18.3130 - val_mae: 2.6998\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 1.6990 - mae: 0.9399 - val_loss: 20.2376 - val_mae: 2.9479\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 1.4492 - mae: 0.8941 - val_loss: 21.4092 - val_mae: 2.8410\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 1.4337 - mae: 0.8879 - val_loss: 22.3821 - val_mae: 2.9903\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5195 - mae: 0.8678 - val_loss: 31.3539 - val_mae: 3.6103\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5182 - mae: 0.9054 - val_loss: 19.9170 - val_mae: 2.7980\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4781 - mae: 0.8715 - val_loss: 25.4237 - val_mae: 3.3780\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3728 - mae: 0.9085 - val_loss: 16.5200 - val_mae: 2.7188\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4514 - mae: 0.8739 - val_loss: 23.1972 - val_mae: 2.9269\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4793 - mae: 0.8622 - val_loss: 22.3921 - val_mae: 2.9679\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5654 - mae: 0.9167 - val_loss: 25.1238 - val_mae: 3.1727\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.4955 - mae: 0.8920 - val_loss: 24.6781 - val_mae: 3.2868\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3952 - mae: 0.9256 - val_loss: 20.1013 - val_mae: 2.8753\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3655 - mae: 0.8699 - val_loss: 19.8307 - val_mae: 2.7955\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2907 - mae: 0.8536 - val_loss: 18.7255 - val_mae: 2.8626\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5766 - mae: 0.9034 - val_loss: 18.5966 - val_mae: 2.7328\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4219 - mae: 0.8858 - val_loss: 24.2734 - val_mae: 3.1081\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4753 - mae: 0.8825 - val_loss: 24.4033 - val_mae: 3.1531\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3387 - mae: 0.8665 - val_loss: 21.8124 - val_mae: 2.8429\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4138 - mae: 0.8458 - val_loss: 22.5792 - val_mae: 2.9474\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4274 - mae: 0.8929 - val_loss: 24.1316 - val_mae: 2.9547\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3652 - mae: 0.8882 - val_loss: 18.4314 - val_mae: 2.8417\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4095 - mae: 0.8918 - val_loss: 23.7610 - val_mae: 3.2051\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4208 - mae: 0.8839 - val_loss: 21.6116 - val_mae: 2.9980\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3567 - mae: 0.8400 - val_loss: 19.2378 - val_mae: 2.9783\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5615 - mae: 0.9359 - val_loss: 22.7401 - val_mae: 3.0408\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.4380 - mae: 0.8662 - val_loss: 22.0338 - val_mae: 3.0115\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3551 - mae: 0.8594 - val_loss: 16.4427 - val_mae: 2.6403\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2999 - mae: 0.8655 - val_loss: 20.2493 - val_mae: 2.9372\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2294 - mae: 0.8429 - val_loss: 21.1928 - val_mae: 2.8755\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4733 - mae: 0.8974 - val_loss: 20.2594 - val_mae: 2.9190\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4048 - mae: 0.8422 - val_loss: 19.1147 - val_mae: 2.7887\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2922 - mae: 0.8566 - val_loss: 27.6878 - val_mae: 3.2106\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4356 - mae: 0.8935 - val_loss: 21.8701 - val_mae: 2.8765\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3114 - mae: 0.8545 - val_loss: 21.2937 - val_mae: 2.7885\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3220 - mae: 0.8536 - val_loss: 18.4697 - val_mae: 2.8105\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4233 - mae: 0.8639 - val_loss: 29.6181 - val_mae: 3.3983\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5158 - mae: 0.8707 - val_loss: 22.0108 - val_mae: 2.9762\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2536 - mae: 0.8099 - val_loss: 24.8504 - val_mae: 2.9867\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3549 - mae: 0.8575 - val_loss: 19.9091 - val_mae: 2.7532\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4162 - mae: 0.8836 - val_loss: 19.3462 - val_mae: 2.7389\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2606 - mae: 0.8269 - val_loss: 20.1628 - val_mae: 2.7591\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3592 - mae: 0.8292 - val_loss: 14.4832 - val_mae: 2.5443\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2911 - mae: 0.8301 - val_loss: 20.4881 - val_mae: 2.9560\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3323 - mae: 0.8458 - val_loss: 26.7254 - val_mae: 3.3204\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3629 - mae: 0.8826 - val_loss: 23.1854 - val_mae: 2.9825\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3482 - mae: 0.8488 - val_loss: 23.9216 - val_mae: 3.1785\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2378 - mae: 0.8313 - val_loss: 18.9949 - val_mae: 2.7960\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3460 - mae: 0.8287 - val_loss: 20.9659 - val_mae: 3.0120\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3329 - mae: 0.8398 - val_loss: 18.7354 - val_mae: 2.7369\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1427 - mae: 0.7873 - val_loss: 23.5455 - val_mae: 3.0331\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2686 - mae: 0.8095 - val_loss: 20.4707 - val_mae: 2.9196\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2884 - mae: 0.8515 - val_loss: 15.6585 - val_mae: 2.6108\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2609 - mae: 0.8245 - val_loss: 20.2779 - val_mae: 2.8229\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3498 - mae: 0.8703 - val_loss: 15.6217 - val_mae: 2.6249\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2951 - mae: 0.8585 - val_loss: 22.8600 - val_mae: 3.0432\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3196 - mae: 0.8505 - val_loss: 20.5769 - val_mae: 2.9281\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1773 - mae: 0.8090 - val_loss: 19.3553 - val_mae: 2.9732\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1935 - mae: 0.8182 - val_loss: 17.2862 - val_mae: 2.7817\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1825 - mae: 0.8056 - val_loss: 18.7155 - val_mae: 2.8920\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2834 - mae: 0.8326 - val_loss: 20.8326 - val_mae: 2.9754\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1720 - mae: 0.7961 - val_loss: 19.5306 - val_mae: 2.8956\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2565 - mae: 0.8187 - val_loss: 21.8273 - val_mae: 3.0890\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2173 - mae: 0.7937 - val_loss: 21.9602 - val_mae: 3.0873\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1486 - mae: 0.7846 - val_loss: 20.4550 - val_mae: 2.7484\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3063 - mae: 0.8020 - val_loss: 20.3121 - val_mae: 2.8423\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1493 - mae: 0.7863 - val_loss: 19.6163 - val_mae: 2.7363\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1979 - mae: 0.8195 - val_loss: 20.0109 - val_mae: 2.8071\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2931 - mae: 0.8151 - val_loss: 17.6828 - val_mae: 2.7533\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2308 - mae: 0.8337 - val_loss: 16.3480 - val_mae: 2.6109\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3258 - mae: 0.8644 - val_loss: 24.3250 - val_mae: 3.0227\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1237 - mae: 0.7933 - val_loss: 22.1341 - val_mae: 2.9682\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3211 - mae: 0.8329 - val_loss: 18.4149 - val_mae: 2.5955\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1904 - mae: 0.8078 - val_loss: 20.5141 - val_mae: 2.7910\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0733 - mae: 0.7884 - val_loss: 18.8655 - val_mae: 2.7992\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1315 - mae: 0.8156 - val_loss: 22.7467 - val_mae: 3.0637\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2265 - mae: 0.8160 - val_loss: 17.9845 - val_mae: 2.7700\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1380 - mae: 0.7957 - val_loss: 17.9361 - val_mae: 2.6271\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1364 - mae: 0.8139 - val_loss: 18.2208 - val_mae: 2.6699\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0851 - mae: 0.7891 - val_loss: 23.3772 - val_mae: 3.0082\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3335 - mae: 0.8312 - val_loss: 15.9204 - val_mae: 2.6296\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1698 - mae: 0.8211 - val_loss: 21.2767 - val_mae: 2.9354\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2662 - mae: 0.8147 - val_loss: 18.0382 - val_mae: 2.6883\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0102 - mae: 0.7621 - val_loss: 18.4688 - val_mae: 2.7021\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0898 - mae: 0.7860 - val_loss: 17.9561 - val_mae: 2.7778\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2460 - mae: 0.8617 - val_loss: 19.7015 - val_mae: 2.7796\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1538 - mae: 0.7939 - val_loss: 20.3076 - val_mae: 3.0613\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1876 - mae: 0.7920 - val_loss: 18.9383 - val_mae: 2.8255\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0753 - mae: 0.7594 - val_loss: 16.4046 - val_mae: 2.6165\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2170 - mae: 0.8254 - val_loss: 17.7375 - val_mae: 2.7529\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1200 - mae: 0.8004 - val_loss: 17.8578 - val_mae: 2.7770\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1883 - mae: 0.8064 - val_loss: 21.2334 - val_mae: 2.9580\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1649 - mae: 0.7880 - val_loss: 18.5440 - val_mae: 2.8728\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1484 - mae: 0.7537 - val_loss: 19.2253 - val_mae: 3.0437\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1923 - mae: 0.7734 - val_loss: 21.6837 - val_mae: 3.0359\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2045 - mae: 0.7853 - val_loss: 21.1642 - val_mae: 3.0998\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1858 - mae: 0.8125 - val_loss: 19.3986 - val_mae: 2.9252\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1421 - mae: 0.7696 - val_loss: 20.9383 - val_mae: 2.9552\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1305 - mae: 0.7779 - val_loss: 16.9078 - val_mae: 2.8219\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1792 - mae: 0.7493 - val_loss: 17.1784 - val_mae: 2.9152\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0830 - mae: 0.7606 - val_loss: 20.3766 - val_mae: 2.8853\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0679 - mae: 0.7776 - val_loss: 19.6683 - val_mae: 2.9960\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2518 - mae: 0.7952 - val_loss: 18.0487 - val_mae: 2.8131\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0971 - mae: 0.7716 - val_loss: 20.2705 - val_mae: 3.0984\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1611 - mae: 0.7996 - val_loss: 20.8547 - val_mae: 2.7837\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0780 - mae: 0.7713 - val_loss: 18.5650 - val_mae: 2.7172\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0861 - mae: 0.7550 - val_loss: 18.2666 - val_mae: 2.7344\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1535 - mae: 0.7832 - val_loss: 20.6467 - val_mae: 2.9650\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0761 - mae: 0.7580 - val_loss: 15.0769 - val_mae: 2.6253\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9992 - mae: 0.7696 - val_loss: 19.1590 - val_mae: 2.9304\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0451 - mae: 0.7608 - val_loss: 15.2382 - val_mae: 2.5995\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2524 - mae: 0.7616 - val_loss: 16.1538 - val_mae: 2.5696\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0792 - mae: 0.7387 - val_loss: 19.7092 - val_mae: 2.8708\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0890 - mae: 0.7806 - val_loss: 20.0657 - val_mae: 2.9010\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9965 - mae: 0.7610 - val_loss: 19.5910 - val_mae: 2.8782\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1466 - mae: 0.7863 - val_loss: 17.7790 - val_mae: 2.8051\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9746 - mae: 0.7262 - val_loss: 18.8176 - val_mae: 2.9717\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1173 - mae: 0.7780 - val_loss: 17.7802 - val_mae: 2.8870\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0321 - mae: 0.7641 - val_loss: 16.9587 - val_mae: 2.7099\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0120 - mae: 0.7428 - val_loss: 14.5335 - val_mae: 2.6222\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1202 - mae: 0.7677 - val_loss: 17.0508 - val_mae: 2.7512\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0380 - mae: 0.7758 - val_loss: 19.5211 - val_mae: 2.8854\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9593 - mae: 0.7303 - val_loss: 17.9777 - val_mae: 2.7010\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0730 - mae: 0.7901 - val_loss: 19.4703 - val_mae: 2.8366\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0509 - mae: 0.7492 - val_loss: 19.2483 - val_mae: 2.8189\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9938 - mae: 0.7484 - val_loss: 16.2654 - val_mae: 2.6112\n",
      "Epoch 404/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1669 - mae: 0.7787 - val_loss: 21.5472 - val_mae: 3.1340\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0240 - mae: 0.7773 - val_loss: 18.4203 - val_mae: 2.7984\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9840 - mae: 0.7178 - val_loss: 22.4781 - val_mae: 3.1653\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1150 - mae: 0.7888 - val_loss: 16.1387 - val_mae: 2.6720\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0583 - mae: 0.7480 - val_loss: 16.2151 - val_mae: 2.6027\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9393 - mae: 0.7414 - val_loss: 21.0074 - val_mae: 2.8783\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0870 - mae: 0.7736 - val_loss: 18.0898 - val_mae: 2.7192\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1434 - mae: 0.7835 - val_loss: 15.3406 - val_mae: 2.7058\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0334 - mae: 0.7441 - val_loss: 18.2002 - val_mae: 2.8478\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0157 - mae: 0.7493 - val_loss: 20.6784 - val_mae: 2.9390\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1578 - mae: 0.7717 - val_loss: 16.1388 - val_mae: 2.7542\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0701 - mae: 0.7565 - val_loss: 15.2069 - val_mae: 2.6041\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0132 - mae: 0.7790 - val_loss: 15.2169 - val_mae: 2.5718\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0163 - mae: 0.7516 - val_loss: 17.7466 - val_mae: 2.7952\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9892 - mae: 0.7436 - val_loss: 15.8307 - val_mae: 2.6907\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9889 - mae: 0.7596 - val_loss: 15.1162 - val_mae: 2.6716\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9752 - mae: 0.7409 - val_loss: 15.5884 - val_mae: 2.6837\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.0698 - mae: 0.7710 - val_loss: 20.2164 - val_mae: 2.9114\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0571 - mae: 0.7487 - val_loss: 18.4241 - val_mae: 2.7706\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0022 - mae: 0.7361 - val_loss: 21.2465 - val_mae: 3.0122\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0333 - mae: 0.7379 - val_loss: 18.1148 - val_mae: 2.7490\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0143 - mae: 0.7271 - val_loss: 17.6196 - val_mae: 2.6863\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9666 - mae: 0.7355 - val_loss: 19.1866 - val_mae: 2.9712\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0464 - mae: 0.7646 - val_loss: 15.3145 - val_mae: 2.6079\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9984 - mae: 0.7433 - val_loss: 18.0838 - val_mae: 2.8764\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9756 - mae: 0.7552 - val_loss: 17.2207 - val_mae: 2.7455\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0873 - mae: 0.7768 - val_loss: 16.6794 - val_mae: 2.6293\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9526 - mae: 0.7361 - val_loss: 19.4002 - val_mae: 2.8122\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0613 - mae: 0.7416 - val_loss: 17.8870 - val_mae: 2.7991\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0666 - mae: 0.7545 - val_loss: 18.0581 - val_mae: 2.9576\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0077 - mae: 0.7506 - val_loss: 16.5353 - val_mae: 2.7337\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8598 - mae: 0.6850 - val_loss: 17.5047 - val_mae: 2.7038\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0193 - mae: 0.7505 - val_loss: 16.5353 - val_mae: 2.8296\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0218 - mae: 0.7425 - val_loss: 14.5376 - val_mae: 2.5378\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0278 - mae: 0.7364 - val_loss: 14.6955 - val_mae: 2.5763\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9650 - mae: 0.6927 - val_loss: 14.8837 - val_mae: 2.5981\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8786 - mae: 0.7006 - val_loss: 16.0484 - val_mae: 2.7109\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0200 - mae: 0.7354 - val_loss: 16.9399 - val_mae: 2.6874\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9447 - mae: 0.7288 - val_loss: 16.8370 - val_mae: 2.7475\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9452 - mae: 0.7354 - val_loss: 16.6974 - val_mae: 2.7238\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9384 - mae: 0.6996 - val_loss: 19.0303 - val_mae: 2.8381\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9710 - mae: 0.7265 - val_loss: 13.4938 - val_mae: 2.5076\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9885 - mae: 0.7214 - val_loss: 20.1997 - val_mae: 3.0554\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8997 - mae: 0.7176 - val_loss: 20.5243 - val_mae: 2.9141\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9703 - mae: 0.7231 - val_loss: 18.2034 - val_mae: 2.8704\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9785 - mae: 0.7351 - val_loss: 16.5795 - val_mae: 2.5977\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9976 - mae: 0.6894 - val_loss: 15.9078 - val_mae: 2.7030\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9773 - mae: 0.6894 - val_loss: 19.4221 - val_mae: 2.9321\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9456 - mae: 0.7285 - val_loss: 16.6947 - val_mae: 2.7360\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8621 - mae: 0.7047 - val_loss: 17.3389 - val_mae: 2.7850\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9385 - mae: 0.7101 - val_loss: 17.5741 - val_mae: 2.7475\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0245 - mae: 0.7343 - val_loss: 20.8727 - val_mae: 2.9611\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 0.9039 - mae: 0.6953 - val_loss: 16.2376 - val_mae: 2.6550\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9264 - mae: 0.6937 - val_loss: 14.8666 - val_mae: 2.5378\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9061 - mae: 0.7209 - val_loss: 18.2404 - val_mae: 2.6786\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9634 - mae: 0.7338 - val_loss: 16.4416 - val_mae: 2.6449\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9766 - mae: 0.7446 - val_loss: 17.0083 - val_mae: 2.6737\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0046 - mae: 0.7515 - val_loss: 14.8965 - val_mae: 2.5632\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8364 - mae: 0.6738 - val_loss: 20.2550 - val_mae: 2.8608\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0676 - mae: 0.7673 - val_loss: 16.6758 - val_mae: 2.6419\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9844 - mae: 0.7508 - val_loss: 18.1637 - val_mae: 2.7533\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9394 - mae: 0.7333 - val_loss: 19.5627 - val_mae: 2.8059\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8910 - mae: 0.6885 - val_loss: 18.8480 - val_mae: 2.8912\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9126 - mae: 0.7147 - val_loss: 16.9620 - val_mae: 2.6190\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9684 - mae: 0.7402 - val_loss: 15.3757 - val_mae: 2.5758\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9264 - mae: 0.7029 - val_loss: 19.4195 - val_mae: 2.8738\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8349 - mae: 0.6598 - val_loss: 18.1127 - val_mae: 2.7462\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9494 - mae: 0.7286 - val_loss: 17.8530 - val_mae: 2.8770\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9944 - mae: 0.7313 - val_loss: 18.1354 - val_mae: 2.8123\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9057 - mae: 0.7075 - val_loss: 14.4239 - val_mae: 2.5490\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9837 - mae: 0.6997 - val_loss: 18.5909 - val_mae: 2.7844\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8761 - mae: 0.6765 - val_loss: 16.6652 - val_mae: 2.6874\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9258 - mae: 0.7114 - val_loss: 19.4039 - val_mae: 2.9272\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8723 - mae: 0.7147 - val_loss: 16.2717 - val_mae: 2.5498\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8534 - mae: 0.6894 - val_loss: 17.2432 - val_mae: 2.6494\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8417 - mae: 0.6903 - val_loss: 18.4042 - val_mae: 2.7416\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.7943 - mae: 0.6810 - val_loss: 15.9891 - val_mae: 2.5982\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9180 - mae: 0.6845 - val_loss: 15.4961 - val_mae: 2.5941\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9106 - mae: 0.6942 - val_loss: 15.5941 - val_mae: 2.5968\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8921 - mae: 0.6680 - val_loss: 15.3176 - val_mae: 2.6212\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9750 - mae: 0.7245 - val_loss: 18.1424 - val_mae: 2.7692\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8433 - mae: 0.6897 - val_loss: 19.8669 - val_mae: 3.0445\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8824 - mae: 0.6950 - val_loss: 17.2009 - val_mae: 2.6137\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9068 - mae: 0.7039 - val_loss: 17.6666 - val_mae: 2.8391\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9799 - mae: 0.7115 - val_loss: 16.2605 - val_mae: 2.6403\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8961 - mae: 0.7039 - val_loss: 16.6239 - val_mae: 2.5893\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9653 - mae: 0.7251 - val_loss: 17.1395 - val_mae: 2.6039\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.7741 - mae: 0.6599 - val_loss: 20.1483 - val_mae: 2.8774\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9328 - mae: 0.7070 - val_loss: 21.6123 - val_mae: 2.9907\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8403 - mae: 0.6752 - val_loss: 20.3476 - val_mae: 2.8259\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8491 - mae: 0.7043 - val_loss: 17.7900 - val_mae: 2.8715\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0096 - mae: 0.7117 - val_loss: 17.3360 - val_mae: 2.7249\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.7524 - mae: 0.6464 - val_loss: 19.1065 - val_mae: 2.7150\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9098 - mae: 0.7097 - val_loss: 15.8016 - val_mae: 2.6020\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.7965 - mae: 0.6577 - val_loss: 19.6926 - val_mae: 2.9889\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9702 - mae: 0.7287 - val_loss: 16.4510 - val_mae: 2.6664\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8737 - mae: 0.7028 - val_loss: 17.2261 - val_mae: 2.7406\n",
      "처리중인 폴드 # 2\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 196.8332 - mae: 10.8107 - val_loss: 40.8807 - val_mae: 4.5900\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 33.4659 - mae: 3.9713 - val_loss: 26.1008 - val_mae: 3.5457\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 23.3520 - mae: 3.2409 - val_loss: 23.0314 - val_mae: 3.0588\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 18.8140 - mae: 2.8969 - val_loss: 19.4118 - val_mae: 2.9079\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 15.6964 - mae: 2.6733 - val_loss: 17.9549 - val_mae: 2.8677\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 13.6803 - mae: 2.5424 - val_loss: 19.4863 - val_mae: 2.9449\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 12.7759 - mae: 2.3919 - val_loss: 16.4532 - val_mae: 2.6484\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.9542 - mae: 2.3911 - val_loss: 15.6425 - val_mae: 2.6082\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 11.3333 - mae: 2.2448 - val_loss: 15.2536 - val_mae: 2.5902\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 10.8138 - mae: 2.2618 - val_loss: 15.0434 - val_mae: 2.5553\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 10.4339 - mae: 2.2219 - val_loss: 15.4620 - val_mae: 2.6367\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.6505 - mae: 2.1445 - val_loss: 15.0143 - val_mae: 2.4983\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.4481 - mae: 2.1019 - val_loss: 16.5732 - val_mae: 2.7866\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.5768 - mae: 2.1343 - val_loss: 15.1864 - val_mae: 2.5045\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.6405 - mae: 2.0064 - val_loss: 16.7234 - val_mae: 2.6667\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.7489 - mae: 2.0752 - val_loss: 17.0988 - val_mae: 2.7042\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.8701 - mae: 2.0093 - val_loss: 15.1156 - val_mae: 2.5982\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 8.2286 - mae: 1.9749 - val_loss: 15.3540 - val_mae: 2.5438\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.8292 - mae: 1.9735 - val_loss: 15.7097 - val_mae: 2.6151\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.9531 - mae: 1.9006 - val_loss: 15.0959 - val_mae: 2.5181\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.8599 - mae: 1.9294 - val_loss: 15.2112 - val_mae: 2.6050\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.6825 - mae: 1.8950 - val_loss: 15.7794 - val_mae: 2.7328\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.8159 - mae: 1.9654 - val_loss: 15.2766 - val_mae: 2.5679\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 7.6929 - mae: 1.8053 - val_loss: 14.4970 - val_mae: 2.5600\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.0483 - mae: 1.8713 - val_loss: 15.9754 - val_mae: 2.5832\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.8189 - mae: 1.8371 - val_loss: 15.5651 - val_mae: 2.5528\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.2088 - mae: 1.8306 - val_loss: 16.1994 - val_mae: 2.7720\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.9615 - mae: 1.8121 - val_loss: 15.6584 - val_mae: 2.5393\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.8257 - mae: 1.7631 - val_loss: 15.5479 - val_mae: 2.5974\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.6672 - mae: 1.7990 - val_loss: 14.5704 - val_mae: 2.5475\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.5974 - mae: 1.7587 - val_loss: 15.2483 - val_mae: 2.5976\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.5443 - mae: 1.7705 - val_loss: 14.8354 - val_mae: 2.6838\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.5670 - mae: 1.7536 - val_loss: 16.2441 - val_mae: 2.5843\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.4982 - mae: 1.7712 - val_loss: 15.1288 - val_mae: 2.6581\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2801 - mae: 1.6771 - val_loss: 15.3814 - val_mae: 2.5445\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.0963 - mae: 1.7055 - val_loss: 14.6207 - val_mae: 2.5712\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.7834 - mae: 1.6357 - val_loss: 15.9225 - val_mae: 2.8718\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8742 - mae: 1.6669 - val_loss: 16.7429 - val_mae: 2.8590\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8260 - mae: 1.6724 - val_loss: 14.6735 - val_mae: 2.5018\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.9535 - mae: 1.7122 - val_loss: 15.3975 - val_mae: 2.7046\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.7263 - mae: 1.6518 - val_loss: 14.7881 - val_mae: 2.6321\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8254 - mae: 1.6887 - val_loss: 15.4425 - val_mae: 2.6657\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.5136 - mae: 1.6089 - val_loss: 16.6851 - val_mae: 2.8081\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6457 - mae: 1.6204 - val_loss: 16.1486 - val_mae: 2.6935\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.4830 - mae: 1.6355 - val_loss: 16.1265 - val_mae: 2.7467\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.4042 - mae: 1.6039 - val_loss: 15.3799 - val_mae: 2.7344\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3312 - mae: 1.5901 - val_loss: 14.8709 - val_mae: 2.5307\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.0157 - mae: 1.5740 - val_loss: 15.5190 - val_mae: 2.6137\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.0707 - mae: 1.5782 - val_loss: 16.0171 - val_mae: 2.7030\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.4944 - mae: 1.5849 - val_loss: 14.0731 - val_mae: 2.4746\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3549 - mae: 1.5626 - val_loss: 14.5945 - val_mae: 2.5475\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.9831 - mae: 1.5066 - val_loss: 15.0466 - val_mae: 2.6207\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.9567 - mae: 1.5560 - val_loss: 14.8069 - val_mae: 2.5019\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.0404 - mae: 1.5324 - val_loss: 15.7852 - val_mae: 2.5631\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6160 - mae: 1.4925 - val_loss: 14.9182 - val_mae: 2.6770\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.5050 - mae: 1.5200 - val_loss: 14.2634 - val_mae: 2.5101\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6627 - mae: 1.5332 - val_loss: 14.8217 - val_mae: 2.6069\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5772 - mae: 1.4404 - val_loss: 14.1433 - val_mae: 2.5374\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.6390 - mae: 1.4577 - val_loss: 14.7467 - val_mae: 2.6326\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.6314 - mae: 1.4884 - val_loss: 15.2047 - val_mae: 2.5725\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.5971 - mae: 1.4922 - val_loss: 15.8695 - val_mae: 2.7477\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.4982 - mae: 1.4784 - val_loss: 14.9326 - val_mae: 2.5558\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.6429 - mae: 1.5030 - val_loss: 15.4694 - val_mae: 2.6892\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5854 - mae: 1.4713 - val_loss: 15.8310 - val_mae: 2.6615\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.2333 - mae: 1.4654 - val_loss: 16.1110 - val_mae: 2.7156\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.2563 - mae: 1.4434 - val_loss: 14.9280 - val_mae: 2.7004\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.1413 - mae: 1.4084 - val_loss: 14.8289 - val_mae: 2.6666\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1226 - mae: 1.4189 - val_loss: 15.3508 - val_mae: 2.5851\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.0947 - mae: 1.4242 - val_loss: 14.8545 - val_mae: 2.6307\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6260 - mae: 1.3786 - val_loss: 15.8133 - val_mae: 2.6375\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9141 - mae: 1.4376 - val_loss: 16.2548 - val_mae: 2.7607\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.9840 - mae: 1.3624 - val_loss: 14.1120 - val_mae: 2.6313\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8263 - mae: 1.3702 - val_loss: 14.5505 - val_mae: 2.5967\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.8690 - mae: 1.4023 - val_loss: 14.3418 - val_mae: 2.4938\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8972 - mae: 1.3481 - val_loss: 15.3276 - val_mae: 2.6697\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.8911 - mae: 1.3786 - val_loss: 17.7311 - val_mae: 2.8722\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7482 - mae: 1.3390 - val_loss: 14.6318 - val_mae: 2.5327\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.5432 - mae: 1.3504 - val_loss: 15.4320 - val_mae: 2.6748\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7772 - mae: 1.3895 - val_loss: 14.8626 - val_mae: 2.5973\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5946 - mae: 1.2984 - val_loss: 15.3102 - val_mae: 2.7198\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6352 - mae: 1.3688 - val_loss: 15.2945 - val_mae: 2.6873\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2367 - mae: 1.2921 - val_loss: 15.9913 - val_mae: 2.7736\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4831 - mae: 1.3583 - val_loss: 14.9719 - val_mae: 2.5871\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3572 - mae: 1.2498 - val_loss: 15.1435 - val_mae: 2.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.2360 - mae: 1.2721 - val_loss: 15.8120 - val_mae: 2.6692\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4133 - mae: 1.3046 - val_loss: 15.4564 - val_mae: 2.6232\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3011 - mae: 1.2879 - val_loss: 15.8839 - val_mae: 2.8448\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2588 - mae: 1.2929 - val_loss: 14.6001 - val_mae: 2.6541\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1638 - mae: 1.2982 - val_loss: 14.9274 - val_mae: 2.5066\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3692 - mae: 1.3010 - val_loss: 14.8750 - val_mae: 2.5645\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2996 - mae: 1.2715 - val_loss: 15.7795 - val_mae: 2.6769\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0715 - mae: 1.2529 - val_loss: 16.2538 - val_mae: 2.6522\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0967 - mae: 1.2776 - val_loss: 16.0601 - val_mae: 2.7712\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.1253 - mae: 1.2225 - val_loss: 16.1913 - val_mae: 2.7516\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1678 - mae: 1.2787 - val_loss: 14.3433 - val_mae: 2.5740\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9521 - mae: 1.1990 - val_loss: 17.7238 - val_mae: 2.9742\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0699 - mae: 1.1973 - val_loss: 15.9221 - val_mae: 2.6974\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0710 - mae: 1.1997 - val_loss: 16.0834 - val_mae: 2.7466\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7857 - mae: 1.1979 - val_loss: 16.4597 - val_mae: 2.8100\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9094 - mae: 1.2351 - val_loss: 15.8441 - val_mae: 2.7410\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.9921 - mae: 1.2333 - val_loss: 17.0616 - val_mae: 2.7681\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6625 - mae: 1.1496 - val_loss: 15.0485 - val_mae: 2.6389\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.7683 - mae: 1.1766 - val_loss: 14.6506 - val_mae: 2.6414\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9039 - mae: 1.1835 - val_loss: 16.4833 - val_mae: 2.8343\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9102 - mae: 1.1980 - val_loss: 15.5562 - val_mae: 2.6509\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6977 - mae: 1.1872 - val_loss: 14.5142 - val_mae: 2.5496\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8393 - mae: 1.1930 - val_loss: 15.0044 - val_mae: 2.6520\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8876 - mae: 1.1527 - val_loss: 17.3998 - val_mae: 2.7601\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5459 - mae: 1.1257 - val_loss: 16.9700 - val_mae: 2.9013\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.4940 - mae: 1.1121 - val_loss: 16.2990 - val_mae: 2.7595\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6090 - mae: 1.1468 - val_loss: 14.5301 - val_mae: 2.5286\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.7219 - mae: 1.2107 - val_loss: 15.0083 - val_mae: 2.6070\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5614 - mae: 1.1653 - val_loss: 15.5306 - val_mae: 2.6987\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5149 - mae: 1.1375 - val_loss: 15.6824 - val_mae: 2.7214\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5594 - mae: 1.1484 - val_loss: 16.0267 - val_mae: 2.6303\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.5576 - mae: 1.1443 - val_loss: 15.3521 - val_mae: 2.6686\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2979 - mae: 1.0818 - val_loss: 14.5701 - val_mae: 2.6590\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.3965 - mae: 1.0831 - val_loss: 15.1230 - val_mae: 2.6741\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4433 - mae: 1.1385 - val_loss: 14.7903 - val_mae: 2.5926\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5207 - mae: 1.0821 - val_loss: 15.4498 - val_mae: 2.7053\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1744 - mae: 1.0766 - val_loss: 15.3445 - val_mae: 2.7009\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3137 - mae: 1.1182 - val_loss: 17.3124 - val_mae: 2.7615\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1721 - mae: 1.0626 - val_loss: 16.2029 - val_mae: 2.7488\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.5020 - mae: 1.1002 - val_loss: 14.8729 - val_mae: 2.6268\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.3417 - mae: 1.0633 - val_loss: 15.3782 - val_mae: 2.6116\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1806 - mae: 1.0361 - val_loss: 15.2244 - val_mae: 2.5845\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.3150 - mae: 1.1252 - val_loss: 14.9228 - val_mae: 2.6253\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2324 - mae: 1.0714 - val_loss: 16.0459 - val_mae: 2.6853\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2519 - mae: 1.0632 - val_loss: 16.8876 - val_mae: 2.7906\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2141 - mae: 1.0576 - val_loss: 17.0719 - val_mae: 2.8839\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2279 - mae: 1.0111 - val_loss: 16.4240 - val_mae: 2.7819\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0254 - mae: 1.0020 - val_loss: 13.8912 - val_mae: 2.5216\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9637 - mae: 1.0438 - val_loss: 15.2442 - val_mae: 2.6606\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0240 - mae: 1.0084 - val_loss: 17.8396 - val_mae: 2.9101\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1944 - mae: 1.0593 - val_loss: 14.9562 - val_mae: 2.6614\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.1151 - mae: 1.0247 - val_loss: 14.7984 - val_mae: 2.6351\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0170 - mae: 1.0077 - val_loss: 16.1563 - val_mae: 2.7514\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 2.0711 - mae: 1.0307 - val_loss: 16.9017 - val_mae: 2.8026\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0636 - mae: 1.0336 - val_loss: 16.9944 - val_mae: 2.7477\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9888 - mae: 0.9758 - val_loss: 17.7833 - val_mae: 2.8025\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0789 - mae: 1.0249 - val_loss: 15.9610 - val_mae: 2.6925\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9504 - mae: 0.9930 - val_loss: 14.7060 - val_mae: 2.6054\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8996 - mae: 1.0435 - val_loss: 15.4364 - val_mae: 2.6214\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8572 - mae: 1.0149 - val_loss: 16.0750 - val_mae: 2.6325\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9101 - mae: 0.9411 - val_loss: 15.3611 - val_mae: 2.6236\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9692 - mae: 0.9857 - val_loss: 15.9260 - val_mae: 2.6980\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8640 - mae: 0.9961 - val_loss: 14.7788 - val_mae: 2.6089\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0260 - mae: 1.0458 - val_loss: 16.2525 - val_mae: 2.7001\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9526 - mae: 0.9926 - val_loss: 17.5370 - val_mae: 2.8533\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7604 - mae: 0.9473 - val_loss: 16.0362 - val_mae: 2.7641\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7362 - mae: 0.9792 - val_loss: 15.3274 - val_mae: 2.6436\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7612 - mae: 0.9618 - val_loss: 17.0984 - val_mae: 2.8256\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7353 - mae: 0.9752 - val_loss: 17.0327 - val_mae: 2.8685\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.9521 - mae: 1.0107 - val_loss: 16.5673 - val_mae: 2.8233\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7165 - mae: 0.9821 - val_loss: 15.7265 - val_mae: 2.7253\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8059 - mae: 0.9464 - val_loss: 17.5595 - val_mae: 2.8989\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8876 - mae: 0.9316 - val_loss: 16.0148 - val_mae: 2.7651\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.8448 - mae: 0.9834 - val_loss: 14.5746 - val_mae: 2.5509\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7406 - mae: 0.9274 - val_loss: 17.2329 - val_mae: 2.9289\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.7779 - mae: 1.0020 - val_loss: 16.0465 - val_mae: 2.6627\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5025 - mae: 0.9153 - val_loss: 16.7603 - val_mae: 2.7439\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8378 - mae: 0.9599 - val_loss: 15.7274 - val_mae: 2.7191\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5767 - mae: 0.9289 - val_loss: 15.3822 - val_mae: 2.6789\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6505 - mae: 0.9267 - val_loss: 14.7435 - val_mae: 2.7920\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6264 - mae: 0.9268 - val_loss: 15.1120 - val_mae: 2.6996\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5795 - mae: 0.9209 - val_loss: 15.1822 - val_mae: 2.7667\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.6630 - mae: 0.9348 - val_loss: 15.0438 - val_mae: 2.6471\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4813 - mae: 0.8972 - val_loss: 16.6304 - val_mae: 2.9164\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4237 - mae: 0.8981 - val_loss: 17.6352 - val_mae: 2.8642\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6456 - mae: 0.9122 - val_loss: 15.2535 - val_mae: 2.7907\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5305 - mae: 0.9278 - val_loss: 15.4772 - val_mae: 2.7966\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3837 - mae: 0.8943 - val_loss: 16.3106 - val_mae: 2.8355\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6331 - mae: 0.9383 - val_loss: 15.4277 - val_mae: 2.6660\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4644 - mae: 0.8895 - val_loss: 16.4525 - val_mae: 2.7309\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6217 - mae: 0.9020 - val_loss: 15.3662 - val_mae: 2.7514\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4559 - mae: 0.9105 - val_loss: 14.9682 - val_mae: 2.6715\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6159 - mae: 0.9280 - val_loss: 15.6287 - val_mae: 2.8528\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.5455 - mae: 0.9221 - val_loss: 15.9557 - val_mae: 2.7594\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5103 - mae: 0.8822 - val_loss: 15.2146 - val_mae: 2.6706\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4040 - mae: 0.9086 - val_loss: 15.3227 - val_mae: 2.7529\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4219 - mae: 0.8866 - val_loss: 16.3269 - val_mae: 2.8418\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4689 - mae: 0.9028 - val_loss: 15.6257 - val_mae: 2.7857\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4123 - mae: 0.8885 - val_loss: 16.1271 - val_mae: 2.7955\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3987 - mae: 0.8747 - val_loss: 15.4208 - val_mae: 2.7750\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4940 - mae: 0.8735 - val_loss: 17.0900 - val_mae: 2.8592\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4465 - mae: 0.8676 - val_loss: 15.5490 - val_mae: 2.7888\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4627 - mae: 0.8634 - val_loss: 16.0041 - val_mae: 2.8152\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2997 - mae: 0.8605 - val_loss: 16.4076 - val_mae: 2.9111\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4407 - mae: 0.8702 - val_loss: 16.4862 - val_mae: 2.8021\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3579 - mae: 0.8796 - val_loss: 15.3465 - val_mae: 2.7505\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3432 - mae: 0.8614 - val_loss: 14.4588 - val_mae: 2.6896\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3719 - mae: 0.8181 - val_loss: 16.1986 - val_mae: 2.7997\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3992 - mae: 0.8472 - val_loss: 14.6917 - val_mae: 2.7339\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2801 - mae: 0.8440 - val_loss: 15.2606 - val_mae: 2.7573\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3603 - mae: 0.8852 - val_loss: 15.7119 - val_mae: 2.7738\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1248 - mae: 0.7964 - val_loss: 17.5552 - val_mae: 2.9461\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3455 - mae: 0.8584 - val_loss: 16.1065 - val_mae: 2.8892\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.4595 - mae: 0.9013 - val_loss: 15.3395 - val_mae: 2.7143\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1883 - mae: 0.7964 - val_loss: 16.4377 - val_mae: 2.8860\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.3893 - mae: 0.8669 - val_loss: 15.4757 - val_mae: 2.8074\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2673 - mae: 0.8300 - val_loss: 15.1260 - val_mae: 2.7156\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2838 - mae: 0.8230 - val_loss: 16.6483 - val_mae: 2.8191\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2299 - mae: 0.8205 - val_loss: 14.7665 - val_mae: 2.7376\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2463 - mae: 0.8391 - val_loss: 15.0693 - val_mae: 2.7063\n",
      "Epoch 205/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2794 - mae: 0.7977 - val_loss: 15.4575 - val_mae: 2.8660\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2081 - mae: 0.8448 - val_loss: 15.3026 - val_mae: 2.8354\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1942 - mae: 0.8377 - val_loss: 15.0577 - val_mae: 2.7241\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1995 - mae: 0.8014 - val_loss: 16.2661 - val_mae: 2.8191\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2046 - mae: 0.8269 - val_loss: 14.3027 - val_mae: 2.6987\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1719 - mae: 0.7844 - val_loss: 14.8347 - val_mae: 2.6200\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2919 - mae: 0.8285 - val_loss: 16.1058 - val_mae: 2.9119\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1490 - mae: 0.7956 - val_loss: 15.8483 - val_mae: 2.8661\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2059 - mae: 0.8232 - val_loss: 15.7330 - val_mae: 2.7715\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1240 - mae: 0.7797 - val_loss: 15.0696 - val_mae: 2.7174\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.2036 - mae: 0.7604 - val_loss: 14.8822 - val_mae: 2.7883\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1962 - mae: 0.8035 - val_loss: 14.7829 - val_mae: 2.7473\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1417 - mae: 0.7905 - val_loss: 15.8770 - val_mae: 2.6756\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1360 - mae: 0.8161 - val_loss: 16.2393 - val_mae: 2.8103\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3226 - mae: 0.7794 - val_loss: 16.2756 - val_mae: 2.7441\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.2246 - mae: 0.7944 - val_loss: 14.4405 - val_mae: 2.6410\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1186 - mae: 0.8052 - val_loss: 15.7747 - val_mae: 2.7385\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1037 - mae: 0.7875 - val_loss: 16.2504 - val_mae: 2.7665\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1244 - mae: 0.7919 - val_loss: 16.1910 - val_mae: 2.8155\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0498 - mae: 0.7820 - val_loss: 15.5193 - val_mae: 2.7597\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0921 - mae: 0.7781 - val_loss: 16.0731 - val_mae: 2.8737\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1751 - mae: 0.8021 - val_loss: 16.3840 - val_mae: 2.8324\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2030 - mae: 0.8240 - val_loss: 17.5094 - val_mae: 2.8669\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1032 - mae: 0.7901 - val_loss: 16.4739 - val_mae: 2.9204\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1352 - mae: 0.8003 - val_loss: 16.4738 - val_mae: 2.8036\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0586 - mae: 0.7562 - val_loss: 16.1341 - val_mae: 2.7424\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1918 - mae: 0.8076 - val_loss: 16.3647 - val_mae: 2.8052\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0933 - mae: 0.7841 - val_loss: 17.2220 - val_mae: 3.0327\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1055 - mae: 0.7776 - val_loss: 16.3518 - val_mae: 2.9246\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2546 - mae: 0.8150 - val_loss: 14.8737 - val_mae: 2.6756\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0884 - mae: 0.7829 - val_loss: 15.3876 - val_mae: 2.7876\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0627 - mae: 0.7558 - val_loss: 15.6284 - val_mae: 2.7947\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1262 - mae: 0.8037 - val_loss: 15.0047 - val_mae: 2.7715\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0738 - mae: 0.7663 - val_loss: 15.1571 - val_mae: 2.7445\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0792 - mae: 0.7892 - val_loss: 16.1651 - val_mae: 2.8190\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1109 - mae: 0.7887 - val_loss: 14.5946 - val_mae: 2.6915\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9649 - mae: 0.7263 - val_loss: 15.6697 - val_mae: 2.7446\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1186 - mae: 0.7748 - val_loss: 13.7333 - val_mae: 2.6428\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0451 - mae: 0.7709 - val_loss: 15.0508 - val_mae: 2.7942\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1209 - mae: 0.7850 - val_loss: 15.6035 - val_mae: 2.7441\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1678 - mae: 0.7985 - val_loss: 15.2820 - val_mae: 2.8033\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0868 - mae: 0.7734 - val_loss: 15.7319 - val_mae: 2.7506\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0907 - mae: 0.7949 - val_loss: 15.6207 - val_mae: 2.7864\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0681 - mae: 0.7649 - val_loss: 15.8483 - val_mae: 2.7828\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1074 - mae: 0.7694 - val_loss: 15.7489 - val_mae: 2.7790\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0175 - mae: 0.7460 - val_loss: 15.8404 - val_mae: 2.9279\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0453 - mae: 0.7790 - val_loss: 14.8426 - val_mae: 2.7107\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2424 - mae: 0.7904 - val_loss: 15.3854 - val_mae: 2.7929\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9317 - mae: 0.7106 - val_loss: 15.0457 - val_mae: 2.7150\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0237 - mae: 0.7584 - val_loss: 14.7763 - val_mae: 2.7020\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0471 - mae: 0.7334 - val_loss: 16.1147 - val_mae: 2.8309\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9554 - mae: 0.7305 - val_loss: 14.9335 - val_mae: 2.7848\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1386 - mae: 0.8097 - val_loss: 17.2168 - val_mae: 3.0464\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1330 - mae: 0.7800 - val_loss: 15.1371 - val_mae: 2.7375\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9656 - mae: 0.7378 - val_loss: 15.5469 - val_mae: 2.7726\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1051 - mae: 0.7250 - val_loss: 14.5339 - val_mae: 2.6659\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0578 - mae: 0.7464 - val_loss: 14.9573 - val_mae: 2.6796\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0807 - mae: 0.7674 - val_loss: 15.2673 - val_mae: 2.7898\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.1053 - mae: 0.7587 - val_loss: 15.2715 - val_mae: 2.7358\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 1.0572 - mae: 0.7437 - val_loss: 14.2181 - val_mae: 2.6582\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9636 - mae: 0.7434 - val_loss: 15.8275 - val_mae: 2.6860\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.1139 - mae: 0.7761 - val_loss: 14.9584 - val_mae: 2.7159\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9249 - mae: 0.6831 - val_loss: 14.1018 - val_mae: 2.6900\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9145 - mae: 0.7328 - val_loss: 16.1501 - val_mae: 2.7593\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1381 - mae: 0.7838 - val_loss: 14.6768 - val_mae: 2.6500\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9771 - mae: 0.7290 - val_loss: 14.7561 - val_mae: 2.7334\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0666 - mae: 0.7604 - val_loss: 15.6389 - val_mae: 2.7660\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9792 - mae: 0.7067 - val_loss: 15.5633 - val_mae: 2.7892\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9067 - mae: 0.7142 - val_loss: 13.6500 - val_mae: 2.5471\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9487 - mae: 0.7110 - val_loss: 15.1557 - val_mae: 2.7196\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8852 - mae: 0.7001 - val_loss: 15.9588 - val_mae: 2.7178\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0148 - mae: 0.7244 - val_loss: 14.7066 - val_mae: 2.7409\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0231 - mae: 0.7478 - val_loss: 14.1324 - val_mae: 2.6135\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8860 - mae: 0.7223 - val_loss: 14.1087 - val_mae: 2.6418\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0627 - mae: 0.7479 - val_loss: 14.4563 - val_mae: 2.7441\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0503 - mae: 0.7222 - val_loss: 15.4169 - val_mae: 2.8225\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0336 - mae: 0.7365 - val_loss: 15.3047 - val_mae: 2.7340\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9758 - mae: 0.7131 - val_loss: 14.9594 - val_mae: 2.7429\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9706 - mae: 0.7434 - val_loss: 16.1303 - val_mae: 2.8542\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9217 - mae: 0.7232 - val_loss: 15.9291 - val_mae: 2.8304\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0592 - mae: 0.7279 - val_loss: 15.9663 - val_mae: 2.9143\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9103 - mae: 0.6994 - val_loss: 14.4152 - val_mae: 2.6550\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0890 - mae: 0.7706 - val_loss: 16.1755 - val_mae: 2.8675\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8811 - mae: 0.7017 - val_loss: 14.9348 - val_mae: 2.6911\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9160 - mae: 0.7167 - val_loss: 15.6517 - val_mae: 2.7374\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9238 - mae: 0.7074 - val_loss: 14.7002 - val_mae: 2.7060\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9323 - mae: 0.7021 - val_loss: 14.2903 - val_mae: 2.6239\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8992 - mae: 0.7096 - val_loss: 15.3668 - val_mae: 2.7443\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0743 - mae: 0.7719 - val_loss: 14.9909 - val_mae: 2.7877\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9297 - mae: 0.7020 - val_loss: 15.8111 - val_mae: 2.8672\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9721 - mae: 0.7377 - val_loss: 17.5922 - val_mae: 3.0279\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8469 - mae: 0.7049 - val_loss: 16.1007 - val_mae: 2.8482\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9641 - mae: 0.7075 - val_loss: 14.2373 - val_mae: 2.6090\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9374 - mae: 0.7066 - val_loss: 14.9903 - val_mae: 2.7473\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0483 - mae: 0.7338 - val_loss: 14.3312 - val_mae: 2.7060\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8770 - mae: 0.6898 - val_loss: 13.6409 - val_mae: 2.5538\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9441 - mae: 0.7265 - val_loss: 16.2741 - val_mae: 2.8649\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9012 - mae: 0.7094 - val_loss: 14.2569 - val_mae: 2.6412\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9636 - mae: 0.7161 - val_loss: 14.9184 - val_mae: 2.7015\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9621 - mae: 0.7004 - val_loss: 17.0090 - val_mae: 2.9419\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9779 - mae: 0.7127 - val_loss: 14.8653 - val_mae: 2.7320\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 0.8526 - mae: 0.6987 - val_loss: 14.6606 - val_mae: 2.7705\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8968 - mae: 0.6961 - val_loss: 15.1362 - val_mae: 2.7738\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8502 - mae: 0.6703 - val_loss: 14.5302 - val_mae: 2.6592\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8958 - mae: 0.6832 - val_loss: 16.1955 - val_mae: 2.8288\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9463 - mae: 0.6865 - val_loss: 14.2030 - val_mae: 2.6488\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7733 - mae: 0.6615 - val_loss: 16.0710 - val_mae: 2.8048\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 1.0028 - mae: 0.7135 - val_loss: 14.6594 - val_mae: 2.6892\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8918 - mae: 0.6777 - val_loss: 14.8210 - val_mae: 2.7315\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8610 - mae: 0.7049 - val_loss: 14.2389 - val_mae: 2.6530\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8938 - mae: 0.7014 - val_loss: 14.7416 - val_mae: 2.7416\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8418 - mae: 0.6935 - val_loss: 15.0668 - val_mae: 2.7141\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8975 - mae: 0.6840 - val_loss: 15.6501 - val_mae: 2.7428\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9431 - mae: 0.7123 - val_loss: 16.7034 - val_mae: 2.9468\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9106 - mae: 0.7046 - val_loss: 14.5994 - val_mae: 2.6895\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8488 - mae: 0.6856 - val_loss: 14.3307 - val_mae: 2.6938\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9178 - mae: 0.7067 - val_loss: 15.1861 - val_mae: 2.7214\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9105 - mae: 0.7216 - val_loss: 14.0573 - val_mae: 2.6424\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9089 - mae: 0.6682 - val_loss: 15.2082 - val_mae: 2.7480\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8989 - mae: 0.6980 - val_loss: 16.5339 - val_mae: 2.8700\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7899 - mae: 0.6626 - val_loss: 14.8963 - val_mae: 2.7736\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8773 - mae: 0.6925 - val_loss: 15.3743 - val_mae: 2.8525\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8860 - mae: 0.7108 - val_loss: 15.4521 - val_mae: 2.8063\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8789 - mae: 0.6783 - val_loss: 14.7759 - val_mae: 2.6962\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8436 - mae: 0.6924 - val_loss: 15.5049 - val_mae: 2.8387\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9302 - mae: 0.7302 - val_loss: 14.2439 - val_mae: 2.6867\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7831 - mae: 0.6643 - val_loss: 14.6550 - val_mae: 2.7398\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8264 - mae: 0.6631 - val_loss: 14.9165 - val_mae: 2.7061\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8880 - mae: 0.6947 - val_loss: 14.3557 - val_mae: 2.6857\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8056 - mae: 0.6884 - val_loss: 15.4278 - val_mae: 2.7851\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8083 - mae: 0.6932 - val_loss: 14.7953 - val_mae: 2.6692\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9254 - mae: 0.6832 - val_loss: 14.6317 - val_mae: 2.7838\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.9089 - mae: 0.6961 - val_loss: 14.9644 - val_mae: 2.7356\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8035 - mae: 0.6605 - val_loss: 14.6054 - val_mae: 2.6819\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8641 - mae: 0.6691 - val_loss: 14.9422 - val_mae: 2.7318\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7707 - mae: 0.6826 - val_loss: 15.1665 - val_mae: 2.6968\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7857 - mae: 0.6824 - val_loss: 13.9094 - val_mae: 2.6004\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8832 - mae: 0.6827 - val_loss: 14.7723 - val_mae: 2.7265\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8836 - mae: 0.6947 - val_loss: 16.2976 - val_mae: 2.8281\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7689 - mae: 0.6594 - val_loss: 14.9763 - val_mae: 2.8201\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 0.7853 - mae: 0.6733 - val_loss: 14.6598 - val_mae: 2.7526\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 0.7806 - mae: 0.6374 - val_loss: 14.0030 - val_mae: 2.6075\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 0.8821 - mae: 0.6950 - val_loss: 14.7913 - val_mae: 2.7516\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8262 - mae: 0.6530 - val_loss: 15.0895 - val_mae: 2.7604\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7994 - mae: 0.6779 - val_loss: 14.4936 - val_mae: 2.6574\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8591 - mae: 0.6863 - val_loss: 15.3837 - val_mae: 2.7806\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7719 - mae: 0.6676 - val_loss: 15.4610 - val_mae: 2.8286\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8845 - mae: 0.6813 - val_loss: 15.2005 - val_mae: 2.7060\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 0.7116 - mae: 0.6233 - val_loss: 14.1898 - val_mae: 2.5858\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9238 - mae: 0.6966 - val_loss: 14.6413 - val_mae: 2.6798\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9347 - mae: 0.7040 - val_loss: 17.1105 - val_mae: 2.9446\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7170 - mae: 0.6118 - val_loss: 14.7236 - val_mae: 2.7283\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7641 - mae: 0.6465 - val_loss: 14.7690 - val_mae: 2.7620\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6966 - mae: 0.6221 - val_loss: 15.2564 - val_mae: 2.8061\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7516 - mae: 0.6494 - val_loss: 15.0213 - val_mae: 2.7929\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8694 - mae: 0.6925 - val_loss: 14.4986 - val_mae: 2.7251\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8162 - mae: 0.6565 - val_loss: 15.2548 - val_mae: 2.8684\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7824 - mae: 0.6435 - val_loss: 13.5251 - val_mae: 2.5594\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7062 - mae: 0.6048 - val_loss: 15.3684 - val_mae: 2.8064\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8554 - mae: 0.6754 - val_loss: 14.9568 - val_mae: 2.7659\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7285 - mae: 0.6279 - val_loss: 15.0051 - val_mae: 2.7714\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7198 - mae: 0.6111 - val_loss: 15.7091 - val_mae: 2.8806\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7920 - mae: 0.6667 - val_loss: 15.3454 - val_mae: 2.8558\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8180 - mae: 0.6557 - val_loss: 14.5038 - val_mae: 2.7585\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7290 - mae: 0.6217 - val_loss: 14.6424 - val_mae: 2.7613\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7683 - mae: 0.6316 - val_loss: 13.8776 - val_mae: 2.6403\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6902 - mae: 0.6051 - val_loss: 15.3909 - val_mae: 2.7679\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7167 - mae: 0.6041 - val_loss: 14.7121 - val_mae: 2.7381\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7470 - mae: 0.6342 - val_loss: 15.3298 - val_mae: 2.7724\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7848 - mae: 0.6561 - val_loss: 14.7716 - val_mae: 2.7005\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7154 - mae: 0.5994 - val_loss: 13.8089 - val_mae: 2.6194\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7585 - mae: 0.6542 - val_loss: 14.5617 - val_mae: 2.7375\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8061 - mae: 0.6366 - val_loss: 15.9501 - val_mae: 2.8731\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7699 - mae: 0.6599 - val_loss: 14.5415 - val_mae: 2.7520\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7019 - mae: 0.6111 - val_loss: 14.3108 - val_mae: 2.7077\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7342 - mae: 0.6151 - val_loss: 14.5072 - val_mae: 2.6740\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8531 - mae: 0.6649 - val_loss: 15.3194 - val_mae: 2.8178\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6631 - mae: 0.6158 - val_loss: 14.1341 - val_mae: 2.6503\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6733 - mae: 0.6136 - val_loss: 14.2733 - val_mae: 2.6239\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8435 - mae: 0.6685 - val_loss: 14.0514 - val_mae: 2.6324\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7606 - mae: 0.6549 - val_loss: 16.0980 - val_mae: 2.8687\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6602 - mae: 0.6010 - val_loss: 13.2853 - val_mae: 2.5390\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8227 - mae: 0.6519 - val_loss: 14.4281 - val_mae: 2.7204\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6894 - mae: 0.6267 - val_loss: 13.7090 - val_mae: 2.6527\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8042 - mae: 0.6460 - val_loss: 13.9794 - val_mae: 2.6482\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7035 - mae: 0.6283 - val_loss: 14.9061 - val_mae: 2.8085\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7136 - mae: 0.6268 - val_loss: 14.5530 - val_mae: 2.6344\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7363 - mae: 0.6223 - val_loss: 14.7782 - val_mae: 2.7883\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7449 - mae: 0.6487 - val_loss: 15.1927 - val_mae: 2.7336\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7051 - mae: 0.6170 - val_loss: 14.7977 - val_mae: 2.7610\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6277 - mae: 0.5958 - val_loss: 15.1469 - val_mae: 2.8277\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7906 - mae: 0.6479 - val_loss: 15.7730 - val_mae: 2.8845\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7231 - mae: 0.6230 - val_loss: 13.8023 - val_mae: 2.6436\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7737 - mae: 0.6257 - val_loss: 15.1170 - val_mae: 2.8697\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7090 - mae: 0.6457 - val_loss: 14.2794 - val_mae: 2.7180\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7453 - mae: 0.6246 - val_loss: 14.3376 - val_mae: 2.6937\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6038 - mae: 0.5740 - val_loss: 15.9627 - val_mae: 2.8993\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7024 - mae: 0.6031 - val_loss: 15.8674 - val_mae: 2.8352\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6573 - mae: 0.6204 - val_loss: 13.7578 - val_mae: 2.6616\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7925 - mae: 0.6177 - val_loss: 14.3293 - val_mae: 2.7252\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7336 - mae: 0.6380 - val_loss: 15.2949 - val_mae: 2.8294\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7013 - mae: 0.6257 - val_loss: 13.1724 - val_mae: 2.6187\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6498 - mae: 0.6236 - val_loss: 14.7122 - val_mae: 2.6922\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7007 - mae: 0.6188 - val_loss: 14.5141 - val_mae: 2.7249\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7430 - mae: 0.6077 - val_loss: 15.4888 - val_mae: 2.8359\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7278 - mae: 0.6050 - val_loss: 14.8148 - val_mae: 2.7429\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7277 - mae: 0.6148 - val_loss: 14.7339 - val_mae: 2.7892\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8147 - mae: 0.6547 - val_loss: 14.4519 - val_mae: 2.7101\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8081 - mae: 0.6095 - val_loss: 14.2484 - val_mae: 2.7524\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7125 - mae: 0.6285 - val_loss: 14.0799 - val_mae: 2.6781\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7053 - mae: 0.6167 - val_loss: 13.6474 - val_mae: 2.6786\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7678 - mae: 0.6371 - val_loss: 14.7754 - val_mae: 2.6946\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6520 - mae: 0.5933 - val_loss: 13.6665 - val_mae: 2.6222\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7001 - mae: 0.6244 - val_loss: 14.7111 - val_mae: 2.7679\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6793 - mae: 0.6009 - val_loss: 14.2694 - val_mae: 2.6901\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7844 - mae: 0.6249 - val_loss: 14.7960 - val_mae: 2.7988\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6714 - mae: 0.6136 - val_loss: 14.3932 - val_mae: 2.7727\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7765 - mae: 0.6128 - val_loss: 14.3952 - val_mae: 2.6754\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7001 - mae: 0.6073 - val_loss: 13.5169 - val_mae: 2.5473\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6243 - mae: 0.5997 - val_loss: 14.2608 - val_mae: 2.6331\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8242 - mae: 0.6432 - val_loss: 14.1205 - val_mae: 2.6888\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7163 - mae: 0.6237 - val_loss: 14.7560 - val_mae: 2.6971\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7339 - mae: 0.6288 - val_loss: 13.6213 - val_mae: 2.5712\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7594 - mae: 0.6149 - val_loss: 14.3007 - val_mae: 2.6990\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6511 - mae: 0.5774 - val_loss: 15.1862 - val_mae: 2.8219\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6910 - mae: 0.6267 - val_loss: 14.5086 - val_mae: 2.6926\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7280 - mae: 0.6265 - val_loss: 13.8278 - val_mae: 2.6639\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6020 - mae: 0.5569 - val_loss: 14.5296 - val_mae: 2.7468\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6532 - mae: 0.6090 - val_loss: 14.0331 - val_mae: 2.6759\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6826 - mae: 0.6153 - val_loss: 14.2287 - val_mae: 2.7120\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6779 - mae: 0.5933 - val_loss: 14.0229 - val_mae: 2.6536\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6900 - mae: 0.6175 - val_loss: 14.7293 - val_mae: 2.7432\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6371 - mae: 0.5961 - val_loss: 14.0572 - val_mae: 2.7285\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6503 - mae: 0.5755 - val_loss: 14.7241 - val_mae: 2.6901\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7043 - mae: 0.6027 - val_loss: 14.8009 - val_mae: 2.6980\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.5845 - mae: 0.5753 - val_loss: 14.9574 - val_mae: 2.7908\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6702 - mae: 0.5996 - val_loss: 14.7803 - val_mae: 2.7468\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7114 - mae: 0.6071 - val_loss: 15.2081 - val_mae: 2.7875\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7062 - mae: 0.6106 - val_loss: 16.0809 - val_mae: 2.8069\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6121 - mae: 0.5727 - val_loss: 15.4934 - val_mae: 2.8223\n",
      "Epoch 445/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7947 - mae: 0.6323 - val_loss: 15.1834 - val_mae: 2.7616\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6489 - mae: 0.5961 - val_loss: 15.6149 - val_mae: 2.8015\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6250 - mae: 0.5797 - val_loss: 14.2209 - val_mae: 2.7132\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7114 - mae: 0.6108 - val_loss: 14.5625 - val_mae: 2.7401\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6197 - mae: 0.5798 - val_loss: 14.5625 - val_mae: 2.7416\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6745 - mae: 0.5824 - val_loss: 15.3602 - val_mae: 2.7890\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7211 - mae: 0.6082 - val_loss: 15.1174 - val_mae: 2.7912\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6847 - mae: 0.5938 - val_loss: 14.7216 - val_mae: 2.7058\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6559 - mae: 0.6147 - val_loss: 14.4103 - val_mae: 2.6958\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7141 - mae: 0.5922 - val_loss: 15.4915 - val_mae: 2.7886\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6702 - mae: 0.6119 - val_loss: 15.1350 - val_mae: 2.7432\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6393 - mae: 0.5842 - val_loss: 16.3798 - val_mae: 2.8813\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6783 - mae: 0.6046 - val_loss: 16.1369 - val_mae: 2.8872\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6085 - mae: 0.5887 - val_loss: 15.5513 - val_mae: 2.8349\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6777 - mae: 0.6071 - val_loss: 15.3012 - val_mae: 2.7264\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6128 - mae: 0.5504 - val_loss: 14.1015 - val_mae: 2.6678\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7069 - mae: 0.6295 - val_loss: 15.5276 - val_mae: 2.8260\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7015 - mae: 0.6077 - val_loss: 14.4963 - val_mae: 2.6910\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6370 - mae: 0.5688 - val_loss: 14.3872 - val_mae: 2.7298\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6230 - mae: 0.5664 - val_loss: 13.9254 - val_mae: 2.6749\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.5793 - mae: 0.5668 - val_loss: 14.5706 - val_mae: 2.7200\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6957 - mae: 0.5863 - val_loss: 13.9833 - val_mae: 2.6147\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6338 - mae: 0.5967 - val_loss: 13.7411 - val_mae: 2.6455\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6404 - mae: 0.5768 - val_loss: 14.9978 - val_mae: 2.7436\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6115 - mae: 0.5543 - val_loss: 14.8699 - val_mae: 2.7648\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6050 - mae: 0.5762 - val_loss: 14.8342 - val_mae: 2.7538\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6344 - mae: 0.5614 - val_loss: 15.1617 - val_mae: 2.7552\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7260 - mae: 0.6187 - val_loss: 14.5261 - val_mae: 2.6946\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.5702 - mae: 0.5527 - val_loss: 15.2187 - val_mae: 2.8397\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6128 - mae: 0.5976 - val_loss: 14.5088 - val_mae: 2.6898\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.5525 - mae: 0.5411 - val_loss: 14.8216 - val_mae: 2.7207\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6476 - mae: 0.5837 - val_loss: 14.4294 - val_mae: 2.6410\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6969 - mae: 0.5874 - val_loss: 13.8956 - val_mae: 2.6177\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.5293 - mae: 0.5447 - val_loss: 15.0398 - val_mae: 2.7074\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6063 - mae: 0.5731 - val_loss: 14.8642 - val_mae: 2.6761\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6600 - mae: 0.5860 - val_loss: 14.7362 - val_mae: 2.6916\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6300 - mae: 0.5606 - val_loss: 15.3580 - val_mae: 2.7150\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7049 - mae: 0.6047 - val_loss: 15.3587 - val_mae: 2.7425\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.5829 - mae: 0.5691 - val_loss: 15.4722 - val_mae: 2.8540\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7264 - mae: 0.6143 - val_loss: 15.2988 - val_mae: 2.7802\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.5714 - mae: 0.5419 - val_loss: 14.9543 - val_mae: 2.7684\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7727 - mae: 0.5813 - val_loss: 14.6169 - val_mae: 2.7184\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6131 - mae: 0.5754 - val_loss: 15.4295 - val_mae: 2.7900\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6458 - mae: 0.5723 - val_loss: 16.3689 - val_mae: 2.8910\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6627 - mae: 0.5897 - val_loss: 14.8447 - val_mae: 2.7484\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6087 - mae: 0.5524 - val_loss: 14.7893 - val_mae: 2.7367\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6552 - mae: 0.5684 - val_loss: 14.7541 - val_mae: 2.6899\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.5517 - mae: 0.5537 - val_loss: 15.3554 - val_mae: 2.7776\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7035 - mae: 0.5834 - val_loss: 15.5456 - val_mae: 2.7959\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.5370 - mae: 0.5418 - val_loss: 14.9338 - val_mae: 2.7720\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.5899 - mae: 0.5466 - val_loss: 15.7424 - val_mae: 2.8388\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.5387 - mae: 0.5607 - val_loss: 15.1668 - val_mae: 2.7595\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6559 - mae: 0.5889 - val_loss: 14.3094 - val_mae: 2.6868\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.5447 - mae: 0.5397 - val_loss: 14.4452 - val_mae: 2.7163\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.5650 - mae: 0.5710 - val_loss: 15.1680 - val_mae: 2.7755\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.6883 - mae: 0.5642 - val_loss: 15.4041 - val_mae: 2.8339\n",
      "처리중인 폴드 # 3\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 178.9553 - mae: 10.1347 - val_loss: 66.1281 - val_mae: 5.5373\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 31.2589 - mae: 3.6143 - val_loss: 41.3831 - val_mae: 3.9955\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 21.4287 - mae: 2.9414 - val_loss: 32.9638 - val_mae: 3.4950\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 17.8435 - mae: 2.7267 - val_loss: 32.3121 - val_mae: 3.3379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 15.6326 - mae: 2.5182 - val_loss: 25.6311 - val_mae: 2.9893\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 14.0775 - mae: 2.4039 - val_loss: 27.3002 - val_mae: 3.1422\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 13.6404 - mae: 2.3353 - val_loss: 24.7614 - val_mae: 2.9792\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 12.2249 - mae: 2.2707 - val_loss: 20.3487 - val_mae: 2.6035\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 12.1367 - mae: 2.2398 - val_loss: 19.3238 - val_mae: 2.6773\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 11.5947 - mae: 2.1625 - val_loss: 21.7263 - val_mae: 2.8645\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 11.4134 - mae: 2.1551 - val_loss: 20.9502 - val_mae: 2.7252\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 10.7772 - mae: 2.1898 - val_loss: 21.4772 - val_mae: 2.7618\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 10.5092 - mae: 2.1782 - val_loss: 20.9066 - val_mae: 2.7585\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 10.0496 - mae: 2.0547 - val_loss: 21.5621 - val_mae: 3.0797\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 10.0836 - mae: 2.0735 - val_loss: 18.2424 - val_mae: 2.6383\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 9.6759 - mae: 1.9849 - val_loss: 18.0389 - val_mae: 2.4936\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 9.8221 - mae: 2.0350 - val_loss: 17.1576 - val_mae: 2.5700\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.8054 - mae: 1.9197 - val_loss: 17.4546 - val_mae: 2.6211\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 9.1499 - mae: 1.9625 - val_loss: 20.7297 - val_mae: 2.8519\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 8.9421 - mae: 1.9728 - val_loss: 18.1092 - val_mae: 2.6201\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 9.3149 - mae: 1.9928 - val_loss: 17.1944 - val_mae: 2.5147\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.9334 - mae: 1.8968 - val_loss: 19.3453 - val_mae: 2.8997\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 9.0977 - mae: 1.8817 - val_loss: 15.8576 - val_mae: 2.4057\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 8.6609 - mae: 1.9027 - val_loss: 15.5123 - val_mae: 2.4123\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 8.5106 - mae: 1.8617 - val_loss: 18.9608 - val_mae: 2.9654\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 8.7284 - mae: 1.8767 - val_loss: 13.9387 - val_mae: 2.3055\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.9144 - mae: 1.8634 - val_loss: 15.2450 - val_mae: 2.4510\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.7035 - mae: 1.8221 - val_loss: 16.0731 - val_mae: 2.6679\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.7745 - mae: 1.8359 - val_loss: 13.7037 - val_mae: 2.2790\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 8.0421 - mae: 1.7987 - val_loss: 15.6179 - val_mae: 2.5701\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.6738 - mae: 1.7944 - val_loss: 13.7892 - val_mae: 2.3920\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.7819 - mae: 1.8016 - val_loss: 12.6890 - val_mae: 2.2684\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.3411 - mae: 1.8145 - val_loss: 17.8427 - val_mae: 2.8537\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.3749 - mae: 1.7347 - val_loss: 14.6322 - val_mae: 2.3920\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 7.2064 - mae: 1.7347 - val_loss: 14.1871 - val_mae: 2.3873\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.4782 - mae: 1.7683 - val_loss: 14.0112 - val_mae: 2.3420\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.8820 - mae: 1.7753 - val_loss: 18.3037 - val_mae: 2.8390\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 7.0037 - mae: 1.7537 - val_loss: 13.3372 - val_mae: 2.3462\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.6951 - mae: 1.7447 - val_loss: 13.5946 - val_mae: 2.2698\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.8545 - mae: 1.6494 - val_loss: 13.1783 - val_mae: 2.3273\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.8543 - mae: 1.7126 - val_loss: 13.8393 - val_mae: 2.6416\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.5035 - mae: 1.7106 - val_loss: 12.1754 - val_mae: 2.4243\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.6926 - mae: 1.6819 - val_loss: 12.8050 - val_mae: 2.4720\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.7284 - mae: 1.6852 - val_loss: 11.6403 - val_mae: 2.1201\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.4920 - mae: 1.6838 - val_loss: 11.6104 - val_mae: 2.1730\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 6.0486 - mae: 1.6229 - val_loss: 14.3266 - val_mae: 2.5562\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.3414 - mae: 1.5982 - val_loss: 12.3853 - val_mae: 2.2957\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.4573 - mae: 1.6571 - val_loss: 10.8017 - val_mae: 2.1608\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.9976 - mae: 1.5532 - val_loss: 10.4049 - val_mae: 2.2398\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.8406 - mae: 1.6837 - val_loss: 12.3228 - val_mae: 2.2418\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.9384 - mae: 1.6009 - val_loss: 13.5292 - val_mae: 2.4758\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.2122 - mae: 1.5391 - val_loss: 13.1896 - val_mae: 2.5591\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 6.1678 - mae: 1.5910 - val_loss: 11.3495 - val_mae: 2.2229\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.8839 - mae: 1.5924 - val_loss: 10.3303 - val_mae: 2.2176\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8518 - mae: 1.6014 - val_loss: 12.9806 - val_mae: 2.6282\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.7885 - mae: 1.5841 - val_loss: 13.2714 - val_mae: 2.5758\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.5883 - mae: 1.5932 - val_loss: 12.3620 - val_mae: 2.4357\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.8278 - mae: 1.4912 - val_loss: 11.8246 - val_mae: 2.3738\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.8813 - mae: 1.5270 - val_loss: 11.9627 - val_mae: 2.3284\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.6846 - mae: 1.5065 - val_loss: 10.7110 - val_mae: 2.1078\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6701 - mae: 1.4936 - val_loss: 13.9688 - val_mae: 2.6710\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.5631 - mae: 1.5296 - val_loss: 13.4929 - val_mae: 2.6293\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.6585 - mae: 1.4624 - val_loss: 10.5427 - val_mae: 2.2130\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3905 - mae: 1.4855 - val_loss: 10.7181 - val_mae: 2.1728\n",
      "Epoch 65/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 5.5509 - mae: 1.4642 - val_loss: 13.5538 - val_mae: 2.7663\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 5.3166 - mae: 1.4567 - val_loss: 11.2841 - val_mae: 2.3316\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.8716 - mae: 1.4804 - val_loss: 12.4488 - val_mae: 2.3113\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.1947 - mae: 1.4470 - val_loss: 10.3359 - val_mae: 2.1412\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7976 - mae: 1.3757 - val_loss: 10.7199 - val_mae: 2.1726\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 5.1009 - mae: 1.4506 - val_loss: 12.6485 - val_mae: 2.5657\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.9526 - mae: 1.4184 - val_loss: 12.3003 - val_mae: 2.3667\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.8512 - mae: 1.4010 - val_loss: 10.6789 - val_mae: 2.2159\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.9216 - mae: 1.4063 - val_loss: 10.8636 - val_mae: 2.2055\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.5311 - mae: 1.3630 - val_loss: 16.5475 - val_mae: 2.9945\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7747 - mae: 1.4563 - val_loss: 12.0799 - val_mae: 2.3726\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.7761 - mae: 1.4348 - val_loss: 10.5885 - val_mae: 2.2348\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.7449 - mae: 1.4135 - val_loss: 10.4012 - val_mae: 2.2101\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5243 - mae: 1.4101 - val_loss: 12.2493 - val_mae: 2.4757\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.6866 - mae: 1.4138 - val_loss: 10.2447 - val_mae: 2.1790\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.5889 - mae: 1.4220 - val_loss: 10.1971 - val_mae: 2.1881\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6429 - mae: 1.4213 - val_loss: 10.5846 - val_mae: 2.2616\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.6554 - mae: 1.4514 - val_loss: 11.2461 - val_mae: 2.2570\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2633 - mae: 1.3511 - val_loss: 10.4178 - val_mae: 2.1454\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.6746 - mae: 1.3837 - val_loss: 11.1539 - val_mae: 2.2525\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.3509 - mae: 1.3555 - val_loss: 14.5612 - val_mae: 2.8808\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.5752 - mae: 1.3505 - val_loss: 10.6825 - val_mae: 2.1899\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.5574 - mae: 1.4256 - val_loss: 10.8207 - val_mae: 2.2418\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.4979 - mae: 1.2924 - val_loss: 10.7391 - val_mae: 2.2167\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1636 - mae: 1.3411 - val_loss: 12.6331 - val_mae: 2.3321\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.2654 - mae: 1.3522 - val_loss: 11.7694 - val_mae: 2.2757\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.3944 - mae: 1.3324 - val_loss: 10.9819 - val_mae: 2.2195\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.1585 - mae: 1.2617 - val_loss: 12.9297 - val_mae: 2.5071\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.5523 - mae: 1.3693 - val_loss: 11.0648 - val_mae: 2.2644\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.1211 - mae: 1.2939 - val_loss: 14.3935 - val_mae: 2.8649\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9025 - mae: 1.3096 - val_loss: 10.7376 - val_mae: 2.1835\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.3611 - mae: 1.3394 - val_loss: 11.5391 - val_mae: 2.3698\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.1603 - mae: 1.3137 - val_loss: 12.7725 - val_mae: 2.5748\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.2557 - mae: 1.3073 - val_loss: 12.7599 - val_mae: 2.6542\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.2600 - mae: 1.3070 - val_loss: 11.1018 - val_mae: 2.2651\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.0559 - mae: 1.3417 - val_loss: 10.9979 - val_mae: 2.2904\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.8610 - mae: 1.2448 - val_loss: 11.3819 - val_mae: 2.3600\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.9371 - mae: 1.2535 - val_loss: 11.8294 - val_mae: 2.2955\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 4.1257 - mae: 1.2873 - val_loss: 10.6059 - val_mae: 2.2432\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8465 - mae: 1.2249 - val_loss: 13.3146 - val_mae: 2.7119\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.7094 - mae: 1.2762 - val_loss: 10.8179 - val_mae: 2.2500\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8807 - mae: 1.2668 - val_loss: 10.8252 - val_mae: 2.3009\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0802 - mae: 1.3058 - val_loss: 10.6459 - val_mae: 2.2700\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 4.0112 - mae: 1.2816 - val_loss: 11.5344 - val_mae: 2.2964\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.7276 - mae: 1.2370 - val_loss: 13.6266 - val_mae: 2.5259\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.9598 - mae: 1.2653 - val_loss: 11.2899 - val_mae: 2.3671\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.8079 - mae: 1.2760 - val_loss: 15.8677 - val_mae: 2.9306\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8431 - mae: 1.2035 - val_loss: 11.2906 - val_mae: 2.3225\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.7762 - mae: 1.2708 - val_loss: 12.1800 - val_mae: 2.4936\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.7983 - mae: 1.2154 - val_loss: 12.5707 - val_mae: 2.4841\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.8043 - mae: 1.2495 - val_loss: 10.9446 - val_mae: 2.2916\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.5692 - mae: 1.2113 - val_loss: 10.9698 - val_mae: 2.3019\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.7003 - mae: 1.2060 - val_loss: 11.2041 - val_mae: 2.2628\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.7316 - mae: 1.1890 - val_loss: 11.6237 - val_mae: 2.4014\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.6236 - mae: 1.2342 - val_loss: 11.4458 - val_mae: 2.2957\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.5963 - mae: 1.2568 - val_loss: 14.7093 - val_mae: 2.8802\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.8395 - mae: 1.2246 - val_loss: 12.0547 - val_mae: 2.4132\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.6765 - mae: 1.2102 - val_loss: 12.9001 - val_mae: 2.5614\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3713 - mae: 1.2027 - val_loss: 17.1699 - val_mae: 3.1159\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.6190 - mae: 1.2289 - val_loss: 13.2464 - val_mae: 2.5852\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 3.5032 - mae: 1.2551 - val_loss: 14.9461 - val_mae: 2.8412\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.8362 - mae: 1.2010 - val_loss: 12.2700 - val_mae: 2.3894\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.5841 - mae: 1.1855 - val_loss: 11.9184 - val_mae: 2.3432\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4775 - mae: 1.1567 - val_loss: 11.9712 - val_mae: 2.3948\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3987 - mae: 1.2043 - val_loss: 11.1287 - val_mae: 2.2949\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.2803 - mae: 1.1857 - val_loss: 11.8347 - val_mae: 2.4098\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.3042 - mae: 1.1974 - val_loss: 11.5624 - val_mae: 2.3443\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4683 - mae: 1.1756 - val_loss: 11.7844 - val_mae: 2.4001\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.1993 - mae: 1.1661 - val_loss: 13.0190 - val_mae: 2.5399\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.6256 - mae: 1.1866 - val_loss: 10.9761 - val_mae: 2.2717\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2443 - mae: 1.1679 - val_loss: 11.8631 - val_mae: 2.4404\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.3201 - mae: 1.1150 - val_loss: 12.4373 - val_mae: 2.4484\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4706 - mae: 1.1917 - val_loss: 11.7082 - val_mae: 2.3741\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3508 - mae: 1.1274 - val_loss: 12.0292 - val_mae: 2.3855\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.3608 - mae: 1.1510 - val_loss: 12.0275 - val_mae: 2.2842\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1566 - mae: 1.1900 - val_loss: 11.9067 - val_mae: 2.4144\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2536 - mae: 1.1973 - val_loss: 12.1724 - val_mae: 2.4642\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2676 - mae: 1.1697 - val_loss: 12.3568 - val_mae: 2.4554\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.2298 - mae: 1.1747 - val_loss: 11.3555 - val_mae: 2.3267\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2493 - mae: 1.1955 - val_loss: 12.5726 - val_mae: 2.4524\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1192 - mae: 1.1457 - val_loss: 12.9188 - val_mae: 2.5193\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.3863 - mae: 1.1338 - val_loss: 11.3251 - val_mae: 2.3029\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.3559 - mae: 1.1244 - val_loss: 12.8205 - val_mae: 2.5803\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1194 - mae: 1.1118 - val_loss: 13.0543 - val_mae: 2.6150\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.3310 - mae: 1.1551 - val_loss: 12.0429 - val_mae: 2.3897\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.1532 - mae: 1.1096 - val_loss: 13.6816 - val_mae: 2.5165\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2127 - mae: 1.1262 - val_loss: 12.9770 - val_mae: 2.4738\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0868 - mae: 1.1434 - val_loss: 11.7709 - val_mae: 2.3432\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.4962 - mae: 1.1446 - val_loss: 12.2832 - val_mae: 2.4802\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.2176 - mae: 1.1168 - val_loss: 13.3674 - val_mae: 2.5639\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.1666 - mae: 1.0886 - val_loss: 12.1731 - val_mae: 2.4353\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.2139 - mae: 1.1038 - val_loss: 11.6844 - val_mae: 2.4169\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.1814 - mae: 1.1090 - val_loss: 11.9089 - val_mae: 2.3612\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.2778 - mae: 1.1521 - val_loss: 11.4598 - val_mae: 2.3573\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1515 - mae: 1.1470 - val_loss: 12.3849 - val_mae: 2.3943\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.2836 - mae: 1.1327 - val_loss: 11.6837 - val_mae: 2.3139\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.0281 - mae: 1.0891 - val_loss: 12.6663 - val_mae: 2.4319\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8339 - mae: 1.1376 - val_loss: 11.6899 - val_mae: 2.4012\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8263 - mae: 1.1271 - val_loss: 13.1125 - val_mae: 2.5875\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0327 - mae: 1.1777 - val_loss: 12.2427 - val_mae: 2.4183\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.1911 - mae: 1.1367 - val_loss: 11.5818 - val_mae: 2.4375\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.0121 - mae: 1.1352 - val_loss: 11.9945 - val_mae: 2.4255\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8094 - mae: 1.0557 - val_loss: 17.4204 - val_mae: 3.1176\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.9070 - mae: 1.1409 - val_loss: 11.4372 - val_mae: 2.3266\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.1842 - mae: 1.1311 - val_loss: 11.8309 - val_mae: 2.4339\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.9088 - mae: 1.0983 - val_loss: 12.5342 - val_mae: 2.4461\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.0787 - mae: 1.1252 - val_loss: 12.6885 - val_mae: 2.4692\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.6279 - mae: 1.0594 - val_loss: 13.1055 - val_mae: 2.5357\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 3.0996 - mae: 1.1035 - val_loss: 12.1397 - val_mae: 2.4035\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.8041 - mae: 1.1204 - val_loss: 13.9982 - val_mae: 2.6093\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8008 - mae: 1.1075 - val_loss: 13.1304 - val_mae: 2.5492\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8693 - mae: 1.1149 - val_loss: 13.2710 - val_mae: 2.5884\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.8529 - mae: 1.0546 - val_loss: 12.4074 - val_mae: 2.4893\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.8779 - mae: 1.0881 - val_loss: 11.6674 - val_mae: 2.3905\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.5478 - mae: 1.0349 - val_loss: 15.8593 - val_mae: 2.8837\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8674 - mae: 1.1061 - val_loss: 11.7565 - val_mae: 2.3510\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7055 - mae: 1.0500 - val_loss: 12.5148 - val_mae: 2.4951\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8542 - mae: 1.0356 - val_loss: 15.4979 - val_mae: 2.8746\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 3.0045 - mae: 1.0750 - val_loss: 13.4006 - val_mae: 2.5122\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.8886 - mae: 1.0817 - val_loss: 12.6166 - val_mae: 2.4710\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 2.7479 - mae: 1.0760 - val_loss: 11.3836 - val_mae: 2.3320\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.7710 - mae: 1.0436 - val_loss: 12.4379 - val_mae: 2.5003\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7421 - mae: 1.0744 - val_loss: 13.9687 - val_mae: 2.6769\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.4842 - mae: 1.0500 - val_loss: 11.4774 - val_mae: 2.3721\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.6367 - mae: 1.0366 - val_loss: 12.6453 - val_mae: 2.5335\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6850 - mae: 1.0599 - val_loss: 11.8804 - val_mae: 2.4149\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6116 - mae: 1.0546 - val_loss: 12.7659 - val_mae: 2.5727\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.5184 - mae: 1.0906 - val_loss: 13.0467 - val_mae: 2.5172\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.6720 - mae: 1.0588 - val_loss: 13.3117 - val_mae: 2.5585\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.6057 - mae: 1.0346 - val_loss: 11.7445 - val_mae: 2.3320\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.5072 - mae: 1.0448 - val_loss: 12.6127 - val_mae: 2.5256\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.7850 - mae: 1.0730 - val_loss: 13.4041 - val_mae: 2.6385\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.4673 - mae: 1.0193 - val_loss: 11.4661 - val_mae: 2.3645\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.6077 - mae: 1.0616 - val_loss: 13.7100 - val_mae: 2.6088\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.5922 - mae: 1.0813 - val_loss: 12.4063 - val_mae: 2.5021\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.3519 - mae: 1.0010 - val_loss: 12.1613 - val_mae: 2.3722\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.4667 - mae: 1.0632 - val_loss: 12.3837 - val_mae: 2.4487\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.4910 - mae: 1.0631 - val_loss: 12.3247 - val_mae: 2.3919\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.4494 - mae: 1.0364 - val_loss: 13.2368 - val_mae: 2.5760\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4622 - mae: 1.0351 - val_loss: 12.2610 - val_mae: 2.4062\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2893 - mae: 1.0293 - val_loss: 11.9478 - val_mae: 2.4243\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.5296 - mae: 1.0570 - val_loss: 13.3556 - val_mae: 2.5009\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.4486 - mae: 0.9681 - val_loss: 12.5722 - val_mae: 2.4103\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2514 - mae: 1.0274 - val_loss: 12.9901 - val_mae: 2.5155\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.3691 - mae: 1.0471 - val_loss: 12.2439 - val_mae: 2.2963\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4547 - mae: 0.9869 - val_loss: 13.0881 - val_mae: 2.6081\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.3231 - mae: 1.0308 - val_loss: 13.5483 - val_mae: 2.5038\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1978 - mae: 1.0050 - val_loss: 12.3088 - val_mae: 2.4028\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3536 - mae: 1.0266 - val_loss: 12.2970 - val_mae: 2.4056\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.4429 - mae: 1.0161 - val_loss: 12.3983 - val_mae: 2.4924\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3156 - mae: 1.0588 - val_loss: 12.0206 - val_mae: 2.4245\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2333 - mae: 1.0389 - val_loss: 12.4872 - val_mae: 2.4502\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.3811 - mae: 1.0602 - val_loss: 12.9705 - val_mae: 2.5344\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2800 - mae: 1.0267 - val_loss: 13.2435 - val_mae: 2.5067\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0993 - mae: 0.9988 - val_loss: 13.3517 - val_mae: 2.5543\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2370 - mae: 0.9953 - val_loss: 13.8232 - val_mae: 2.6308\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.4081 - mae: 0.9972 - val_loss: 12.8395 - val_mae: 2.4897\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1240 - mae: 0.9579 - val_loss: 13.2439 - val_mae: 2.4896\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.3338 - mae: 1.0142 - val_loss: 13.0575 - val_mae: 2.4929\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.3137 - mae: 0.9482 - val_loss: 13.0602 - val_mae: 2.5287\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1610 - mae: 1.0368 - val_loss: 15.3251 - val_mae: 2.8462\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.3100 - mae: 1.0240 - val_loss: 14.2798 - val_mae: 2.7204\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2098 - mae: 0.9950 - val_loss: 12.8768 - val_mae: 2.4760\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1353 - mae: 1.0148 - val_loss: 14.0277 - val_mae: 2.7308\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2574 - mae: 0.9701 - val_loss: 13.4642 - val_mae: 2.6288\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2480 - mae: 1.0083 - val_loss: 13.2355 - val_mae: 2.5533\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2657 - mae: 1.0043 - val_loss: 12.9523 - val_mae: 2.5724\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2781 - mae: 1.0093 - val_loss: 13.0902 - val_mae: 2.5054\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2792 - mae: 1.0027 - val_loss: 12.9133 - val_mae: 2.4357\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2064 - mae: 1.0051 - val_loss: 13.2579 - val_mae: 2.4770\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2468 - mae: 1.0204 - val_loss: 12.4664 - val_mae: 2.4904\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1464 - mae: 0.9808 - val_loss: 13.7491 - val_mae: 2.5803\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1488 - mae: 0.9812 - val_loss: 13.1293 - val_mae: 2.5907\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.0925 - mae: 0.9588 - val_loss: 14.9667 - val_mae: 2.7747\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.0330 - mae: 0.9603 - val_loss: 12.8748 - val_mae: 2.5058\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1853 - mae: 0.9587 - val_loss: 14.5019 - val_mae: 2.6783\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0052 - mae: 0.9826 - val_loss: 13.2536 - val_mae: 2.4895\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.0048 - mae: 0.9673 - val_loss: 13.6382 - val_mae: 2.5412\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1086 - mae: 0.9969 - val_loss: 14.0122 - val_mae: 2.5877\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.2220 - mae: 0.9973 - val_loss: 13.5587 - val_mae: 2.5528\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1775 - mae: 0.9807 - val_loss: 12.7571 - val_mae: 2.4316\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1101 - mae: 0.9934 - val_loss: 15.8754 - val_mae: 2.8764\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9144 - mae: 0.9710 - val_loss: 13.2987 - val_mae: 2.5364\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.0326 - mae: 0.9649 - val_loss: 13.0384 - val_mae: 2.5399\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0371 - mae: 0.9959 - val_loss: 13.6074 - val_mae: 2.5214\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0393 - mae: 0.9433 - val_loss: 14.6589 - val_mae: 2.5785\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8804 - mae: 0.9383 - val_loss: 13.1949 - val_mae: 2.5356\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9701 - mae: 0.9816 - val_loss: 13.1724 - val_mae: 2.5108\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9747 - mae: 0.9530 - val_loss: 14.3874 - val_mae: 2.5784\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.1655 - mae: 0.9747 - val_loss: 14.1440 - val_mae: 2.6772\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8388 - mae: 0.9559 - val_loss: 13.1731 - val_mae: 2.5709\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.0885 - mae: 0.9842 - val_loss: 13.7214 - val_mae: 2.6145\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9532 - mae: 0.9509 - val_loss: 14.0547 - val_mae: 2.5295\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8979 - mae: 0.9196 - val_loss: 16.4639 - val_mae: 2.9723\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.2519 - mae: 0.9686 - val_loss: 14.4832 - val_mae: 2.6316\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8284 - mae: 0.9246 - val_loss: 13.6337 - val_mae: 2.4209\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9800 - mae: 0.9874 - val_loss: 14.5461 - val_mae: 2.6647\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9765 - mae: 0.9932 - val_loss: 13.3608 - val_mae: 2.4674\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9369 - mae: 0.9243 - val_loss: 14.1678 - val_mae: 2.4999\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 2.1639 - mae: 0.9574 - val_loss: 12.9233 - val_mae: 2.4825\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 2.0174 - mae: 0.9543 - val_loss: 15.0443 - val_mae: 2.7573\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8642 - mae: 0.9275 - val_loss: 14.1658 - val_mae: 2.6910\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9089 - mae: 0.9277 - val_loss: 13.7025 - val_mae: 2.5548\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8972 - mae: 0.9406 - val_loss: 15.2084 - val_mae: 2.6944\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7044 - mae: 0.8970 - val_loss: 13.0507 - val_mae: 2.4371\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9884 - mae: 0.9769 - val_loss: 12.6061 - val_mae: 2.5110\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9620 - mae: 0.9699 - val_loss: 13.5850 - val_mae: 2.5695\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9158 - mae: 0.9642 - val_loss: 14.5349 - val_mae: 2.7024\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.8310 - mae: 0.9437 - val_loss: 13.8131 - val_mae: 2.5787\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9167 - mae: 0.9468 - val_loss: 13.9213 - val_mae: 2.5913\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9738 - mae: 0.9509 - val_loss: 14.1932 - val_mae: 2.5338\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8169 - mae: 0.9487 - val_loss: 14.8762 - val_mae: 2.8218\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9595 - mae: 0.9454 - val_loss: 13.9954 - val_mae: 2.5362\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.9220 - mae: 0.9374 - val_loss: 12.8615 - val_mae: 2.4764\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8244 - mae: 0.9368 - val_loss: 12.9271 - val_mae: 2.4865\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7617 - mae: 0.9574 - val_loss: 13.5246 - val_mae: 2.5939\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7592 - mae: 0.9218 - val_loss: 14.9088 - val_mae: 2.6801\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8199 - mae: 0.9217 - val_loss: 13.4149 - val_mae: 2.5985\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.8063 - mae: 0.9597 - val_loss: 14.4614 - val_mae: 2.6179\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7653 - mae: 0.9609 - val_loss: 14.4963 - val_mae: 2.6876\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.9188 - mae: 0.9312 - val_loss: 14.7111 - val_mae: 2.7024\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7401 - mae: 0.9174 - val_loss: 15.8499 - val_mae: 2.7322\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7620 - mae: 0.9259 - val_loss: 14.2311 - val_mae: 2.6285\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6900 - mae: 0.9231 - val_loss: 13.8988 - val_mae: 2.6045\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5477 - mae: 0.9257 - val_loss: 17.1431 - val_mae: 2.9184\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6673 - mae: 0.9111 - val_loss: 13.3382 - val_mae: 2.5125\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7766 - mae: 0.9149 - val_loss: 13.7883 - val_mae: 2.5728\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7237 - mae: 0.9140 - val_loss: 13.6000 - val_mae: 2.5727\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6971 - mae: 0.9019 - val_loss: 12.9928 - val_mae: 2.4543\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7154 - mae: 0.8829 - val_loss: 13.0207 - val_mae: 2.5021\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7007 - mae: 0.9391 - val_loss: 13.3534 - val_mae: 2.5196\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.6785 - mae: 0.9395 - val_loss: 14.3002 - val_mae: 2.6683\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.6183 - mae: 0.8862 - val_loss: 13.3733 - val_mae: 2.5474\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7100 - mae: 0.9196 - val_loss: 17.8156 - val_mae: 2.9541\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5443 - mae: 0.8978 - val_loss: 13.1676 - val_mae: 2.4953\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7380 - mae: 0.9109 - val_loss: 12.5897 - val_mae: 2.4380\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.6500 - mae: 0.8931 - val_loss: 14.8961 - val_mae: 2.6081\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.6577 - mae: 0.9237 - val_loss: 13.5329 - val_mae: 2.6234\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.6654 - mae: 0.9044 - val_loss: 15.9408 - val_mae: 2.8080\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.7113 - mae: 0.8980 - val_loss: 13.5571 - val_mae: 2.5255\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5022 - mae: 0.8605 - val_loss: 13.8357 - val_mae: 2.6697\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5880 - mae: 0.9074 - val_loss: 12.6403 - val_mae: 2.4467\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5242 - mae: 0.8667 - val_loss: 13.5755 - val_mae: 2.5516\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.6737 - mae: 0.8730 - val_loss: 14.0720 - val_mae: 2.5571\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5933 - mae: 0.9367 - val_loss: 12.8397 - val_mae: 2.5137\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5912 - mae: 0.8935 - val_loss: 16.5725 - val_mae: 2.9185\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.6384 - mae: 0.9085 - val_loss: 13.9456 - val_mae: 2.5628\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4951 - mae: 0.8567 - val_loss: 14.5817 - val_mae: 2.6070\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5104 - mae: 0.8999 - val_loss: 13.5519 - val_mae: 2.5650\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4119 - mae: 0.8583 - val_loss: 13.4855 - val_mae: 2.5803\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5615 - mae: 0.8869 - val_loss: 13.7083 - val_mae: 2.5957\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4866 - mae: 0.8822 - val_loss: 13.0498 - val_mae: 2.4840\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.7365 - mae: 0.9397 - val_loss: 12.2205 - val_mae: 2.3977\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5015 - mae: 0.8791 - val_loss: 13.5208 - val_mae: 2.5557\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4857 - mae: 0.8863 - val_loss: 14.3903 - val_mae: 2.6336\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4309 - mae: 0.8399 - val_loss: 13.3560 - val_mae: 2.5877\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5015 - mae: 0.8568 - val_loss: 13.3815 - val_mae: 2.6106\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.6033 - mae: 0.9032 - val_loss: 13.4681 - val_mae: 2.5729\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4351 - mae: 0.8542 - val_loss: 14.7720 - val_mae: 2.6822\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4359 - mae: 0.8260 - val_loss: 13.5766 - val_mae: 2.5452\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5226 - mae: 0.8962 - val_loss: 13.0724 - val_mae: 2.5290\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5559 - mae: 0.8798 - val_loss: 13.6463 - val_mae: 2.6724\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5937 - mae: 0.9356 - val_loss: 13.5819 - val_mae: 2.6394\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3386 - mae: 0.8327 - val_loss: 13.1096 - val_mae: 2.5315\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3668 - mae: 0.8601 - val_loss: 12.5399 - val_mae: 2.4412\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4836 - mae: 0.8446 - val_loss: 14.3802 - val_mae: 2.6996\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5279 - mae: 0.8773 - val_loss: 12.7691 - val_mae: 2.4629\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4020 - mae: 0.8553 - val_loss: 13.7212 - val_mae: 2.5671\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3909 - mae: 0.8464 - val_loss: 13.5562 - val_mae: 2.6172\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5327 - mae: 0.8832 - val_loss: 14.0677 - val_mae: 2.7049\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3337 - mae: 0.8245 - val_loss: 13.2710 - val_mae: 2.5118\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3669 - mae: 0.8399 - val_loss: 13.7874 - val_mae: 2.7099\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4019 - mae: 0.8500 - val_loss: 14.7469 - val_mae: 2.6429\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4259 - mae: 0.8901 - val_loss: 12.4201 - val_mae: 2.4229\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4822 - mae: 0.8418 - val_loss: 13.6435 - val_mae: 2.6302\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3830 - mae: 0.8552 - val_loss: 13.2177 - val_mae: 2.5992\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3497 - mae: 0.7880 - val_loss: 16.0306 - val_mae: 2.8711\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5751 - mae: 0.8973 - val_loss: 13.1259 - val_mae: 2.5437\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4423 - mae: 0.8607 - val_loss: 13.7734 - val_mae: 2.6540\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3962 - mae: 0.8655 - val_loss: 14.3733 - val_mae: 2.5445\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.5249 - mae: 0.8721 - val_loss: 15.1815 - val_mae: 2.6784\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2495 - mae: 0.8052 - val_loss: 13.5913 - val_mae: 2.6144\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.5106 - mae: 0.8978 - val_loss: 13.7422 - val_mae: 2.5151\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4949 - mae: 0.8672 - val_loss: 15.3323 - val_mae: 2.7966\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2939 - mae: 0.8003 - val_loss: 14.0771 - val_mae: 2.6747\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2884 - mae: 0.8366 - val_loss: 15.1801 - val_mae: 2.7573\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3577 - mae: 0.8528 - val_loss: 13.3829 - val_mae: 2.5456\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4066 - mae: 0.8865 - val_loss: 13.4605 - val_mae: 2.5235\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3977 - mae: 0.7908 - val_loss: 13.5114 - val_mae: 2.6412\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3462 - mae: 0.8387 - val_loss: 14.8980 - val_mae: 2.8006\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4327 - mae: 0.8457 - val_loss: 15.3299 - val_mae: 2.7177\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4101 - mae: 0.8469 - val_loss: 13.8178 - val_mae: 2.6538\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3380 - mae: 0.8570 - val_loss: 13.3116 - val_mae: 2.4656\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2841 - mae: 0.8088 - val_loss: 15.2008 - val_mae: 2.7675\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3711 - mae: 0.8325 - val_loss: 15.6384 - val_mae: 2.7478\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4069 - mae: 0.8383 - val_loss: 14.6738 - val_mae: 2.7021\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3963 - mae: 0.8363 - val_loss: 13.3910 - val_mae: 2.4551\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3913 - mae: 0.8498 - val_loss: 14.6233 - val_mae: 2.6846\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.3080 - mae: 0.8178 - val_loss: 13.4463 - val_mae: 2.5925\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.4283 - mae: 0.8392 - val_loss: 12.8285 - val_mae: 2.4429\n",
      "Epoch 365/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3224 - mae: 0.7922 - val_loss: 13.6826 - val_mae: 2.5743\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.4487 - mae: 0.8767 - val_loss: 13.6022 - val_mae: 2.6015\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2824 - mae: 0.8025 - val_loss: 14.2062 - val_mae: 2.6346\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2256 - mae: 0.7871 - val_loss: 14.2060 - val_mae: 2.6863\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3172 - mae: 0.8191 - val_loss: 13.2043 - val_mae: 2.5880\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3251 - mae: 0.8187 - val_loss: 14.0767 - val_mae: 2.6128\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2535 - mae: 0.8186 - val_loss: 13.7635 - val_mae: 2.5969\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1782 - mae: 0.8068 - val_loss: 13.1934 - val_mae: 2.5389\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3132 - mae: 0.7888 - val_loss: 13.6288 - val_mae: 2.6457\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2298 - mae: 0.7869 - val_loss: 13.6532 - val_mae: 2.6377\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2085 - mae: 0.7876 - val_loss: 13.2878 - val_mae: 2.6364\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2195 - mae: 0.7872 - val_loss: 13.7638 - val_mae: 2.5755\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2770 - mae: 0.7632 - val_loss: 12.7860 - val_mae: 2.5020\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1815 - mae: 0.7677 - val_loss: 15.1180 - val_mae: 2.7421\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1648 - mae: 0.7824 - val_loss: 13.0781 - val_mae: 2.6306\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2749 - mae: 0.7834 - val_loss: 12.7022 - val_mae: 2.5365\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1048 - mae: 0.7685 - val_loss: 13.5270 - val_mae: 2.6077\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.3739 - mae: 0.8410 - val_loss: 13.9093 - val_mae: 2.6165\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2482 - mae: 0.7887 - val_loss: 13.0824 - val_mae: 2.5918\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2871 - mae: 0.8035 - val_loss: 12.8717 - val_mae: 2.5645\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1853 - mae: 0.7940 - val_loss: 14.3964 - val_mae: 2.8243\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1555 - mae: 0.7802 - val_loss: 13.7480 - val_mae: 2.6699\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.2925 - mae: 0.8137 - val_loss: 13.0257 - val_mae: 2.5433\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1936 - mae: 0.7970 - val_loss: 12.9489 - val_mae: 2.5356\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1995 - mae: 0.8041 - val_loss: 12.7282 - val_mae: 2.6468\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1192 - mae: 0.7566 - val_loss: 12.7077 - val_mae: 2.5317\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0804 - mae: 0.7456 - val_loss: 13.0186 - val_mae: 2.5567\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1867 - mae: 0.7820 - val_loss: 14.2374 - val_mae: 2.6088\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0670 - mae: 0.7589 - val_loss: 12.2465 - val_mae: 2.5041\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0533 - mae: 0.7665 - val_loss: 12.6066 - val_mae: 2.5026\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1563 - mae: 0.7470 - val_loss: 13.5239 - val_mae: 2.5730\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2143 - mae: 0.7918 - val_loss: 13.3095 - val_mae: 2.6093\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1600 - mae: 0.7641 - val_loss: 13.5904 - val_mae: 2.5721\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2112 - mae: 0.7853 - val_loss: 13.8592 - val_mae: 2.6716\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0851 - mae: 0.7650 - val_loss: 15.4148 - val_mae: 2.7813\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.2753 - mae: 0.8132 - val_loss: 12.9714 - val_mae: 2.5349\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1776 - mae: 0.7815 - val_loss: 13.2949 - val_mae: 2.5797\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0935 - mae: 0.7695 - val_loss: 14.3675 - val_mae: 2.7011\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0666 - mae: 0.7503 - val_loss: 13.7529 - val_mae: 2.6525\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1628 - mae: 0.7828 - val_loss: 12.8316 - val_mae: 2.5855\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1390 - mae: 0.7654 - val_loss: 15.0557 - val_mae: 2.7447\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0843 - mae: 0.7597 - val_loss: 13.9831 - val_mae: 2.6699\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0985 - mae: 0.7682 - val_loss: 12.8445 - val_mae: 2.5461\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0560 - mae: 0.7381 - val_loss: 14.6779 - val_mae: 2.7501\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0818 - mae: 0.7526 - val_loss: 13.3826 - val_mae: 2.5950\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0259 - mae: 0.7589 - val_loss: 14.9907 - val_mae: 2.7508\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1574 - mae: 0.7516 - val_loss: 13.1896 - val_mae: 2.6051\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0403 - mae: 0.7350 - val_loss: 14.7573 - val_mae: 2.7419\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0847 - mae: 0.7613 - val_loss: 13.8145 - val_mae: 2.6953\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1210 - mae: 0.7722 - val_loss: 14.0637 - val_mae: 2.6535\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9993 - mae: 0.7247 - val_loss: 13.5147 - val_mae: 2.7115\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0423 - mae: 0.7428 - val_loss: 14.9969 - val_mae: 2.7541\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1323 - mae: 0.7651 - val_loss: 13.1761 - val_mae: 2.5904\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9511 - mae: 0.7432 - val_loss: 15.5337 - val_mae: 2.8609\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0518 - mae: 0.7493 - val_loss: 16.7537 - val_mae: 2.9123\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0802 - mae: 0.7425 - val_loss: 13.9042 - val_mae: 2.6749\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1010 - mae: 0.7466 - val_loss: 16.6430 - val_mae: 3.0315\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9527 - mae: 0.7398 - val_loss: 13.9426 - val_mae: 2.6201\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1043 - mae: 0.7618 - val_loss: 14.4963 - val_mae: 2.7316\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0670 - mae: 0.7608 - val_loss: 13.6807 - val_mae: 2.6226\n",
      "Epoch 425/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9675 - mae: 0.6808 - val_loss: 15.5422 - val_mae: 2.8515\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9926 - mae: 0.7312 - val_loss: 14.4586 - val_mae: 2.6705\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0926 - mae: 0.7589 - val_loss: 15.1212 - val_mae: 2.7294\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1389 - mae: 0.7743 - val_loss: 13.1934 - val_mae: 2.5516\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9194 - mae: 0.6892 - val_loss: 12.9243 - val_mae: 2.6016\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.1102 - mae: 0.7566 - val_loss: 14.7357 - val_mae: 2.7334\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0304 - mae: 0.7447 - val_loss: 13.6186 - val_mae: 2.6942\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.1609 - mae: 0.7408 - val_loss: 14.5855 - val_mae: 2.7403\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9804 - mae: 0.7216 - val_loss: 14.1259 - val_mae: 2.5952\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9974 - mae: 0.7283 - val_loss: 13.9796 - val_mae: 2.7097\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9721 - mae: 0.7341 - val_loss: 14.2971 - val_mae: 2.6911\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0706 - mae: 0.7516 - val_loss: 14.5307 - val_mae: 2.7118\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9444 - mae: 0.6928 - val_loss: 16.0449 - val_mae: 2.9097\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0426 - mae: 0.7441 - val_loss: 13.3062 - val_mae: 2.6281\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0387 - mae: 0.7289 - val_loss: 14.0870 - val_mae: 2.7625\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0492 - mae: 0.6962 - val_loss: 14.0592 - val_mae: 2.6945\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0439 - mae: 0.7171 - val_loss: 13.4625 - val_mae: 2.5793\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0345 - mae: 0.7305 - val_loss: 15.0878 - val_mae: 2.7753\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9405 - mae: 0.7138 - val_loss: 13.7222 - val_mae: 2.7056\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9426 - mae: 0.6976 - val_loss: 14.0868 - val_mae: 2.6301\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0055 - mae: 0.7289 - val_loss: 13.4263 - val_mae: 2.6702\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8897 - mae: 0.6987 - val_loss: 13.8851 - val_mae: 2.6649\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9846 - mae: 0.6919 - val_loss: 13.6312 - val_mae: 2.6551\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0873 - mae: 0.7349 - val_loss: 15.1411 - val_mae: 2.7925\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8526 - mae: 0.7095 - val_loss: 14.4398 - val_mae: 2.7781\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9806 - mae: 0.7040 - val_loss: 14.1946 - val_mae: 2.6729\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9029 - mae: 0.6902 - val_loss: 13.7860 - val_mae: 2.7577\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0175 - mae: 0.6948 - val_loss: 15.3813 - val_mae: 2.8170\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9320 - mae: 0.6960 - val_loss: 13.1614 - val_mae: 2.5949\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8648 - mae: 0.6836 - val_loss: 14.1557 - val_mae: 2.6643\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0494 - mae: 0.7356 - val_loss: 13.7138 - val_mae: 2.6715\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9132 - mae: 0.7035 - val_loss: 13.2662 - val_mae: 2.6484\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9414 - mae: 0.7153 - val_loss: 15.2178 - val_mae: 2.9024\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 1.0024 - mae: 0.6914 - val_loss: 14.5044 - val_mae: 2.6464\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0264 - mae: 0.7306 - val_loss: 14.0317 - val_mae: 2.6503\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9776 - mae: 0.7255 - val_loss: 16.6906 - val_mae: 2.8550\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9977 - mae: 0.7188 - val_loss: 15.3912 - val_mae: 2.7524\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8997 - mae: 0.7034 - val_loss: 13.0054 - val_mae: 2.5712\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8739 - mae: 0.6651 - val_loss: 14.8373 - val_mae: 2.7586\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8865 - mae: 0.7038 - val_loss: 13.6880 - val_mae: 2.5610\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0446 - mae: 0.7359 - val_loss: 15.5796 - val_mae: 2.8115\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9431 - mae: 0.7167 - val_loss: 14.2188 - val_mae: 2.6963\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9465 - mae: 0.6891 - val_loss: 14.6429 - val_mae: 2.6924\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9388 - mae: 0.6822 - val_loss: 15.4101 - val_mae: 2.7533\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9622 - mae: 0.7278 - val_loss: 17.3955 - val_mae: 3.0176\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9289 - mae: 0.7135 - val_loss: 15.8082 - val_mae: 2.8011\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9272 - mae: 0.6990 - val_loss: 15.4013 - val_mae: 2.7386\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0254 - mae: 0.7177 - val_loss: 14.5514 - val_mae: 2.6861\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8030 - mae: 0.6692 - val_loss: 13.8575 - val_mae: 2.7006\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8658 - mae: 0.7073 - val_loss: 15.0228 - val_mae: 2.8256\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.9814 - mae: 0.7405 - val_loss: 14.1431 - val_mae: 2.6264\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8584 - mae: 0.6901 - val_loss: 14.4428 - val_mae: 2.6716\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9699 - mae: 0.7107 - val_loss: 14.1772 - val_mae: 2.6945\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8178 - mae: 0.6816 - val_loss: 15.3014 - val_mae: 2.7341\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9813 - mae: 0.7230 - val_loss: 13.9070 - val_mae: 2.6878\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9735 - mae: 0.7162 - val_loss: 15.2978 - val_mae: 2.7841\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8618 - mae: 0.6975 - val_loss: 14.9046 - val_mae: 2.6860\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9163 - mae: 0.6982 - val_loss: 15.2788 - val_mae: 2.7789\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8591 - mae: 0.6727 - val_loss: 14.9515 - val_mae: 2.7260\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.7710 - mae: 0.6558 - val_loss: 15.2691 - val_mae: 2.8525\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9564 - mae: 0.7295 - val_loss: 14.8394 - val_mae: 2.7770\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8971 - mae: 0.6921 - val_loss: 16.8776 - val_mae: 2.8730\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8532 - mae: 0.6508 - val_loss: 16.2733 - val_mae: 2.8621\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8029 - mae: 0.6511 - val_loss: 15.2914 - val_mae: 2.7393\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9548 - mae: 0.6849 - val_loss: 14.1707 - val_mae: 2.6563\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.8018 - mae: 0.6360 - val_loss: 16.1359 - val_mae: 2.8902\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9022 - mae: 0.6924 - val_loss: 14.1856 - val_mae: 2.6803\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8141 - mae: 0.6903 - val_loss: 15.2575 - val_mae: 2.7582\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 1.0310 - mae: 0.7146 - val_loss: 14.9645 - val_mae: 2.7715\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8755 - mae: 0.6885 - val_loss: 14.7876 - val_mae: 2.6727\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.9027 - mae: 0.6678 - val_loss: 14.5273 - val_mae: 2.7255\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.7363 - mae: 0.6435 - val_loss: 14.6158 - val_mae: 2.7715\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8426 - mae: 0.6787 - val_loss: 14.2347 - val_mae: 2.6687\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8127 - mae: 0.6524 - val_loss: 15.2771 - val_mae: 2.8191\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8142 - mae: 0.6521 - val_loss: 14.7875 - val_mae: 2.6625\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.8749 - mae: 0.6762 - val_loss: 15.6940 - val_mae: 2.8164\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "    \n",
    "    print('처리중인 폴드 #', i)\n",
    "    \n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    \n",
    "    model = build_model()  # 케라스 모델 구성(컴파일 포함)\n",
    "    \n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                    validation_data=(val_data, val_targets),\n",
    "                    epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    \n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 epoch에 대한 평균 MAE 점수 계산\n",
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3wc1bXA8d9ZdcuWi1xwl40B495wwTQbA8bUUAIECPAglBAgLwkBQh4BQiCkACGhmRIgQCChBxzAxriAwUZy793GVZKLetd9f0zR7O7sal1Wsr3n+/noo93Z2dk7KnPmtnPFGINSSqnEFWjuAiillGpeGgiUUirBaSBQSqkEp4FAKaUSnAYCpZRKcMnNXYB91b59e5OTk9PcxVBKqcNKXl5eoTGmg99rh10gyMnJITc3t7mLoZRShxUR2RTpNW0aUkqpBKeBQCmlEpwGAqWUSnAaCJRSKsFpIFBKqQSngUAppRKcBgKllEpwCRMIVu0o4bHPVlFYWtXcRVFKqUNKwgSCtfmlPDl9LbvLqpu7KEopdUhJmEAgYn2v14V4lFIqSMIEgoAdCDQOKKVUsIQJBGBFAq0RKKVUsIQJBFojUEopfwkTCMTuJNBAoJRSwRImELg1AjQSKKWUV8IEgoZRQ81bDqWUOtQkUCDQzmKllPKTMIEgoH0ESinlK2ECgd0yhNFIoJRSQRImELg1gmYuh1JKHWoSJhC4ncXaW6yUUkESLhBoGFBKqWCJEwg0xYRSSvlKmEAQcHuLm7UYSil1yEmYQNAwj6CZC6KUUoeYhAkEmmJCKaX8JUwg0BQTSinlL+6BQESSRGSBiHzk89q1IlIgIgvtrxviWA5AJ5QppVSo5Cb4jDuAFUBWhNffMsb8JN6FaJhZHO9PUkqpw0tcawQi0g04B3ghnp8Ti4aZxRoJlFLKK95NQ08AvwTqo+xzsYgsFpG3RaR7vArSMLM4Xp+glFKHp7gFAhE5F8g3xuRF2e0/QI4xZhAwDXglwrFuFJFcEcktKCjYr/JoriGllPIXzxrBWOB8EdkIvAmMF5HXvDsYY3YZY6rsp88Dw/0OZIyZbIwZYYwZ0aFDhwMqlM4sVkqpYHELBMaYe4wx3YwxOcDlwHRjzFXefUSks+fp+VidynGh6xEopZS/phg1FEREHgRyjTEfAreLyPlALbAbuDZenxuwQ54OH1VKqWBNEgiMMTOAGfbj+zzb7wHuaYoyNCSda4pPU0qpw0fCzCzWFBNKKeUvYQKBpphQSil/CRQINMWEUkr5SZxAYH/XOKCUUsESJhBoigmllPKXMIFAU0wopZS/hAkEmmJCKaX8JUwgcGiKCaWUCpYwgSDQMJFAKaWUR8IEAmfUkNYIlFIqWMIEAu0jUEopfwkTCBpmFmsoUEopr4QLBBoHlFIqWOIEAjTFhFJK+UmYQKCDhpRSyl/CBAIn6Vy9ph9VSqkgCRMIApqGWimlfCVMIBAdPqqUUr4SKBBY37WzWCmlgiVMIHAnlGkcUEqpIAkTCDTFhFJK+UuYQKApJpRSyl/CBAJNMaGUUv4SLhBoHFBKqWCJEwg0xYRSSvlKmEAQ0BqBUkr5SphA4KaY0ECglFJBEiYQNCSd00iglFJeCRMItEaglFL+4h4IRCRJRBaIyEc+r6WJyFsislZE5opITnzLgnYSKKVUiKaoEdwBrIjw2vXAHmNMH+Bx4NF4FkTQGoFSSoWKayAQkW7AOcALEXa5AHjFfvw2cLo4bThxEBDRPgKllAoR7xrBE8AvgfoIr3cFvgMwxtQCRUB2vAojojUCpZQKFbdAICLnAvnGmLxou/lsC7tUi8iNIpIrIrkFBQUHUiZNMaGUUiHiWSMYC5wvIhuBN4HxIvJayD5bgO4AIpIMtAZ2hx7IGDPZGDPCGDOiQ4cO+12ggKBZ55RSKkTcAoEx5h5jTDdjTA5wOTDdGHNVyG4fAtfYjy+x94nbpVrQGoFSSoWKGAhE5Jeex5eGvPbw/n6giDwoIufbT18EskVkLfAz4O79PW4sAqKjR5VSKlS0GsHlnsf3hLw2cV8+xBgzwxhzrv34PmPMh/bjSmPMpcaYPsaYkcaY9fty3H1l9RHE8xOUUurwEy0QSITHfs8PCyKaYkIppUJFCwQmwmO/54cFnVislFLhkqO8NlhEirGunxn2Y+zn6XEvWRwEAqLrESilVIiIgcAYk9SUBWkKmmJCKaXC7dPwURHJFJErReTjeBUonjTFhFJKhWs0EIhIqohcKCL/ArYDE4Bn416yONAUE0opFS5i05CInAFcAZwFfAH8AxhpjLmuicp20ImIdhYrpVSIaJ3FnwKzgZOMMRsAROQvTVKqOLFGDWkkUEopr2iBYDjWpLJpIrIeK1/QYd2BHNAagVJKhYnYR2CMWWCMucsYczRwPzAUSBWR/4rIjU1VwIPJ6iPQSKCUUl4xjRoyxnxljPkJ1voBTwBj4lqqOLFGDSmllPKK1lk8LMJLBcBf41Oc+NMagVJKBYvWR5ALLMO68ENwfiEDjI9XoeIlEOAwTY6hlFLxEy0Q/By4GKjA6ih+zxhT2iSlipOArlCmlFJhonUWP26MOQn4CdYqYp+LyL9EZEiTle4g0xQTSikVrtHOYnsOwQfAZ8BI4Nh4FypetLNYKaXCRess7o01j+AC4Dus5qHfGWMqm6hsB58OH1VKqTDR+gjWAouxagPFQA/gxyJWn7Ex5rG4l+4gC1gr0yillPKIFggepOGy2bIJyhJ3Vh+BRgKllPKKth7B/U1YjiahKSaUUircPq1HcLjTFBNKKRUuwQKBjhpSSqlQiRUI0DTUSikVKlpnMQAikoY1wzjHu78x5sH4FSs+AgG0j0AppUI0Ggiwho8WAXlAVXyLE1+CpphQSqlQsQSCbsaYiXEvSRMI6DQCpZQKE0sfwRwRGRj3kjQFEc01pJRSIWKpEZwEXCsiG7Cahuw+VzMoriWLg4BoZ7FSSoWKJRCcHfdSNBErgjV3KZRS6tASS/bRTUAb4Dz7q429LSoRSReReSKySESWicgDPvtcKyIFIrLQ/rphf04iVlb2UY0ESinl1WggEJE7gNeBjvbXayJyWwzHrgLGG2MGA0OAiSIy2me/t4wxQ+yvF/ah7PtMBOrr4/kJSil1+Imlaeh6YJQxpgxARB4FvqaRdYuN1RjvrGiWYn816+246AplSikVJpZRQwLUeZ7XEbx+ceQ3iiSJyEIgH5hqjJnrs9vFIrJYRN4Wke6xHHd/6fBRpZQKF0sg+DswV0TuF5H7gW+AF2M5uDGmzhgzBOgGjBSRASG7/AfIsUcgTQNe8TuOiNwoIrkikltQUBDLR/sSREcNKaVUiFg6ix8DrgN2A3uA64wxT+zLhxhj9gIzgIkh23cZY5zZys8DwyO8f7IxZoQxZkSHDh325aODaIoJpZQKF22pyixjTLGItAM22l/Oa+2MMbujHVhEOgA1xpi9IpIBTAAeDdmnszFmu/30fGDFfp1FjDTFhFJKhYvWWfwGcC5WjiHv1VPs570bOXZn4BURScKqefzLGPORiDwI5BpjPgRuF5HzgVqsGse1+3UWMQoEhDqNA0opFSTaCmXn2t977c+BjTGLgaE+2+/zPL4HuGd/jr8/UpOE2jodP6qUUl6xzCP4PJZth4OUpAA1GgiUUipItD6CdKAF0F5E2tIwZDQL6NIEZTvorECgbUNKKeUVrY/gJuCnWBf9PBoCQTHwVJzLFRcpSQGqa7VGoJRSXtH6CP4C/EVEbjPGRJ1FfLhISRJtGlJKqRCNppgwxvzVngjWD0j3bH81ngWLB+0jUEqpcLGsWfwb4DSsQDAFKy31l8BhGQhqtY9AKaWCxJJi4hLgdGCHMeY6YDCQFtdSxUlKslCtNQKllAoSSyCoMMbUA7UikoWVQK6xyWSHpFRtGlJKqTCxpKHOFZE2WLmA8rBSS8+La6niJCUpQL2BunpDUiCmBKpKKXXEi6Wz+Mf2w2dF5BMgy541fNhJSbIqQDV19SQFkpq5NEopdWiINqFsWLTXjDHz41Ok+ElJsmoB1XX1pKdoIFBKKYheI/iz/T0dGAEswppUNgiYC5wU36IdfKnJdo1AJ5UppZQrYmexMWacMWYcsAkYZq8HMBwrkdzapirgwZQccJqGdAipUko5Yhk11NcYs8R5YoxZirUY/WHHaRrSkUNKKdUgllFDK0TkBeA1rHUIriLOC8jEi9M0pHMJlFKqQSyB4DrgFuAO+/ks4Jm4lSiOnFFDOrtYKaUaxDJ8tBJ43P46rHmHjyqllLJEGz76L2PM90VkCcFLVQJgjBkU15LFgXf4qFJKKUu0GoHTFHRuUxSkKaQm6fBRpZQKFW09gu32901NV5z4SknW4aNKKRUqWtNQCT5NQliTyowxJitupYoT7SNQSqlw0WoErZqyIE0hOaB9BEopFSqW4aMAiEhHglco2xyXEsWRm2JCA4FSSrkanVksIueLyBpgAzAT2Aj8N87ligttGlJKqXCxpJj4LTAaWG2M6YW1WtlXcS1VnLjDR3XUkFJKuWIJBDXGmF1AQEQCxpgvOExzDbVMs1rCSqvqmrkkSil16Iilj2CviLTESi3xuojkA7XxLVZ8OIGgpLKmmUuilFKHjlhqBBcAFcD/Ap8A64Dz4lmoeElOCtAyLZniisMyjimlVFxEm0fwN+ANY8wcz+ZX4l+k+GqVnqw1AqWU8ohWI1gD/FlENorIoyKyT/0CIpIuIvNEZJGILBORB3z2SRORt0RkrYjMFZGcfSv+vstKT6FYA4FSSrmirVD2F2PMGOBUYDfwdxFZISL3icixMRy7ChhvjBmM1bk8UURGh+xzPbDHGNMHK7vpo/t1FvvAqhFo05BSSjka7SMwxmwyxjxqjBkK/AD4HjEsTGMspfbTFPsrNGXFBTQ0N70NnC4iEmvh90dWhtYIlFLKK5YJZSkicp6IvI41kWw1cHEsBxeRJBFZCOQDU40xc0N26Qp8B2CMqQWKgGyf49woIrkikltQUBDLR0ekNQKllAoWMRCIyBki8hKwBbgRmAIcbYy5zBjzfiwHN8bUGWOGAN2AkSIyIPRj/N7mc5zJxpgRxpgRHTp0iOWjI8pKT6G4QmsESinliFYj+BXwNXC8MeY8Y8zrxpiy/fkQY8xeYAYwMeSlLUB3ABFJBlpj9UfEjVMjMEZTUSulFETvLB5njHneGLNfF2YR6SAibezHGcAEYGXIbh8C19iPLwGmmzhfoTPTkqmtN7omgVJK2WLOProfOgOviEgSVsD5lzHmIxF5EMg1xnwIvAj8Q0TWYtUELo9jeQBIT0kCoKKmzs1GqpRSiSxugcAYsxgY6rP9Ps/jSuDSeJXBT3qKdfGvqqmDjJSm/GillDokJdwtcYanRqCUUioBA0G6BgKllAqScIHAqRFU1uiaBEopBQkYCNLsPoKKaq0RKKUUJGAgcGsEtRoIlFIKEjAQOH0ElVojUEopIAEDgY4aUkqpYAkXCNK1s1gdJj5btoMPFm5t7mKoBBDPmcWHJK0RqMPFjf/IA+CCIV2buSQq3tbml5CTnUlyUvPcmydejSDVOuVKDQRHtIenrCDn7o8jJhfcVVrFyh3FTVyq2L0+d1PQ8+1FFazNL3Gf/zv3O77bXd7UxVJxsL6glAmPzeKJaWuarQwJFwhS7Yj7xtzN1Ndr4rkj1eRZ6wGoqvVvApz05GwmPjH7oH1ecWUNX6/bddCOd+97S4Oej3lkOhMemwVAeXUtd769mKteDF3eY/+UVh352Xh3FFWSc/fHzFiV39xFCbNlTwUA8zfvabYyJFwgcBZA27q3gs9XHnp/FOrgirT2xM7iKoCgC+BFT3/FqIen7dfn3PbGAq54/huKyg98rYvauuDgFXqRLiypBmBncWXQ9tU7S6jzubnZXlTBMzPWhR0nv6SSm/6Ry4DffMrzs9cfcLkPZQu/2wtYN4CHmmr7ZqU5k2AmXCDw2lFU0dxFUHFW3MhqdN4aw/zNe90Asa+cZqay6gNf/a6sKrjZMrRWU1hmlTEl0PDvu6GwjDMfn8VjU1e5275et4u1+SX85I0FPPrJStYVlAYd5663F/Ppsp0AvDv/yO6UdoJgIL4r4e6XajvwpzZT/wAkaCC4enRPADYUahvroaK6tp7yCBfRrXsrKKuKfIEtq6rl02U7fF9rbH3q0ijH3RfJ9kU50jnsi5Kq4DJ7l1bdureCtTtL7f1qybn7Y/I27WZPuVVLmLa8oZZ7xfPfMOGxWZTYP4PqWutiaIxh2vKdfLuxoSmi9iA2kz49Yy1LthTt13tLq2oZ8dBU5qwtPGjlAXBOrznjQFF5je/fsfP70RpBE/vthQPo1zmL9YWlje+smsTFz8yh332f+r429vfTueL5byK+9+53l3DTP/JYm9/w+3T+4b0X0b32xdKr9CCtX52cZH1gaVX0QQjf7S4P6vT1E1oj8DZnjP39dH75zuKg1/+zaLt7Hnt8ztG5C169swRjDJt2lXPDq7lBQTC0Oaoxy7cVM3d9eJ9IbV09f/hkFef97ct9Op5j5fZiCkur+eNnqxrfeR8YmqdG8OPX83je7q8a/OBnjPvTjLB9iius30NaclJTFi1IQgYCgB7tWridNKr5LdnqfwfpVOkXR7nDXLndapbxjgRz/uGdPoJZqwsY8uBUvlwTfKfpVyOoqavnq7WFvJO3pdFyl1fXUl1bT3LADgSNBJaT//CF2+nrlV9cyVL7ZxBapsenrY56zE5Z6ey1z9P57u0PcILUT99ayHsLtrr7eDW2Yl/owIpJT87mssnhwbkoQp9MaId0fb3xHawRr+t0rX1+zvGnLt+537XBV7/eyBcx9i9OWbKD301Z4T7PLwlvenR+ZnX19fsckA+WhA0ErdKTD9rdoDp4Qjs7I4368dvHW+0OhNQIZq4uAGDptuCAUuLzN7BiezFXvjCXn/97UaOf3e++T/nhS3NJsdt3vReXxVv2Rgwmu0qDLwin/3km5/71y7BjxKKipo4iuyZQXVuPMYZyTwoV77Vl/uY9lNvH//u1J3j2iRwIKqrr6P2rKbzg06FcWVPHw1NWMOGxmQC+QWZ3WTUDfvMpz81qeP/lz3/DyIensaEweBl0p6zRBjF9sHAr97y7JPIOPpybhIAI327czY9ezeWxz8ID7CdLd4R1woe674NlXPfyt41+pjfw/SLK35ITCN5fuI0bXs313Wf+5j1xHeWYsIEgMy05aruzahq7y6qD/sBDR/nE8juqshMIejuG3RqB3f7qHLd1Roq7PzRcdL3/tOf/7auwz1i9s4RbXsvznX/yzfrdJDk1Avt4ReU1nP+3ryIGk+EPTaOksoaJT8xi2vKdlHjO0znnRy4aGPW8HQUlVby7oKGzt6SqNijArdjeMF8iORCgzA4S7Vumudtr6xuixWvfbGLKku3u87e+tZqm3pgXPuJmXUEpk2etZ21+KTV19W7zm7fjc7s9KOOVORsB2LyrnHkbdlNYWs3SrUUYY5i5uoAH/7Pc7WOJdsm7482F/NOnLJG8k7eFlTus5jgRmLfBWoa9rj74JqOqto6bX8vjsue+9j3OlCXb+cc3DfM7bnjlW6Yt3xnxc703MW9HqV16+7FmrLJuWNYVlJJfYgWkr9ft4qKn5/DilxsiHuNAJdzMYkfLtGTKqq3qqhyCIwkSwa7SKoY/NI2fjOvjbttTXk3bzFT3eWh7uR9n+J03iDjX9b3lNfz6/SXkbbI6RoXgWkCp3TFbHaFKXl9vCASEO99ezKLv9rJqx2xe/9EoOrfOCAoozoxQ5yI+c02B+1pVbZ1v++9Xa3exckcJd3vubuvqjdsM1r1tCwBG5rTjytE9uOPNhb5lDL0o5hdXRZwXkJIkbhkz0xrK5E3L/uv3rTkMub+eQPuWaXyz3rpwHt2hZdjxvP0yx9z7XwZ2be1+znsLtvDG3M1cf1JvoOHO97PlDR37787fws//tcj9+Z+Q09Z6IYZ5DZ8s3c5Z/Y+i3uAGYuuthjfmbea04zrSoWVaUDD+dNkOVtud7d6/M2hoq9+4K3wQyTt5W8KC+rQV+Uxbkc/qh8727eiNNHQ51F6fIcen/9mqYW38/TluIA2tzR5MCV0jqDeaaqI57S6z7h7/u7Th7tPbtDDhsZmc9qcv3OfOxdxRW1dPfb1x77ycO6uq2jr3wpK7cTevfbOZ9XYTRFl1XdA/qNM8WB4h4DhBo8r+O1lfWMZTX6y1Pq+iIaAkh9QIvl7X0Bfh948O8OVaK1g462gDzN2wi2dnrgOgf5csHji/P89dPZzM1OB7tuE923LnWcfR96hWYcf93tNfhTW5OCpq6twhrplpDccsq64La65y7k5X253b3s729i2ti+iWPRVB7fpOX09KcoDHp67h2417eOS/Vht5eXUdD/xnGQ99vIIe7VqQFBC+WFUQFIQL7TJ4w8AXK/NZsqWIF7/cEDQb/ObX5nP9K7n0uXdK0PZX5mzk3veW8rfpa9hVFnxOlTX1bg0pdE2SSCPMisprojYTbt3r39cYaehyaJDetCv4d+VtGly6tci9yaiJY/9BwgaClvbd0MEaPnikqa83PPLfFU2SxsD7b+G92KzNL8XbLHrxM3OC3vfDl+Yx7s8z3PZw58LsrUXkhgSPiuraoA5Np0km0vj/8X+ewSdLdwRdrNpkWBdB73Hq7X9uJ3DM37TXfe3fud8xdfnOsAvArNVWsHDyXwF8vqKhEzIzLZlrTsyhbWYqLVKDaxQ9s1tw67g+tAu5q3XK8JfP/dMVTF2+k8327zT0mNNX5gc10y3ZspfKmjo22XfITuCGhj6F7UUVdGqVHvY5ARH3or7Jc4f99682AtC1TQZtW4SXfYfdPr94SxGfLLVqDte9/C3n/e1LfvvRcs59Mng00vSV+RhjzcSurq1n694KptsBbMueCnfynZ/y0EDgcwe/vqCUwQ9+FvEY0ND05di0q4yLn5kT8X/HufmsqaunsLSKTSH7feOZoT5vw263v2t7UWXUvpwDkbCBwLkbiqXpIRGt2FHMczPXc/ubC+L2Gc6dvPf6uKcsenXaezGds25X0EXGuaNzLtDe5gJHWXVd0BDLxz5bzQuz14ddFBy7yqq5+bU81hc03LWl2c0A3jtIJ5ttWVUttXX1rC8sZXD3NgD86bPV/OjV3LDPcC7I6Z5AMN0zGsXb3JAectF2ypCVnuJuu+nU3u7jZdusu97/nXBs0Pt2Flfx3Eyr07aFp5bRKj2ZO99e7L4P4JNlO5j0l9nU1RvaZaayt7yGwtIq5qwtdM9lR1EVAYGs9OAay+6yasqr68KCjeM35/cj2yeIbS9q6Ki9+bU8LnwquL8m0nyHvE17+MHz3zD299PdO/7l24rdYOQnNPh77+CdgOg0i0WzNWT04eRZ68nbtIfXvtnku7/TNHXHmwsY8dC0sFaw2Z5mxQc/Wu7WhBds3svvPl5BPGgg0BqBL7+L9P7YXVYdcUic08bu/R2s2F7MZp82WkeB/Y/td0znjm7LHuv9p/ftGLZPRXUduz3Bprbe8NDHK2Juz4WGWoS3RuBcfEoqa1hXUEZNneGEnm2D3ufUPs/o14nRvdsFlcGxobCMfp2zeOoHw4LeG3pBdUYptc6wAsHJx7Tn7ol9w8qa076F7zlkpCSRFBA+uHUsb904mnsnHQ/AN/bcgHaZqewsrmJ9YRk9s1tw6Yhu7CqrZsRD0/jBC3Pdv49pK3ayraiSi4Z18/2cswd0dh9PON76fTx39XD6HpXFbjsg926f6e6zoyh4xI6TGiIWTu2voKSK1OQAu8qqWb0z8pyNiuo6yqpq6ft//+WMx2ZyzUvz3Nd2llRijGH6ysidwY47317Ml2sKqa2r561vN7v9QRt2+TfPXfjUV3y1tpApS/wnQb4zfyut0pIZ1cv6G3FqUQBd2oTXvg6GhA0ELe1AoE1D/tz8Jwcw7f2dvC0M++1U39EmABXV1md4O29f+HIDp/zxC/eCFOqF2RtYtq0oqJnC8e+8LeRu3O3WEq4a3ZNubTO4/7x+vPDDEXRunU5ZVS277Xbj/l2y3Pde8qw1UuTNG0eHXYQBzhnUmTl3j7fLGzwSyWv59mLOesKaJzAip13Qa07gOG9wF47v3PDZW/cEB75RvdtxzqDOQdu8zUeA26wyoKt1nM27yxER7p10PG/cMIqTj2kPWPNlAI7KCr6AODdCg7u3YVTvbPeC7QS0s/of5e779s0n+jbjeLVKT+acgZ25YmR3rhjZw93+o1N6MaR7G64a3YO/XjGM331vAOPtAF1gj6m/eHhDEAkNBLHo3SEzbJvT6eyMFvJTXl3HrNUFVNbUsyY/eHLp8m3FzFhVwDRPU503eIf+X/xn0TaembGOu95ZwstzrNE9Ti3y7ZvHhH32lS8EJwxM9tReS6tquXh4N568YmjY+7q1zYh4PgciYQOB1giiczqmDmTa+wx77P6mCHf4zlBMvw770I5hx+RZ6znnyS/DJuYM7maNVvnpWwvZvLuc1OQAJ/Vpz5d3jefasb2Y0K8TGalJ/DtvC1+v20VqUsC3fT0rPYVzBnXmjRtGBW1vkZJElzYZ9G6fyT/nfcc7eVt8A4FT7QcY0zs76LVpK6y7y1ZpyXRp3fAPHdqpGHrRBsjw1AguGtqVW047GoBLR3Snfcs0bjrFev6jU3pzYp/2/Oa8/tx9dl+624Ggtt7wzJUNAc7bQQ2QlZGMCO4wVOfu/arRPejQKo2kRkbWZaYl89SVw3jkokF0b9dwbsd2bMX7t47loQsHkpGaxJWjerq1mZevO4H/nXAs/TwBeft+BAJndJXXCXYQXrmjhMwIzVMzVxdwy+vzfV+bvaaQjz1DaAEe+/4Q9/H0X5zKkvvPdJ+/lfsdj9kT/0Jbr3r7jLYKVR9S9R7esy2dstI5Z2DwDUHXNv41vAOVsIHA6Sy+/pXcg5If5kiyo6jSveNOSWoYjx9LNdmr1L5zjvTzrayN3D/jbZP3UxDS9nvXxL48dOEAtuypYPaaQrq3zSAQ0kfgdCZ/saqAtpkpYf98PxnXh+M7W6NwBtnt+w7nztqZpfvzfy/ila+D24A7tmoYl//StSNo3SKFY5TG1q0AABnlSURBVDs1XAT+8ImVNqFVejKdWlsX+65twu/wOvkEAm9fwC8n9nX7FdJTksj99QR+MKpH0P59Orbk5lOPJjszlWtPzOHv157A2QM784eLBwGEzaoXkaBmwE5Z6cz/vzO4/7z+gFW7uv30Y4Lec++k4907We8IJGeEU1Z6ctjvwOu04zpyx4RjOO3YDvz6HKtpKtoovrQINyXeoNaldTr3n9ePSQMbajg57cNrDNEc26klL8/ZyNt5W0hJEvccs1um8qOTewHQsVU6rdJT+OIXp3HBkC6A1Yzq3JC0b5nKNWN6MqBrFm0yUuhllyHv1xNYdN+ZLPrNmVzsaU4b2iO4GdFpAuoVUvauWiM4uLx/uHNj6BBKJBc/M4dH/7sSaKgR/OythfzPy7lsizBUDqzqdM7dH7OxsIxPlu5glp3OwWn6+cMnK93JPBB9udDG8kAVhGQJzUxLZpj9z7Rie7HvmHdvx2G7zDRG9Qq+Y7/t9D7unJKWaclMuf1klj94Fn+4eBA3nWrdcXuHgq7NL2XSwKPcO23vBbyjPZLm05+ewushtYvu7Vpw7sDOvPo/I3n6ymGM7t3ObeIB6JiVRqj0lCSG230OWRmxT/8REe4/vz8D7QvUmf07xfS+1hkptMtMdYcuZqQm8bMzjuWj204KOo/vn9AdCO7Ed8rnfGYsZbxubK9G9+vraU7zqvWkx7jr7L5cO7ZX0GS54T3bMuvOcb7vvWxEd166dkTQMNwfjskJKtsHPxnLPWf3JS05iV9NOp5VD010/y96tc8MKvvwnlZNpGd2Jg9cMICPbjuZQEB4/9axvHjNCLJbptG6RQqtM1L48/cHc/kJ3Zl89XBeuvYEPvzJWPc4ne0aY2gQa9sihXhI2All3jbPWWsKGOfTsZiIaurqg8ZFO9V4dxx+lKa09xZYsyc/XbaDR+xAAlYg2FNWzdMz1lFeXcdIuxMsdJZuckDcjtMFm4M7CW8ddzRPfbHOfT5v425EGjqzW6Yn09Mem15Xb4La4P20y0zh1nF9OKv/UXRolUZBSVXYpC+nycK52EFDUrd3f3winVunc1RWupvF06k9ARxl3/GLCMd5LjJ3nnWcGzBOObYDAG/eOIai8hp3mKJf0xDAP380mg2FZUGjffZVmxapPH3lMN+7649vP4lrXppHYWk1bSJccAZ0bbi4Z6Yl0coeLeTt53H6G87sdxSxSgoIWenJbjPZMR1bsia/FBFYev9ZPPrJSi4c2pWLnp7j+16HczPQJiMlaFuP7BZh76mrN/TrksX4vp0Y37cTX6/bxfrCUn4wsgebd5czedZ6qmvr6d+lNf27WOctImF/J4O7teZ7Q7ty3uDOGAMvfbUhaKIdWIH19OPDg/Dv7RoawKBuDbVQp3bp7RN45X9Gxm3ya8IGgvSUJNY9PInvPf1Vo80Qh7uSyhq27Klo9OIIhHXCOnc+TvU4WtXd2Td0n5LKGrcTsriihmnLd/JW7neMDOlMPap1eliTRfuWafzp0kGcdlzHoEDwdt4WerXPdCdOtUxLJjkpQNc2GWzeXc6xncInWnl1aJlGUqDhIu3XX+DHSc7Wu30mbeybCecuzZu3rZ3nRqN9yzTWPzwpajNJC88s35xs/6aM1ORAUFDZX5NC2p0d/bu05ut7TmfTrnJapUe+8xzftyPTV+aTFBDOHtCZ52auZ2yf9u7r6SlJfG+o/yiiaObdO4G1+aXU1RvW5Jfyi38vIjM1mcy0ZB68YEBYQrvxfTvSo10Lbjq1N5/ZqR6cC6f3Z+0E3EkDj2LKkh389Yqh/HX6GlbvLOWYjg01xzFHZzPmaKuWePGwbu4qd40RER6/zOo/cJpBvf0k+8OpiXkDwan2ecRD3AKBiHQHXgWOAuqBycaYv4TscxrwAeAk0XjXGPNgvMoUKikgdGyV7g43DFVWVcvO4sqYOnsOZf/z8rd8u3FPoxejooqasMVLnADg5Nv3S9IG1igjZ1jm9r3BHX6lVbUsdwJBZS33fbCUbUWVQbWL7MzUsI7pd2450W0O8Tr12A7MXF1A2xYp7h+O09T3q0l9ufm1+Qzr2Sbsfc9dPZyb7AXh97et9fITuvPmt9+5QQCs1Au3jjuaS4Z358evz2fF9uKwn3O0nztYNa+J/Y/inEGdG903nlKSAvTpGP3v/YnLh/DaN5s4IacdKUkBNv7+nIPy2ekpSW6Nwxnjf/fZDUNivXMVFvzfGWSmJbt/M6/fMIqiipqwO+aUJHGD/F8uH8qjF9fRKj2F39s11kjnur+jc1qkJvPej0/07fuJxWPfHxy0OFKk2uHBFs8aQS3wc2PMfBFpBeSJyFRjzPKQ/WYbY86NYzmi6pSVxvzNe1iweQ9PTFvDXy4fwkeLtzOkexse+M8yvt24h39cP5LiitqwIX3NxVm84+krhzG+r3+bb1FFjTvG3Gm6qKqtDxp9EmrwA+EzKJ2mGqeTtCTCNPzb/jnfXe3qi5B1YUsqa92JSs7IGbAmhDm6tMkIa3byS58A8KOTezNzdQE57TOZbzchtbA7TycO6MyGRyb5VqHP6n8UJx/TntlrCvd79MUjFw3ktxcOCNoWCAh3nmVdsN695cSgHET74tmrh+/X+5paVnoKPz6tT+M7HoAxvbOZ/ctx7qgnIOh3GponyFsjceT+eoLbtAlWkHOeP3vVcKYs3U6HVuH9MWDdWFw2ojtnDYitT8UrtON3X4TOx0huolXL4hYIjDHbge324xIRWQF0BUIDQbPqlJXO7rJqHp+2hlmrCzj1jzPCqqBXv2hNNDln0MG582nMd7vLg/4BQq3LL6Wypp7Hp67xDQSrd5Zw5uOz+NOlg7lkeDe3Lb28ujZqIPDjNIU4NYNI+VOcIADhOde3F1Xy3oLoSyF2bp3OuYO7cPs/F/DbCwfwzbpdQR36AAO7tmbJ1iJG5LTltetHMah7a3eJRe9ddLR2VGdG7P5OzBGRoL6AUBmpSfv8M1bhRMT3f6B3+8yYa3PeDuNQA7u1brQz+9FLBkV9vak8eEF/96YuXpqkj0BEcoChwFyfl8eIyCJgG/ALY8wyn/ffCNwI0KNHj9CXD0gne4TGLHvMe6SFNSKpqatn2bZihnQPb4rYH9OW7+SGV3OZfPVwurTJoEVqEt3btWDB5r1uJ2uds/5qhCYEZzbl9JU7uWR4N5IDQk2dlaM+2/cdkdXYE8ucpqF9XcPB26HrNbh7GxZ5Zo2O7NWO8wd34fzB1lA8ZzlRr5evO4Hl24tJT0niJHvCVMu05H2aFOgkGmtsgpQ6NE3/xWnNXYQm5x3FFC9xr3eISEvgHeCnxpjikJfnAz2NMYOBvwLv+x3DGDPZGDPCGDOiQ4eD22Hibev94NaxUfb099jU1Vz41FdBOd8PxGI7e+PSrUWc+9cvGf/nmTw8ZQXff+5rN8OikwclNA7MWJXP0zPWurn4nXTrSTF09EZKZuXkqXeOEamPIBJvEPBWw0PvcM6zA0A02S3TOPmY4N//9F+cyqc/PSXm8vzhkkFM7H9UTB3nSiWKuAYCEUnBCgKvG2PeDX3dGFNsjCm1H08BUkQkvLEvjsYcnc1lI7oz71enMyjGcc9ea+y770izZ/ebp3nDybfi3I277fYhkeDav3/LHz5ZhbN1W1EFP/vXQvciHymxGviv5wtQbTcNOdk3/foI/N57iZ02YEDXLAICH912UlDun6s8E6C+vGuc7ySqWHRslb5PI2kGdG3Ns1cPb9aFwpU61MTtv0GshtoXgRXGmMci7HOUvR8iMtIuj3+SmTjJSk/h0UsG0TErfZ/G6G7ZU87ohz9328MPWs4i+xbaWxIn74/TFOQk/Iq0ELczcWrxliLenb/Vbecvr65l8qx15Nz9sXtMh1/uHmhoGnKCyAtfbuA3HywN2mfp1vDakJNv5oHzB7D+kXMY0LW1WyP586WDOdOTy6abT4oApVTTiWcfwVjgamCJiDhLK/0K6AFgjHkWuAS4RURqgQrgchNpaaUmlpPdwnelIscbczezo7jSzZ8eS99CRXUdeZv2uO3bsXIu/M4ELO/6q37+74Owbhb38x+eYg2b211W7U56Aivdsh8n55B38tcrX2/ittOPoX3LNKpq68jdFD4ze3jPtmHDCp1g4mTSzPv1hEYXTVdKxV88Rw19SfCNrd8+fwP+Fq8yHIihPdqGBQLvspZOU1BqUoDqunry7bS1EHnUyv0fLuOt3O+Y9rNTI45fdi6L3kM4wxGraoIvyn759qPxNg3tKQ8OBJFqBKt2ljD0wc/YU17DcZ1aMWlgZx6ftpqv1+3izP6dOOGhaRFHEoW6a2JfyqpqOdmeGJMdZVSHUqrpaENpBE7yMS/vYtTOoiJO23lBcRW97pnCL99eHPGYfkv+hfKrDzkBwGlacUa+7Otsc+9ShHvKq6msqcMYw/aiCv671D83ekllLXvs/Dpjjs7m1nFH0yo9mTnrCvl02U43CJzrmWOx6Ddn+h6rT8eWvPGj0W4KcKXUoUH/I0O8fN0JfLN+Nz3ahU/zr6qtd7M+hnaa7iyxmoj+nbeFP146OOi16tp6np+93k2OVVUbOdma0xTj3cd57ASA/a0ReFP8PjNjHbPXFPKDUT34dOmOiE1DXqnJAZKTAozqlc1Xa3exsdAKhucM6sxNpxzNR4uttL3xHvOslDq4tEYQ4rTjOnL32X3D0r8C/PTNBe7QzdDO4W2etAr5JZWUV9e6HbKvfbOJP366yl3Y28lgWWuvWerl3PV7x+s7+UvcGoFdQ2gsR3yoAs9Er9l2ZtA35m4OCwKRpscvt2cHn3xMezbvLufr9bv4xZnH8tQPhrnzMZRShx8NBBEc26klPz8jeL3XL1YVuJ3DoePpvfmKRv7uc/rd9ylXv2jNn3Pe49hbYV14f/KGtWbp9JU72WNfjJ12/L2ezmenQzW0s9gbB0JHAfkJzeHvZ+Pvz+HNG0czqlc7zuxnzVpu2yKFET3b8mN7MZTvj+jOiUdnM7ZPNtfaKXhD19RVSh0+NBBEICJcNrJ72PbNu8uprq0Pa97xG/0y1869X1Qe3Iy0dGsxs9cUuInYnp25nqG/nUrepj1u849fP0Jo05D3M2NZaa2gpPFAAFae+bduGkN7ewJY17YZvH3LiZxo53PJSE3i9RtG8foNDe39oUspKqUOHxoIokj3ubht3lW+z8tbhg4t/ee8zVz94jx3opezWMvcDbvc5h+/ZRCdFb2cQOCtBcQyjyE0B1Co0ElWzrqsfjlbwrM86p+SUocr/e+Nwu8ud9PusqgX3aNDFtI2xlAcIWPn1pDVvgpKqtz+gEVbisL2dxZ7d4JFQWmVGxT8hn/efXbfoHNw9nn4ewPD9h3Wow3v3nJi0DZn5nJTpcJVSjUPDQRR+N3lLvxuLw9PWQFA/y7h+WoGdwtOPnfTP/KC0i1Hs3pnidsRHCo5IGGdxWvzS3ngP8swxnD/f5aF3dHffOrR9O4Q3ul9Rr9OZNtpfAd2bU1SQHj9htFBq09BQw2if9fYU29ESh2tlDp06fDRffTV2oaL+uje2W6efUeXkBE3zspJjtYZKVw+sjvPzQxf/WjrnoqIOXA6t0kP6ywGmLo8n4KSXBZs3ssjFw1kVK927CmvcRfxCE3lDFbGzqk/O5WSyhprXdpAwDd18qod1ryHgTEGgrxfT9AUzEodhrRGEAO/oaQAo3q1C9vmDQS3jw9fvOP7I7px0ylH+x5vV1l1WIdut7YZvHzdCWSkJFFRXccbczczZ22h+3phaRXTVuRzbKeWXDysG707tGR4z7YcYy/V2C4k3XJAID0lQLvMVHpmZ9IqPSXixfv8IVZG0Fjv8rNbph3QerpKqeahgaARGx6ZxHMRVo7q3aEl143N4cEL+rvb2noW/f7fM44NWws3Kz0laB/HwK6t3Vm83jH5f7p0MKcd15GMlCSKKmr41XtLKPPJIvrkFUN9axPOot3OYuT1JvrCLV63juvD2t+d7dtprpQ6cujtWyNExB09E6pFahK/Oa8/dfWGwpIqxvXtGNSRLCJhieE62VlOW6UlU1JV6y7ccma/Tu6Es6evHMbFz3wNQJp9ce+Ylc7UkGYmrz4R1lV2VnmKZZ6Bn6ZaKk8p1Xw0EMSgNmTRlnMGdaZb2ww620nbkgLCz848DoAFm631gZ0Mm6E3306it8k/HMG97y9h8tXD+W53hTuRTAT6HpVFekqAypp69y7/uhNzfAPBuYM606VNRsQLttOsM7ZP+6iBRCmVuDQQxKBndgtO79uR047rwP99sIwbT+7N4AhLUzqds5GWQnQCwZijs5n+89MA6NOxFXPWWe3+vdpnkpmWTEZKEpU19aQlJ7n7d22TETbk9Lbxx0RdmOWEnHY8e9UwTjqmA8u3Fe/zHAil1JFPA0EMUpICvHjtCQBc3cj6oU4A+IG9Aldoa7w39bNXdqbVL9C/izVCx2qXr3GbpUSEqT87hYuensNKezQPQNvMxhO8TRxgZQYd6dO5rZRSGggOsg6t0lh035lkZfj/aFtFSMHcoVUaAYHB9nKZHVulsb2oknpPXuoWqckM7No6KBC0ydBF2JVSB0YDQRy09hkV9MuJx7G3vCbiiJ12man866Yx7qSuZ68eznsLttIzO3gZx7vO7ktaSoA7z+zL7vJqXXtXKXXANBDEWVZGCvklVVw0tFvEZiHHiJyGppvOrTP48Wnh8xDat0zjoQutFBF+AUcppfaVBoI4e/GaEXywcJvm61dKHbI0EMRZz+xMbj/9mOYuhlJKRaQNzEopleA0ECilVILTQKCUUglOA4FSSiU4DQRKKZXgNBAopVSC00CglFIJTgOBUkolODHGNL7XIURECoBN+/n29kBho3sdWfScE4Oec2I4kHPuaYzp4PfCYRcIDoSI5BpjRjR3OZqSnnNi0HNODPE6Z20aUkqpBKeBQCmlElyiBYLJzV2AZqDnnBj0nBNDXM45ofoIlFJKhUu0GoFSSqkQGgiUUirBJUQgEJGJIrJKRNaKyN3NXZ6DRUReEpF8EVnq2dZORKaKyBr7e1t7u4jIk/bPYLGIDGu+ku8/EekuIl+IyAoRWSYid9jbj9jzFpF0EZknIovsc37A3t5LROba5/yWiKTa29Ps52vt13Oas/wHQkSSRGSBiHxkPz+iz1lENorIEhFZKCK59ra4/20f8YFARJKAp4CzgX7AFSLSr3lLddC8DEwM2XY38Lkx5hjgc/s5WOd/jP11I/BME5XxYKsFfm6MOR4YDdxq/z6P5POuAsYbYwYDQ4CJIjIaeBR43D7nPcD19v7XA3uMMX2Ax+39Dld3ACs8zxPhnMcZY4Z45gvE/2/bGHNEfwFjgE89z+8B7mnuch3E88sBlnqerwI62487A6vsx88BV/jtdzh/AR8AZyTKeQMtgPnAKKwZpsn2dvfvHPgUGGM/Trb3k+Yu+36cazf7wjce+AiQBDjnjUD7kG1x/9s+4msEQFfgO8/zLfa2I1UnY8x2APt7R3v7EfdzsKv/Q4G5HOHnbTeRLATyganAOmCvMabW3sV7Xu45268XAdlNW+KD4gngl0C9/TybI/+cDfCZiOSJyI32trj/bSfC4vXisy0Rx8weUT8HEWkJvAP81BhTLOJ3etauPtsOu/M2xtQBQ0SkDfAecLzfbvb3w/6cReRcIN8YkycipzmbfXY9Ys7ZNtYYs01EOgJTRWRllH0P2jknQo1gC9Dd87wbsK2ZytIUdopIZwD7e769/Yj5OYhIClYQeN0Y8669+Yg/bwBjzF5gBlb/SBsRcW7mvOflnrP9emtgd9OW9ICNBc4XkY3Am1jNQ09wZJ8zxpht9vd8rIA/kib4206EQPAtcIw92iAVuBz4sJnLFE8fAtfYj6/BakN3tv/QHmkwGihyqpuHE7Fu/V8EVhhjHvO8dMSet4h0sGsCiEgGMAGrA/UL4BJ7t9Bzdn4WlwDTjd2IfLgwxtxjjOlmjMnB+p+dboy5kiP4nEUkU0RaOY+BM4GlNMXfdnN3jjRRB8wkYDVWu+q9zV2eg3he/wS2AzVYdwfXY7WLfg6ssb+3s/cVrNFT64AlwIjmLv9+nvNJWNXfxcBC+2vSkXzewCBggX3OS4H77O29gXnAWuDfQJq9Pd1+vtZ+vXdzn8MBnv9pwEdH+jnb57bI/lrmXKua4m9bU0wopVSCS4SmIaWUUlFoIFBKqQSngUAppRKcBgKllEpwGgiUUirBaSBQyiYidXbWR+froGWqFZEc8WSJVepQkggpJpSKVYUxZkhzF0KppqY1AqUaYeeIf9ReE2CeiPSxt/cUkc/tXPCfi0gPe3snEXnPXj9gkYicaB8qSUSet9cU+MyeJYyI3C4iy+3jvNlMp6kSmAYCpRpkhDQNXeZ5rdgYMxL4G1bOG+zHrxpjBgGvA0/a258EZhpr/YBhWLNEwcob/5Qxpj+wF7jY3n43MNQ+zs3xOjmlItGZxUrZRKTUGNPSZ/tGrIVh1tsJ73YYY7JFpBAr/3uNvX27Maa9iBQA3YwxVZ5j5ABTjbW4CCJyF5BijHlIRD4BSoH3gfeNMaVxPlWlgmiNQKnYmAiPI+3jp8rzuI6GPrpzsHLGDAfyPNk1lWoSGgiUis1lnu9f24/nYGXGBLgS+NJ+/DlwC7gLymRFOqiIBIDuxpgvsBZhaQOE1UqUiie981CqQYa9CpjjE2OMM4Q0TUTmYt08XWFvux14SUTuBAqA6+ztdwCTReR6rDv/W7CyxPpJAl4TkdZY2SQfN9aaA0o1Ge0jUKoRdh/BCGNMYXOXRal40KYhpZRKcFojUEqpBKc1AqWUSnAaCJRSKsFpIFBKqQSngUAppRKcBgKllEpw/w+zp712PbFzwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 검증 그래프\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 처음 10개의 데이터 포인트를 제외한 검증 점수 그리기\n",
    "\n",
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    \n",
    "    return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "404/404 [==============================] - 0s 430us/step - loss: 511.1451 - mae: 20.7177\n",
      "Epoch 2/80\n",
      "404/404 [==============================] - 0s 197us/step - loss: 343.7651 - mae: 16.4748\n",
      "Epoch 3/80\n",
      "404/404 [==============================] - 0s 193us/step - loss: 172.2105 - mae: 10.8263\n",
      "Epoch 4/80\n",
      "404/404 [==============================] - 0s 223us/step - loss: 79.3951 - mae: 6.6172\n",
      "Epoch 5/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 46.7220 - mae: 4.9721\n",
      "Epoch 6/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 33.4074 - mae: 4.1626\n",
      "Epoch 7/80\n",
      "404/404 [==============================] - 0s 193us/step - loss: 27.3487 - mae: 3.6917\n",
      "Epoch 8/80\n",
      "404/404 [==============================] - 0s 359us/step - loss: 24.2446 - mae: 3.4792\n",
      "Epoch 9/80\n",
      "404/404 [==============================] - 0s 200us/step - loss: 22.0862 - mae: 3.2948\n",
      "Epoch 10/80\n",
      "404/404 [==============================] - 0s 215us/step - loss: 19.8162 - mae: 3.0843\n",
      "Epoch 11/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 18.0645 - mae: 2.9280\n",
      "Epoch 12/80\n",
      "404/404 [==============================] - 0s 205us/step - loss: 16.1739 - mae: 2.7734\n",
      "Epoch 13/80\n",
      "404/404 [==============================] - 0s 199us/step - loss: 15.0397 - mae: 2.6515\n",
      "Epoch 14/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 13.8556 - mae: 2.5346\n",
      "Epoch 15/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 13.0596 - mae: 2.4638\n",
      "Epoch 16/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 12.4680 - mae: 2.4682\n",
      "Epoch 17/80\n",
      "404/404 [==============================] - 0s 218us/step - loss: 11.9209 - mae: 2.3979\n",
      "Epoch 18/80\n",
      "404/404 [==============================] - 0s 212us/step - loss: 11.4246 - mae: 2.3367\n",
      "Epoch 19/80\n",
      "404/404 [==============================] - 0s 205us/step - loss: 10.9596 - mae: 2.2891\n",
      "Epoch 20/80\n",
      "404/404 [==============================] - 0s 223us/step - loss: 10.8468 - mae: 2.2744\n",
      "Epoch 21/80\n",
      "404/404 [==============================] - 0s 213us/step - loss: 10.5423 - mae: 2.2751\n",
      "Epoch 22/80\n",
      "404/404 [==============================] - 0s 200us/step - loss: 10.2013 - mae: 2.2382\n",
      "Epoch 23/80\n",
      "404/404 [==============================] - 0s 220us/step - loss: 10.2151 - mae: 2.2337\n",
      "Epoch 24/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 9.7918 - mae: 2.2087\n",
      "Epoch 25/80\n",
      "404/404 [==============================] - 0s 220us/step - loss: 9.8308 - mae: 2.2006\n",
      "Epoch 26/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 9.7180 - mae: 2.1916\n",
      "Epoch 27/80\n",
      "404/404 [==============================] - 0s 190us/step - loss: 9.2513 - mae: 2.1178\n",
      "Epoch 28/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 9.4202 - mae: 2.1607\n",
      "Epoch 29/80\n",
      "404/404 [==============================] - 0s 227us/step - loss: 9.0801 - mae: 2.1199\n",
      "Epoch 30/80\n",
      "404/404 [==============================] - 0s 197us/step - loss: 9.0725 - mae: 2.1299\n",
      "Epoch 31/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 8.7437 - mae: 2.1155\n",
      "Epoch 32/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 8.7770 - mae: 2.0859\n",
      "Epoch 33/80\n",
      "404/404 [==============================] - 0s 235us/step - loss: 8.5673 - mae: 2.0876\n",
      "Epoch 34/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 8.5943 - mae: 2.0785\n",
      "Epoch 35/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 8.3592 - mae: 2.0708\n",
      "Epoch 36/80\n",
      "404/404 [==============================] - 0s 220us/step - loss: 8.3432 - mae: 2.0585\n",
      "Epoch 37/80\n",
      "404/404 [==============================] - 0s 213us/step - loss: 8.2627 - mae: 2.0238\n",
      "Epoch 38/80\n",
      "404/404 [==============================] - 0s 183us/step - loss: 8.2417 - mae: 2.0335\n",
      "Epoch 39/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 8.0880 - mae: 2.0194\n",
      "Epoch 40/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 7.8885 - mae: 1.9897\n",
      "Epoch 41/80\n",
      "404/404 [==============================] - 0s 193us/step - loss: 7.8103 - mae: 1.9982\n",
      "Epoch 42/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 7.7550 - mae: 1.9886\n",
      "Epoch 43/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 7.7281 - mae: 1.9493\n",
      "Epoch 44/80\n",
      "404/404 [==============================] - 0s 207us/step - loss: 7.7050 - mae: 1.9677\n",
      "Epoch 45/80\n",
      "404/404 [==============================] - 0s 225us/step - loss: 7.7173 - mae: 1.9823\n",
      "Epoch 46/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 7.5010 - mae: 1.9836\n",
      "Epoch 47/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 7.4066 - mae: 1.9515\n",
      "Epoch 48/80\n",
      "404/404 [==============================] - 0s 193us/step - loss: 7.4433 - mae: 1.9433\n",
      "Epoch 49/80\n",
      "404/404 [==============================] - 0s 220us/step - loss: 7.2686 - mae: 1.9188\n",
      "Epoch 50/80\n",
      "404/404 [==============================] - 0s 223us/step - loss: 7.1536 - mae: 1.9223\n",
      "Epoch 51/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 7.1615 - mae: 1.9270\n",
      "Epoch 52/80\n",
      "404/404 [==============================] - 0s 210us/step - loss: 7.1209 - mae: 1.8972\n",
      "Epoch 53/80\n",
      "404/404 [==============================] - 0s 229us/step - loss: 7.0269 - mae: 1.8853\n",
      "Epoch 54/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 6.8535 - mae: 1.8617\n",
      "Epoch 55/80\n",
      "404/404 [==============================] - 0s 230us/step - loss: 6.8321 - mae: 1.8658\n",
      "Epoch 56/80\n",
      "404/404 [==============================] - 0s 215us/step - loss: 6.7000 - mae: 1.8964\n",
      "Epoch 57/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 6.6415 - mae: 1.8506\n",
      "Epoch 58/80\n",
      "404/404 [==============================] - 0s 205us/step - loss: 6.6554 - mae: 1.8368\n",
      "Epoch 59/80\n",
      "404/404 [==============================] - 0s 200us/step - loss: 6.5347 - mae: 1.8184\n",
      "Epoch 60/80\n",
      "404/404 [==============================] - 0s 208us/step - loss: 6.4475 - mae: 1.8104\n",
      "Epoch 61/80\n",
      "404/404 [==============================] - 0s 210us/step - loss: 6.4322 - mae: 1.8340\n",
      "Epoch 62/80\n",
      "404/404 [==============================] - 0s 200us/step - loss: 6.4745 - mae: 1.7996\n",
      "Epoch 63/80\n",
      "404/404 [==============================] - 0s 186us/step - loss: 6.2111 - mae: 1.8008\n",
      "Epoch 64/80\n",
      "404/404 [==============================] - 0s 183us/step - loss: 6.4132 - mae: 1.8058\n",
      "Epoch 65/80\n",
      "404/404 [==============================] - 0s 225us/step - loss: 6.2393 - mae: 1.7963\n",
      "Epoch 66/80\n",
      "404/404 [==============================] - 0s 210us/step - loss: 6.2386 - mae: 1.7770\n",
      "Epoch 67/80\n",
      "404/404 [==============================] - 0s 188us/step - loss: 6.0829 - mae: 1.7715\n",
      "Epoch 68/80\n",
      "404/404 [==============================] - 0s 213us/step - loss: 6.0819 - mae: 1.7671\n",
      "Epoch 69/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 5.9923 - mae: 1.7732\n",
      "Epoch 70/80\n",
      "404/404 [==============================] - 0s 204us/step - loss: 5.8333 - mae: 1.7343\n",
      "Epoch 71/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 5.9536 - mae: 1.7463\n",
      "Epoch 72/80\n",
      "404/404 [==============================] - 0s 203us/step - loss: 5.8592 - mae: 1.7232\n",
      "Epoch 73/80\n",
      "404/404 [==============================] - 0s 190us/step - loss: 5.7247 - mae: 1.6989\n",
      "Epoch 74/80\n",
      "404/404 [==============================] - 0s 200us/step - loss: 5.7476 - mae: 1.7261\n",
      "Epoch 75/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 5.7450 - mae: 1.7219\n",
      "Epoch 76/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 5.7317 - mae: 1.7222\n",
      "Epoch 77/80\n",
      "404/404 [==============================] - 0s 213us/step - loss: 5.6320 - mae: 1.6903\n",
      "Epoch 78/80\n",
      "404/404 [==============================] - 0s 229us/step - loss: 5.6323 - mae: 1.6735\n",
      "Epoch 79/80\n",
      "404/404 [==============================] - 0s 198us/step - loss: 5.4680 - mae: 1.6768\n",
      "Epoch 80/80\n",
      "404/404 [==============================] - 0s 195us/step - loss: 5.4904 - mae: 1.6598\n",
      "102/102 [==============================] - 0s 235us/step\n"
     ]
    }
   ],
   "source": [
    "# 약 80번째에 줄어드는것이 멈춤\n",
    "model = build_model()\n",
    "model.fit(train_data, train_targets,\n",
    "         epochs=80, batch_size=16, verbose=1)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5827550888061523 2.5827550888061523\n"
     ]
    }
   ],
   "source": [
    "print(test_mae_score, test_mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tutorial",
   "language": "python",
   "name": "tkeras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
