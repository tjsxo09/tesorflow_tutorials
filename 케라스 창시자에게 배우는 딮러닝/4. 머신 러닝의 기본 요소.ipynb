{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 머신 러닝의 네 가지 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전에 다루었던 문제들\n",
    "    1. 이진 분류 (리뷰 긍정, 부정 분류)\n",
    "    2. 다중 분류 (기사 토픽 분류)\n",
    "    3. 스칼라 회귀 (주택값 예측)\n",
    "\n",
    "- 위의 학습 방법들은 모두 지도 학습(supervised learning)의 예이다.\n",
    "\n",
    "- 지도 학습\n",
    "    - 훈련 데이터의 입력과 타깃 사이의 관계를 학습을 목적으로 학습하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. 지도 학습\n",
    "\n",
    "- 가장 흔한 경우\n",
    "- 타깃에 입력 데이터를 매핑하는 방법을 학습\n",
    "\n",
    "\n",
    "- 특이한 경우\n",
    "    1. 시퀸스 생성 : 사진이 주어지면 이를 설명하는 캡션 생성\n",
    "    2. 구문 트리 예측 : 문장이 주어지면 분해된 구문 트리 예측\n",
    "    3. 물체 감지 : 사진이 주어지면 사진 안의 특정 물체 주위에 경계 상자를 그린다.\n",
    "    4. 이미지 분할 : 사진이 주어졌으 때 픽셀 단위로 특정 물체에 마스킹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. 비지도 학습\n",
    "\n",
    "- 어떤 타깃도 사용하지 않고 입력 데이터에 대한 변환을 찾는다.\n",
    "- 데이터 시각화, 데이터 압축, 데이터 노이즈 제거, 데이터의 상관관계를 알기 위해 사용\n",
    "- 데이터 분석에 중요한 요소이다.\n",
    "- 잘 알려진 것\n",
    "    1. 차원 축소\n",
    "    2. 군집(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. 자기 지도 학습\n",
    "\n",
    "- 지도 학습의 특별한 경우\n",
    "- 사람이 만든 레이블을 사용하지 않는다. -> 사람이 개입하지 않는다.\n",
    "- 레이블은 필요하지만 보통 경험적인 알고리즘을 사용하여 데이터로부터 생성한다.\n",
    "- 오토 인코더가 잘 알려진 자기 지도 학습의 예이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. 강화 학습\n",
    "\n",
    "- 에이전트는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택한다.\n",
    "- 대부분 연구 영역에 속함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 머신 러닝 모델 평가\n",
    "\n",
    "- 훈련에 사용한 데이터로 모델을 평가하지 않는 이유 : 훈련 데이터에 과대적합을 할 수 있기 때문\n",
    "- 머신 러닝의 목표 : 일반화된 모델을 얻는 것    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 훈련, 검증, 테스트 셋\n",
    "\n",
    "- 훈련 셋과 테스트 셋 2개를 사용하지 않고 검증 셋을 추가해서 사용하는 이유\n",
    "    1. 모델을 개발할 때 모델의 설정을 튜닝하기 때문\n",
    "    2. 검증 셋의 성능을 기반으로 모델의 설정을 튜닝하면 검증 셋에 과대적합 할 수 있기 때문 -> 정보 누설\n",
    "    \n",
    "    \n",
    "- 데이터가 적을 때 훈련, 검증, 테스트 셋으로 나누는 고급 기법\n",
    "    1. 단순 홀드아웃 검증\n",
    "    2. K-겹 교차 검증\n",
    "    3. 셔플링을 사용한 반복 K-겹 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 홀드아웃 검증\n",
    "\n",
    "- 데이터의 일정량을 테스트 셋으로 떼어 놓는다.\n",
    "- 정보 누설을 막기 위해 테스트 셋을 사용하여 모델을 튜닝하는것은 안된다.\n",
    "\n",
    "\n",
    "- 단순 홀드아웃 검증 그림 예시\n",
    "![홀드_아웃_검증](./images/hold-out.png)\n",
    "\n",
    "\n",
    "### 홀드아웃 검증 구현 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_validation_samples = 10000\\n\\nnp.random.shuffle(data) # 데이터를 무작위로 섞는것이 좋다. -> 오버 피팅 방지를 위해서\\n\\nvalidation_data = data[:num_validation_samples]\\ndata = data[num_validation_samples:]\\n\\ntraining_data = data[:]\\n\\nmodel = get_model()\\nmodel.train(training_data) # 훈련 데이터로 훈련 후 \\nvalidation_score = model.evaluate(validation_data) # 검증 데이터로 평가\\n\\n# 반복적으로 훈련 및 튜닝\\n\\nmodel = get_model()\\nmodel.train(np.concatenate([training_data, validation_data])) # 튜닝이 끝나면 전체 데이터를 가지고 훈련\\n\\ntest_score = model.evaluate(test_data)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data) # 데이터를 무작위로 섞는것이 좋다. -> 오버 피팅 방지를 위해서\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "training_data = data[:]\n",
    "\n",
    "model = get_model()\n",
    "model.train(training_data) # 훈련 데이터로 훈련 후 \n",
    "validation_score = model.evaluate(validation_data) # 검증 데이터로 평가\n",
    "\n",
    "# 반복적으로 훈련 및 튜닝\n",
    "\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data, validation_data])) # 튜닝이 끝나면 전체 데이터를 가지고 훈련\n",
    "\n",
    "test_score = model.evaluate(test_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순 홀드아웃의 단점\n",
    "    1. 데이터가 적을 때는 검증 셋과 테스트 셋이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-겹 교차 검증\n",
    "\n",
    "- 데이터가 너무 적어 검증, 테스트 셋이 통계적으로 대표하지 못할 때 사용\n",
    "\n",
    "\n",
    "- 동일한 크기를 가진 K개 분할로 데이터를 나눈다.\n",
    "- 최종적으로는 K개의 점수 평균을 이용한다.\n",
    "\n",
    "\n",
    "- K-겹 교차 검증 사진 예시\n",
    "![kfold](./images/kfold.jpg)\n",
    "\n",
    "\n",
    "### K-겹 교차 검증 구현 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nk = 4\\nnum_validation_samples = len(data) // k\\n\\nnp.random.shuffle(data)\\n\\nvalidation_scores = []\\n\\nfor fold in range(k):\\n    validation_data = data[num_validation_samples * fold: num_validation_samples * (fold + 1)] # 검증 셋 선택\\n    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1)] # np.concatenate로도 만들 수 있다.\\n    \\n    model = get_model()\\n    model.train(training_data)\\n    validation_score = model.evaluate(validation_data)\\n    validation_scores.append(validation_score)\\n    \\n    validation_scroe = np.average(validation_score)\\n    \\n    model = get_model()\\n    model.train(data)\\n    test_score = model.evaluate(test_data)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold: num_validation_samples * (fold + 1)] # 검증 셋 선택\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1)] # np.concatenate로도 만들 수 있다.\n",
    "    \n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "    \n",
    "    validation_scroe = np.average(validation_score)\n",
    "    \n",
    "    model = get_model()\n",
    "    model.train(data)\n",
    "    test_score = model.evaluate(test_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셔플링을 사용한 K-겹 교차 검증\n",
    "\n",
    "- K 개로 분할을하기 전에 매번 데이터를 무작위로 섞는다.\n",
    "- 비용이 매우 많이 든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 기억해야 할 것\n",
    "\n",
    "- 평가 방식을 선택할 때\n",
    "    1. 대표성이 있는 데이터 : 훈련 셋과 테스트 셋은 데이터에 대한 대표성이 있어야한다.\n",
    "    2. 시간의 방향 : 과거에서 미래를 예측한다면 데이터를 무작위로 섞어서는 안 된다.\n",
    "    3. 데이터 중복 : 한 데이터셋에 어떤 데이터 포인트가 두 번 등장하면, 데이터를 섞고 훈련 셋과 검증 셋으로 나누었을 때 훈련 셋과 검증 셋에 데이터 포인트가 중복될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tutorial",
   "language": "python",
   "name": "tkeras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
